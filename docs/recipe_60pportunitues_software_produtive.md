Ao escrever este prefácio, estou realizando um ato de expiação, anos atrás.
quando comecei a ouvir falar de Harlan Mills e suas idéias, dei-lhes breves
Ou melhor, não lhes dei nenhuma atenção. Para encolher, o padre fez isso.
ouvir a confissão do pecador, e não simplesmente ouvir fofocas sobre o
pecado. Até conhecer Harlan, simplesmente não me preocupei em ler nenhum de seus escritos.
Foi um ato de puro preconceito, não contra garotos de fazenda de Iowa ou contra o beisebol.
fãs, mas contra os matemáticos. Ou, na verdade, contra os escritos dos matemáticos.
matemáticos.
Meu preconceito vem da minha primeira aula de geometria, no ensino médio.
Até então, eu era uma espécie de garoto prodígio em matemática, fato
que nunca deixei escapar à atenção dos meus colegas de escola. Mas geometria.
absolutamente me deixou perplexo. Durante três semanas fiquei sentado de boca aberta na aula.
nossa professora delineou prova após prova no quadro-negro.
poderia raciocinar de uma maneira tão direta e logicamente consistente era
simplesmente além da minha compreensão.
Durante a quarta semana, à medida que os teoremas se tornaram mais complexos,
começou a notar seus tropeços. Quando o fez, ela se referiu às suas anotações.
Eventualmente, eu a peguei raciocinando ao contrário, baixinho, de
teorema para axiomas. Eureka! Foi tudo uma farsa! Essas provas não foram!
métodos de raciocínio, mas métodos de confirmação do raciocínio.
não métodos de descoberta, embora fossem apresentados como se funcionassem
do axioma, passando por regras de inferência, até - oh, surpresa! - um teorema.
Eu me senti como se tivesse sido enganado e isso não combinava bem com meu status
como o garoto prodígio da gangue, resolvi nunca mais ser enganado pela matemática.
matemáticos e seus truques mesquinhos. Esse preconceito me serviu muito bem.
através de muitos anos de faculdade e pós-graduação em matemática, nunca.
confundiu a prova de um teorema com o método que poderia ter sido
usado para descobrir esse teorema - um método que eu sabia que seria
tudo menos limpo e arrumado.
E então, quando ouvi que Harlan Mills era um matemático por
origem, escrevendo sobre produtividade de software, zombei da perda minha.
descobri quando finalmente tive vergonha de ler alguns de seus reais
trabalho em vez de alguma repetição bastarda. O que descobri foi um pensador.
com um dom notável para expor a origem e o desenvolvimento de sua
idéias, e por levar o leitor na mesma viagem intelectual que ele próprio
havia levado.
É claro que, se as ideias não tivessem sido absolutamente de primeira linha, os viajantes
idade não teria valido a pena, independentemente do talento de Harlan como um escritor. Mas, como você bem sabe, eram ideias de primeira linha - ideias que tiveram uma influência profunda na produtividade de software em todo o mundo.
Durante a última década, tivemos muitas ideias menores afetando o corpo da produtividade do software Muitas dessas ideias se espalharam.
porque eles estão bem empacotados em sistemas de software "completos"
As ideias de Harlan, porém, sempre tiveram um ar fértil.
incompletude sobre eles, nenhum problema parece fechado, qualquer.
mais do que sua mente está fechada para extensões ou mesmo contradições de sua
Todos nós já ouvimos como a produtividade do software é um problema imenso.
problema do nosso tempo. Suponho que seja a imensidão do problema que o faz.
os desenvolvedores são presas fáceis desses "sistemas completos de desenvolvimento".
pessoalmente, gosto mais da abordagem de Mills.
Em vez de empacotar alguma ideia trivial que deveria resolver
todos os problemas de uma forma impensada, atacam as raízes do problema.
as pessoas veem seu processo de pensamento e decidem por si mesmas como se adaptar
as ideias para seu próprio ambiente É verdade que a abordagem de Mills pressupõe.
alguma inteligência e atenção por parte do leitor, mas não posso
acredito que qualquer melhoria na produtividade do software resultará
da boca estúpida de slogans.
Quando Harlan falou comigo sobre a coleta de seus livros inéditos
documentos limitados ou inacessíveis, agarrei-me à ideia em Produção de Software.
atividade, não temos apenas o desenvolvimento de uma ideia significativa, mas
o desenvolvimento de todo um conjunto de ideias inter-relacionadas.
"pacote de desenvolvimento de sistemas" do que antes - Deus me livre.
leitor inteligente e atento, é muito, muito mais do que um pacote poderia
sempre será. É uma chance de ver a mente de um dos pensadores profundos.
de nossa indústria - ou de qualquer indústria Seguindo esta ordem cronológica.
desenvolvimento de ideias, o estilo de resolução de problemas do leitor será sutilmente
mudou. O meu foi. Talvez eu não tenha aprendido muito com aqueles outros matemáticos.
matemáticos, mas Harlan Mills tem sido meu verdadeiro professor. Você tem sorte.
que ele agora pode ser seu.

Entrei na IBM em 1964. Tive a sorte de estar no Federal
Divisão de Sistemas, que tem enfrentado problemas desafiadores de
desenvolvimento de software, ao longo desses anos Esses problemas são tantos.
gerencial como técnico, e durante esse tempo as idéias e a disciplina de
a engenharia de software começou a emergir de forma visível.
As notas e documentos deste livro representam uma história pessoal de
ganhando e crescendo por uma pessoa, ajudado por muitos.
Primeiro, meus associados na Divisão de Sistemas Federais foram
construir sistemas complexos de software em tempo real sob condições contratuais.
Há uma grande diferença entre programar para você mesmo e programar
para outros. Há também uma grande diferença entre "interno".
desenvolvimento de software e desenvolvimento de software por contrato A diferença.
- cada caso é a necessidade de ser específico. Os outros nunca sabem o que você.
não fiz por si mesmo; mas o mundo inteiro sabe o que você prometeu e
"não serviria para os outros. Esses associados foram gentis o suficiente para experimentar
qualquer uma das minhas ideias e fornecer um campo de provas para a nova disciplina
de engenharia de software.
Em segundo lugar, a universidade desempenhou um papel central na criação de novas
-~'fundações em metodologia de software Durante esse tempo na IBM, tive.
também atuou, graças à IBM, no corpo docente da Universidade Johns Hopkins
e a Universidade de Maryland. As interações com professores e alunos.
a essas universidades e os universitários de ciência da computação em outros lugares foram muito benéficos, para dizer o mínimo. 
Os principais avanços nos fundamentos da metodologia de software vieram da universidade, não da indústria. Graças a Edsger Dijkstra, Tony Hoare, David Parnas, David Gries, Niklaus Wirth e outros, pelo trabalho em programação estruturada, entendemos e programam a correção, agora temos muitas simplicidades profundas sobre ideias que antes estavam envoltas no mistério e na complexidade do conhecimento da programação.
Uma busca por produtividade em software
O tema subjacente desta história tem sido a busca por produtividade
em software. Minha abordagem ao software tem sido a de um estudo em gestão,
lidar com um processo muito difícil e criativo. O primeiro passo.
tal abordagem é descobrir o que é ensinável, para poder
gerenciá-lo. Se não pode ser ensinado, não pode ser gerenciado de forma organizada e organizada.
atividade coordenada. Como o software lida com processos puramente lógicos, ele
Parecia claro que a matemática era a ferramenta certa para aplicar ao problema.
Nesta busca pela ensinabilidade, foi uma agradável surpresa descobrir
que grande parte da metodologia de software poderia ser formulada em termos clássicos
matemática Minha segunda surpresa foi descobrir quão próxima e facilmente.
a produtividade cresce a partir da capacidade de gerenciamento com controle intelectual.
desenvolvimento de software, as melhorias na produtividade são medidas em
fatores, não porcentagens.

Em 1968, escrevi um artigo para uma publicação interna de notícias da IBM
(ver artigo 2.º não existia então uma programação estruturada, mas sim o artigo).
mostra que eu buscava, já naquela época, produtividade de software por meio
desenvolvimento matemático.
Ao aprender pela primeira vez sobre programação estruturada da OTAN
artigo de Edsger Dijkstra (ver referência 4, p. 101), afirmei aos meus associados
na IBM que "deixando para os programadores, poderíamos esperar um
melhoria de produtividade de 50%, mas se conseguirmos isso poderíamos esperar
um fator de 3." Aconteceu mais ou menos assim; vimos os dois níveis
de melhoria, resultante de diferentes introduções da ideia em diferentes
partes da IBM. Esse diferencial em vigor é típico na introdução de novos
tecnologia em trabalhos que exigem muita atenção, como programação, porque a produtividade
é resultado de expectativas e também de capacidades.
pouco, ganhamos pouco, por vários motivos. Ou seja, gestores que permitem a introdução.
de nova tecnologia para ver como ela se sai invariavelmente ganha menos
do que os gestores que desenvolvem convicções de que grandes melhorias
Neste último caso, os gestores envolvem-se ativamente.
"fazer acontecer", em vez de simplesmente "deixar acontecer" passivamente.
Minha busca por capacidade de ensino e controle intelectual se voltou para
matemática e outras áreas de ciências exatas porque sem essa influência,
ficamos reduzidos a ser mais inteligentes que nossos antecessores.

poderia ser tão inteligente quanto um antecessor selecionado aleatoriamente,
isso não é bom o suficiente. É preciso melhorar as melhores ideias de todos os antecessores.
porque as melhores ideias até agora já terão sido testadas
e usado.
Mas uma vez encontrada esta alavancagem matemática, paradoxalmente, o
as ideias devem ser traduzidas de volta ao contexto da matéria a ser ensinada.
Descobri que esta tradução tem suas próprias armadilhas.
se tiver a ideia final, maior será o perigo de ver e discutir
com base no bom senso. Uma ilustração impressionante dessa armadilha ocorreu.
na minha descoberta de que as declarações individuais de um programa estruturado
poderia ser enumerado de uma maneira especial, de modo que nenhuma afirmação dependesse
por sua correção em declarações ainda a serem enumeradas, descobri isso.
pensando sobre a teoria da computabilidade e problemas que poderiam
ser resolvido sem nunca resolver conjuntos de equações simultâneas (resolver
problemas de interface simultâneos na integração do programa).
tradução para o contexto de programação "programação de cima para baixo".
resultado de rigor matemático específico na aplicação à programação.
na verdade, é válido apenas para computadores digitais e não para computadores analógicos.
Outras visões e interpretações
Para minha surpresa, depois de escrever sobre isso, ocorreram muitas discussões
de "programação top down" em conferências e revistas, baseada inteiramente
em argumentos de bom senso sobre o nome, que ignoraram completamente o
teoria da omputabilidade que eu tinha em mente. Por exemplo, argumentou-se que "o
er é o topo do sistema", que "o intérprete de controle de trabalho é o topo
do sistema ", e assim por diante. Como não havia rigor matemático para
· proibir essas discussões, alguns se tornaram bastante veementes Agora a virtude.
da definição de cima para baixo da teoria da computabilidade foi que
e um processo de integração integrado, que foi realizado durante, em vez
:han no final do processo de programação Esses vários processos comuns.
as definições dos sentidos não compartilhavam dessa virtude, e as pessoas que as usavam compartilhavam
não obter seus benefícios Mas isso não impediu o coro de pessoas que inventaram.
seus próprios significados convenientes para o termo, em vez de se dar ao trabalho
o descubra a ideia por trás disso. Como resultado, um número surpreendente de pessoas.
software ainda vê a programação de cima para baixo como uma "maneira de ver
coisas", em vez de uma ideia matemática rigorosa aplicada à programação,
e obtêm apenas benefícios superficiais com a ideia.
Perseguida com rigor matemático, a programação de cima para baixo ditava
que o código de controle do trabalho deveria ser escrito primeiro, e não por último, como havia sido feito universalmente anteriormente.
teve que ser escrito antes do código para acessar esses arquivos.
poderia reduzir os erros de programação a uma questão de falibilidade humana, enquanto
a integração tradicional de baixo para cima continha não apenas a falibilidade humana
mas é preciso enfrentar a incomputabilidade matemática. Isso ocorre por causa da depuração.
um sistema com erros de interface requer solução simultânea de interface
equações, para as quais não existem procedimentos finitos e que podem ser
feito apenas de forma aproximada e nunca completamente confiável.
Como resultado desta ideia matematicamente descoberta, as pessoas que
entendeu o que era, em vez de inventar algum senso comum
significado para isso, de fato experimentou uma melhoria dramática na integração
Simplesmente não houve crise de integração na última fase do processo.
desenvolvimento de software. Na verdade, meu principal critério para julgar se
a programação de cima para baixo foi realmente usada é apenas esta ausência de qualquer dificuldade
na integração. A prova do pudim está em comê-lo!
O coro de interpretações conflitantes do termo “de cima para baixo”
programação" foi superada em diversidade apenas pela do termo "chefe"
equipe de programadores." A equipe de programadores chefe foi concebida no setor industrial
engenharia como uma atividade estruturante de trabalho para dividir o
trabalho em vez de dividir o produto Estruturação do trabalho para um criativo.
processo é um problema profundo do processo, psicologia do trabalho, industrial
método e princípios de gerenciamento A equipe de programadores chefe tinha.
muitas considerações e verificações e equilíbrios explícitos incorporados a ele.
isso não impediu muitas pessoas de inventarem suas próprias ideias para o
termo, apesar do meu critério original de que um programador-chefe seja ambos.
um bom programador de nível de design e um bom gerente, principalmente de cronograma
e orçamento, programadores-chefes de todas as categorias, desde prima donnas
(com quem não sabemos o que fazer) a administradores administrativos (com quem
não sabemos o que fazer) apareceu em racionalizações de senso comum,
que convenientemente ignorou as questões centrais da criatividade e da
controle que impulsiona a ideia da equipe de programadores-chefe Não é de admirar.
que essas equipes de programadores-chefe nem sempre funcionavam bem, e
alguns levaram a um verdadeiro desastre. É o velho problema das bolsas de seda e das porcas.
ouvidos.

Metodologia e Gestão
Minha busca por produtividade em software não revelou nenhuma mágica, nenhuma panacéia.
Há melhorias notáveis ​​na produtividade possíveis ao longo
níveis aceitos hoje, mas exigem metodologia sólida e sólida.
O domínio da metodologia exige um comprometimento intelectual de vários anos. Se fosse mais fácil, todos já estariam fazendo isso.
-A gestão é tão necessária quanto a metodologia, para focar potencial
~ produtividade em produtividade realizada, conforme ilustramos abaixo.
As notas e documentos deste livro representam as ideias originais para
y termos que a indústria começou a usar, estou feliz que as pessoas estejam.
g os termos. Ficarei ainda mais feliz quando eles começarem a usar as ideias A. objetivo principal do consultor de matemática nos Sistemas Federais.
enter é descobrir maneiras de aumentar a produtividade do programador por meio de find.
g novas dimensões técnicas na programação de computadores.
Estas novas dimensões técnicas devem ser lógicas e matemáticas.
A ideia da matemática é facilitar a vida, encontrar formas mais simples
"fazer coisas. Um teorema matemático é elegante, não porque seja comum.
·suficiente ou difícil de entender, mas porque diz mais com menos desperdício
Dessa forma, a matemática pode ser uma fonte de grande poder na organização.
· g ideias e descrição de processos.
Precisamos desse tipo de poder na programação de computadores para lidar com
detalhes com menos esforço No entanto, é fácil confundir a simplicidade.
-' isso vem de uma análise profunda com uma análise simplória, que leva
complexidades desesperadoras. Encontrando as principais simplicidades em um processamento de dados.
roblem é um problema profundo que nem sempre é resolvido por um aplicativo simplório::.
ach. Mas essas simplicidades, encontradas antes da programação detalhada.
gins, soletre a diferença entre um programa concluído rapidamente e
.:.eficiente e difícil de terminar e ainda mais difícil de depurar.
Apenas escrever e executar um programa de computador para resolver um problema
Um problema de processamento é muito parecido com colocar a bola em todos os 18 buracos de um
= Se é claro. Esse é um bom começo - mas apenas um começo para o problema.
~ golfe, as próximas perguntas são fáceis de fazer, como "Quantas tacadas foram feitas
· ake?" Mas em programação as coisas são muito mais difíceis. A primeira coisa que não sabemos é "Qual é o tamanho do trabalho de programação?"
pergunte quanto tempo demorou. E podemos fazer mais algumas perguntas, como:
1. O programa funciona corretamente? Há boas evidências no formulário;
de clareza do programa e/ou testes sistemáticos para apoiar isso?
2. Funciona de forma eficaz em termos de tempo e recursos?
argumentos para dizer que os requisitos de tempo e recursos estão próximos do ideal?
3. O programa pode cuidar de si mesmo diante de dados incorretos ou
controlar informações; pode identificar e sinalizar diagnósticos ou sugestões;
para operadores ou usuários?
4. O programa está bem documentado o suficiente para que outros possam entender?
o que faz; é documentável em termos de estrutura e
modularidade no programa global?
5. O programa pode ser mantido; pode ser atualizado através de equipamentos?
alterações que possam surgir, através de bugs encontrados posteriormente, mantidos através
períodos de tempo mais longos em que ninguém se dedica a tempo inteiro?
6. O programa pode ser modificado, adicionado ou incorporado
programas de dimensões maiores como novas ideias no assunto
vem à luz ou está destinado a se tornar um programa morto que não
alguém entende ou usa?

As questões anteriores refletem mais a nossa ignorância do que a nossa sabedoria.
Eles perguntam, aos poucos e ao acaso, sobre nossas esperanças intuitivas
e temores pelo programa, e não por um conjunto sistemático de propriedades
que define o valor do programa.
A programação de computadores tem menos de uma geração e tem recantos
e recantos em abundância, em comparação com um assunto como geometria. No entanto, foi preciso.
muitas gerações de mentes brilhantes para evoluir a geometria em um mundo bem organizado
assunto o suficiente para ser valioso para um agrimensor científico, por exemplo.
a descoberta avança “a um ritmo mais rápido hoje, mas ainda estamos longe de
alicerce da programação de computadores e longe de ser um conjunto bem organizado de
princípios e técnicas.
Neste momento, parece que esta base poderá eventualmente consistir
da unificação de dois ramos bastante distintos da teoria da informação em
um único corpo.
Existe uma teoria estatística da informação, incorporada no trabalho de
Claude Shannon e outros, que fornece medidas quantitativas de informação
nos processos de transmissão e armazenamento de dados. Essas medidas podem ser.
aplicado à programação de computadores de duas maneiras, de maneira bastante direta.
o conteúdo de informação de uma linguagem de programação pode ser estudado de maneira muito
da mesma forma que as línguas naturais são tratadas em segundo lugar, a informação;
o conteúdo dos programas em execução pode ser estudado de maneira semelhante à maneira
processos de controle estocásticos são considerados.

Há também outra teoria da informação mais antiga, mais qualitativa
de caráter, que trata de questões de sintaxe e semântica em mensagens
com significados racionais. Este ramo busca identificar o que é estável (semântica).
em padrões de informação, para análise e exploração.
práticas de programação, essas ideias são encontradas em áreas tão diversas
como compiladores direcionados à sintaxe e processadores de arquivos orientados a tabelas.
Parece cada vez mais evidente que nenhum destes ramos pode
ser uma base suficiente para a programação de computadores em si.
união, com elaborações adequadas e peculiares ao tema da informática
programação, promete aproximar-se de questões fundamentais
como:
1. O que é par?
2. Existem limitações básicas nas eficiências e capacidades do programa
baseado na lógica da própria programação de computadores, independentemente do
Engenhosidade dos programadores?
3. Qual é um conjunto completo de perguntas a serem feitas sobre um programa para avaliar
Vale a pena?
É típico do desenvolvimento científico encontrar progresso principalmente
através de encontrar as perguntas certas a serem feitas, e a programação de computadores
não seja exceção. Podemos esperar que estas três questões sejam modificadas e
aprimorado de maneiras inesperadas à medida que as ideias certas vêm à tona.

Consideramos o problema de formulação de instruções de programação de alto nível
em formas primitivas (reconhecendo que é logicamente mal definido, mas
pragmaticamente de primeira importância). Nossa principal observação é que podemos
defina uma declaração chamada Iterative IF (IIF) para servir como uma construção fácil
bloco (com bloqueio de instruções e instruções de atribuição) para IFTHEN-
ELSE e DO (FOR) instruções compostas Isto, juntamente com.
a observação adicional de que a programação pode ser realizada de uma forma razoável
maneira sem rótulos de instrução (e sem instruções GO TO), leva
para uma linguagem de programação de alto nível com apenas duas instruções: atribuição
e SE iterativo.
A instrução Iterative IF (IIF) tem a forma
IFI E;
onde E é uma expressão com valor lógico e significa: se a expressão E for verdadeira,
execute o bloco sintático máximo imediatamente após esta instrução,
e depois retornar a esta instrução IIF para reexecução. Por exemplo,
usando delimitadores Algol, a sequência
IIFX<1O;
COMEÇO... FIM;
executaria o bloco BEGIN ... END repetidamente enquanto X <10
(para sempre, se X <10 para começar e X não for alterado no bloco).
para obter uma capacidade de loop DO, adicionamos duas instruções de atribuição,
X = 1;
IFI X< 10;
COMEÇO; X= X+ 1;
e temos o efeito de DO X= 1 TO 10. Para obter um IF-THEN
capacidade, podemos fazer o seguinte:
B=verdadeiro;
Banda IFF X< 10;
COMEÇO; B = falso; ..., FIM;.
A partir daí é fácil chegar a IF-THEN-ELSE.

Produtividade do programador
Através
Responsabilidade Individual
(1968)
Resumo
O seguinte começa a articular uma hipótese de trabalho para considerar
programar na IBM como uma atividade individual, e não como uma atividade de equipe.
Reconhece que os sistemas de suporte de software, como o OS/360, permitem agora
uma pessoa dedicada para lidar com os principais sistemas de programação atualmente
atribuídos a equipes de cerca de 10 a 30 pessoas.
A questão principal não é se os projetos individuais podem ser
produtivos, mas se eles podem ser gerenciados e organizados no
Estrutura da IBM Parece haver poucas dúvidas de que eles podem e
eles deveriam ser.
Introdução
Pode ser possível atacar todo o espectro da programação de computadores
problemas da Divisão e da Corporação, mudando de
uma abordagem de equipe para uma abordagem individual na concepção e produção
sistemas de programação Nesta abordagem, um único indivíduo é o único responsável,
no total e em detalhes, para desenvolver uma grande programação
sistema.
Objetivos que podem ser alcançados em produtividade, dados como fatores
de melhoria em relação aos níveis atuais usando a abordagem de equipe, são:
Sistemas Científicos
Comando/Sistemas Comerciais
Programação de sistemas de software
10-50
5-20
2-10
Esses fatores variados refletem os vários graus em que os níveis superiores
linguagens de programação podem assumir responsabilidades detalhadas na produção
de programas em diversas áreas.
A base para tal produtividade é a introdução de um novo IBMer,
um Programador Individual, com as mais altas qualificações profissionais, comparável
em habilidade e treinamento para profissionais em outras áreas como medicina,
direito e ensino universitário, atuando como indivíduo em uma carreira
Novos ingredientes que podem tornar possível essa produtividade são:
1. Um novo conceito de “imersão profunda” por um Programador Individual
em um problema de processamento de dados durante um período de vários meses.
2. Uma distinção mais precisa entre análise de sistemas e programação,
que permite que a operação de programação seja "limpa e
rápido."
3. As ferramentas de software do OS/360, PL/I e assim por diante, que podem ser usadas
por programadores individuais para lidar com detalhes em lotes de atacado.
Antecedentes Históricos
É fácil ver por que surgiu a abordagem de equipe para a programação,
por necessidade, no crescimento da indústria de processamento de dados.
sistemas complexos, como SAGE, rastreamento espacial e outros, foram abordados
com ferramentas de programação muito primitivas. À parte, há a história de.
o sujeito do rancho que nunca tinha andado a cavalo "Tudo bem", disse.
o capataz, "temos um cavalo que nunca foi montado, então você pode
comecemos juntos!" Assim foi no processamento de dados. Com hardware de capacidade sem precedentes
capacidade, crescida praticamente da noite para o dia, a coleção de
engenheiros e outros que foram os primeiros programadores começaram simultaneamente
aprender como construir sistemas complexos e aprender como
construir as ferramentas com as quais construir os sistemas.
Assim, os programadores começaram com enormes quantidades de detalhes
para lidar e nenhuma base teórica para lidar com isso.
havia uma “segurança inerente nos números, mas profeticamente, na experiência”.
de muitos, esta segurança em números não reside nos esforços combinados

de muitas pessoas, mas no fato de que havia mais chance, com muitos
pessoas, de encontrar alguns que fariam a maior parte do trabalho.
Também é fácil esquecer o quão jovem e imatura a ciência da computação
é, particularmente na teoria da programação, e com que rapidez está crescendo.
Por exemplo, o compilador FORTRAN apareceu em 1957, culminando alguns
anteriormente na direção de linguagens de programação de alto nível.
ainda assim, as primeiras ideias de compiladores direcionados à sintaxe não apareceram até 1960, depois
FORTRAN em vez de antes Mesmo agora, está claro que estamos longe de.
ideias fundamentais em linguagens de programação e sua tradução Por exemplo,
PL/1, de longe o melhor que temos como linguagem implementada de propósito geral,
é uma mistura ad hoc cujas origens são a pragmática exterior e não
qualquer síntese teórica profunda das necessidades do usuário e das realidades computacionais é importante.
na organização e estrutura de dados estão ainda mais atrás da programação
línguas.
Isso não significa que não haja muito sendo dito e escrito sobre
teoria da programação Existe. Mas está escrito em um ambiente amorfo,
em termos de especificidades diversas, precisamente porque nenhuma estrutura básica
ou literatura sobre o assunto realmente surgiu. Como resultado, há muito.
haff em torno da maioria dos grãos de trigo e muita reinvenção de rodas,
e assim por diante.
Por causa disso, é difícil acompanhar a literatura, que
· está se expandindo rapidamente e não muito bem estruturado.
a ciência da computação, tal como é, pode "superar" um gerente na indústria,
ou por essas mesmas razões. Um programador brilhante há dez anos, na época de.
montadores e carregadores, que pouco depois se tornou gerente, não só
teve que adicionar novos fatos e técnicas para se manter atualizado, já que a maioria das disciplinas
exigir, mas também teve que adicionar categorias totalmente novas de assuntos
ao seu pensamento, por exemplo, linguística matemática e biblioteca
gerenciamento.
Mas o facto é que, por mais embrionários e mal estruturados que sejam
pode ser que existam novas técnicas na ciência da computação agora, de forma alguma
visível no início, o que pode permitir que as pessoas lidem com detalhes no atacado
Muitas das principais e mais óbvias dessas técnicas são de alto nível.
linguagens de programação, melhor incorporadas hoje em PL/1 e no
recursos de sistemas operacionais, como no OS/360. Mas existem recursos adicionais
novas capacidades em um nível teórico mais profundo que estão apenas começando a
emergem, com base no processamento de sintaxe e na decomposição de sintaxe e
semântica em operações de processamento de dados. O compilador direcionado à sintaxe.
incorpora esta última capacidade no apoio a uma programação de alto nível
linguagem.
São estas capacidades teóricas, à medida que são utilizadas, que permitirão
o Programador Individual, como profissional, para realizar a programação completa
projetos, que agora são abordados pelas equipes.

Evidência Empírica
A validade da abordagem individual dependerá finalmente simplesmente
se funciona. Não é preciso procurar muito para encontrar evidências.
que pode funcionar. Normalmente, no entanto, esta evidência é examinada com um
hipótese bastante diferente em mente.
A evidência é que, em muitas ocasiões, indivíduos altamente motivados,
além de circunstâncias favoráveis ​​na formulação do problema, disponibilidade da máquina,
e assim por diante, apresentaram performances surpreendentes quando
em comparação com o que a indústria teve de se contentar como normal até
duas ordens de grandeza superiores em produtividade.
Se a pergunta for "Podemos fazer com que o programador médio faça isso?",
então essas performances são um tanto irrelevantes porque, por definição,
os programadores médios não são altamente motivados, nem têm condições favoráveis
• circunstâncias sob as quais trabalhar.
Mas essa é a pergunta errada para os nossos propósitos.
O cirurgião não é uma pessoa comum, nem é um mestre da vida no bridge.
próprios caminhos, são pessoas dedicadas. E sabemos que são pessoas de talento.
e visão estão dispostos a se dedicar às ideias em que acreditam.
A razão pela qual a questão anterior surge em um contexto organizacional
o conteúdo é uma suposição feita ceteris parabis sobre o número de programadores
precisamos. Supõe-se tacitamente que precisamos cada vez mais.
programadores e, portanto, a maioria deles cairá na categoria média.
É esta suposição que é desafiada aqui.
Se os objetivos de produtividade forem alcançáveis ​​através de profissionais
desenvolvimento e dedicação pessoal, conforme descrito em mais detalhes abaixo,
então a Divisão e a Corporação exigirão incrivelmente poucos computadores
programadores realizem o mesmo nível de esforço que fazemos agora.
Portanto, estes programadores não serão retirados do conjunto de média
programadores, mas entre os 10 ou 20% melhores.
Portanto, o peso da evidência é que alguns programadores, se forem capazes
e motivado, pode fazer o trabalho de muitas questões importantes.
são "A IBM pode pedir isso?" e ​​"A IBM pode depender deles para fazer isso?"
Estes são abordados a seguir.
A resposta para ambas as perguntas é “Sim, de fato!”

O programador individual
Esboçamos, brevemente, um retrato de um Programador Individual: seu ou
seu modo de trabalhar, processo de crescimento profissional, motivações e relações
com a empresa. A pessoa é fictícia, praticamente por necessidade. Existem pessoas com as capacidades necessárias e motivações latentes.
a empresa, possivelmente até 100 ou mais Mas as condições para prosseguir.
a carreira aqui descrita não está presente na empresa.
essas pessoas ocuparão cargos de equipe técnica sênior, outras em cargos técnicos
cargos gerenciais porque agora podem obter mais reconhecimento lá.
Há uma coisa a ser observada no início: o título “Programador Individual”
é usado para ser descritivo para satisfação no trabalho, prestígio e assim por diante.
em diante, um título melhor pode ser selecionado, como "Arquiteto de Sistema", "Programação
Architect", "System Definer" ou algo parecido.
Queremos que este título descreva uma posição importante.
Um Programador Individual assume um projeto de programação que
atualmente designaríamos uma equipe de até 10 a 30 pessoas (ou mais ou
menos, dependendo das circunstâncias). A questão é que atribuímos a um.
pessoa uma responsabilidade muito grande.
desenvolver abaixo, por meio de tarefas menores.) Este programador individual
será o único responsável pelo programa ou sistema de programação necessário,
na concepção geral e em detalhes completos A ajuda estará disponível no.
forma de serviços pessoais, como secretariado, digitação e coleta de dados,
e de serviços de consultoria com especialistas em teoria de programação,
serviços de software e o assunto do problema de programação.
Mas o Programador Individual não delegará nenhuma parte do design do programa
ou qualquer codificação detalhada para qualquer um. Alguns dos consultores irão.
ser outros Programadores Individuais "entre empregos", como discutiremos abaixo.
As bases para atribuir um grande problema e esperar a produtividade
são:
1. Capacidades teóricas mais aprofundadas para resolver problemas de processamento de dados.
O Programador Individual terá conhecimento do assunto,
e consultoria especializada ajuda como backup Com um conhecimento profundo de.
o suporte de software e consultoria nessa área, o Programador Individual
trabalhará diretamente com o cliente e resolverá qualquer disparidade
entre as necessidades do cliente e as realidades do processamento de dados.
2. Melhor utilização de ferramentas de suporte de software, em linguagens de programação
e manutenção e utilização da biblioteca. Conhecer todo o escopo da biblioteca.
suporte de software possível, o Programador Individual construirá a partir de,
em vez de reinventar, capacidades que podem ser necessárias e irão adaptar os dados
necessidades de processamento às capacidades existentes através de uma visão geral do
operação de programação.
3. Diminuição das especificações intermediárias entre o processamento de dados
problema e sua solução em linguagens de programação.
O programador é um profissional e trabalha com o cliente em um nível de respeito e confiança para resolver o problema de processamento de dados sem enredar
o cliente nos detalhes da solução Isto não implica qualquer
mistério na forma como o Programador Individual trabalha, mas reconhecer
que as linguagens de programação, cada vez mais, são elas próprias as melhores
linguagens a serem usadas na redação de especificações para um sistema de processamento de dados.
4. Diminuição de problemas de comunicação interna na produção de programação
Esta é a vantagem mais óbvia de um indivíduo.
Programador em uma equipe de programadores, e uma equipe importante.
5. Intensa motivação e dedicação durante o período de tempo necessário
para completar o projeto. O Programador Individual, como qualquer outro.
outros profissionais, é capaz de um nível sustentado de motivação e dedicação
na realização de um projeto. Essa motivação surge da oportunidade.
para criar um sistema de programação de valor para clientes e pares.

Análise e Programação de Sistemas
É importante, para compreender a responsabilidade de um indivíduo
Programador, para fazer uma distinção cuidadosa entre análise de sistemas,
pesquisa operacional e outras atividades que podem preceder a programação
de um sistema de processamento de dados Identificamos analistas de sistemas de.
programadores hoje em conceito, mas um projeto de programação geralmente tem grandes dimensões.
ingredientes da análise de sistemas nele, e esse fato confunde e confunde
considerações gerenciais na execução de tais projetos.
A razão para fazer uma distinção cuidadosa é esta: na programação
operação, alguns problemas importantes são a comunicação e o
manutenção da coerência detalhada em todo o sistema.
O programador tem uma tremenda vantagem sobre uma equipe neste aspecto, mas
mesmo assim, o tempo ainda é essencial para levar o projeto a um sucesso
conclusão Ou seja, a programação deve ser realizada em um intervalo de tempo.
tão curto quanto possível, mesmo que possa demorar vários meses, a fim de
manter esta coerência tão rigorosamente quanto possível.
análise ocorre concomitantemente à programação, todo o esforço
se dilui e se estende no tempo em detrimento da programação
em si.
Como resultado dessas considerações, um importante problema de gestão
A função no desenvolvimento geral de sistemas é a identificação de um limite
entre análise de sistemas e programação.
deve entrar no desenvolvimento geral nesse ponto, para que a operação de programação possa ser relativamente limpa e rápida.
mesma pessoa pode muito bem funcionar primeiro como analista de sistemas e depois como
programador, mas essas funções separadas ainda devem ser identificadas.
É frequente - e, de facto, normalmente deveria ser - que o
o esforço de análise de sistemas leva mais tempo do que o esforço de programação.
o que o sistema de processamento de dados deve fazer exige sujeito
importa a criatividade, enquanto determina como o sistema de processamento de dados
deveria fazer isso “o que” envolve criatividade na própria programação.
O programador deve conhecer o assunto para garantir
a integridade e relevância do sistema de processamento de dados nesse
assunto. Mas o Programador Individual deve se envolver pouco.
pensamento criativo sobre o assunto em si durante a programação. Caso contrário,
a vantagem de tempo de um esforço de programação rápido e limpo
estar perdido.
Em resumo, a atividade de análise de sistemas é essencialmente indutiva
reunião dos requisitos de dados, das técnicas e algoritmos
para processá-lo e a forma como os resultados devem ser interpretados.
É uma atividade extrovertida, que envolve a resolução de um problema do cliente
área uma solução em termos de projeto geral de sistemas, independente de
considerações sobre máquinas na maioria dos casos. Esta solução é apresentada em inglês,
matemática, e assim por diante, para comunicação entre pessoas e rigor;
O que é exigido é o assunto, não os detalhes da comunicação,
porque as pessoas têm capacidades muito elaboradas de correção de erros e feedback
nesses processos, como resultado, a atividade de análise de sistemas pode ser
realizado de forma um tanto vagarosa com problemas de "pousio" na vida das pessoas
mentes, a menos que os requisitos de tempo do cliente determinem o contrário, sem particular
comprometendo a própria atividade.
No entanto, a atividade de programação é de caráter mais dedutivo,
começando com os resultados da análise de sistemas como seus "axiomas" e determinando
a maneira mais eficaz de cumprir esses requisitos em um sistema de dados
sistema de processamento. É uma atividade introvertida, em geral, envolvendo
lidar com todos os detalhes necessários para projetar e implementar o
sistema de processamento de dados. Esta solução está em linguagens de programação, e
o rigor exigido está em refletir os requisitos do sistema nestas programações
Mas, diferentemente da análise de sistemas, o tempo é realmente importante.
essência na conclusão da operação de programação, a fim de manter
rigor e coerência no detalhe exigido pelas máquinas e
suas linguagens de programação.
Notamos que a descrição da análise de sistemas como extrovertida
e a programação como introvertida refere-se aos processos de trabalho e não
relacionamentos com clientes. Ainda há muitas decisões a serem tomadas entre eles.
o cliente e o Programador Individual Para permanecer dentro do razoável.
limites, essas decisões devem envolver principalmente como o cliente interage com as sequências de controle do sistema de processamento de dados, formatos de saída,
etc.- em vez dos algoritmos e técnicas de processamento dos dados.
Isto não quer dizer que exceções não sejam possíveis;
como pessoa, terá a capacidade de abordar o sistema
ele ou ela está programando em uma base muito mais ampla. Em vez disso, esses limites.
uma disciplina voluntária sobre todas as partes envolvidas, o que pode tornar
todo o processo de desenvolvimento do sistema mais eficaz.

O programador individual será responsivo
para os clientes?
Uma questão que pode surgir é a capacidade de resposta de um Programador Individual
de acordo com as necessidades do cliente. Essa pessoa programará o que ela ou ela
"pensa o melhor" para o cliente, para só mais tarde descobrir que não resolve
o problema de processamento de dados do cliente da melhor maneira?
Após um pouco de reflexão, parece que a resposta é que isto será
é muito menos problemático para um programador individual do que para uma equipe.
Existem duas razões principais para isso: responsabilidade e capacidade.
Primeiro, o Programador Individual é totalmente responsável pelo
sistema de programação e sabe disso se o sistema posteriormente não o fizer.
satisfazer o cliente, é um reflexo do Programador Individual, que
sabe disso também.
Em segundo lugar, o Programador Individual é mais capaz de responder
para um cliente do que uma equipe frequentemente, por causa das comunicações.
problemas e compartimentalização, um gerente de equipe simplesmente faz
não sei se uma solicitação de um novo cliente pode ser atendida.
se puder, o gestor pode hesitar, querendo manter a integração da equipe
problemas sob controle. Um programador individual não tem tais inibições.
Um Programador Individual é o mestre completo da situação.
Deveria ser característico dos Programadores Individuais serem ex-·
tremamente responsivo à interface do cliente em nível profissional, o que
inclui descobrir o que se passa na mente dos clientes e também o que eles dizem.
Uma reclamação frequente na programação de equipes é que “o cliente não
sabe o que quer", o que muitas vezes é uma admissão de que a equipe
não descobriu o que o cliente deseja. Frequentemente, por exemplo, os clientes.
não se pode realmente esperar que saibam o que querem até que tenham
vi alguma saída do sistema ou tentei usar procedimentos de controle do sistema que
pode ser proposto. Um programador individual poderia ser esperado.
muitos resultados para esses clientes, tendo a capacidade de modificar uma solução
de acordo com o problema do cliente.
É claro que esta capacidade de “ganhar dinheiro” no desenvolvimento de um sistema não está necessariamente presente em todas as pessoas que o fazem.
não devem ser Programadores Individuais, assim como algumas pessoas
não deveriam ser cirurgiões cardíacos.
Também vale a pena notar que outra razão pela qual os clientes podem
parecem continuar "mudando de idéia" é que o desenvolvimento do programa
O ciclo leva tanto tempo que ocorrem mudanças no pessoal ou surgem novas ideias em
o assunto. Este ciclo de desenvolvimento do programa deve ser mais curto para
um programador individual do que uma equipe.
Ainda outra razão, claro, para as dificuldades da equipe, é que diferentes
os membros da equipe interpretam o que ouvem de maneira diferente quando o cliente
estava dizendo a mesma coisa o tempo todo.
Os programadores individuais podem ser suficientemente motivados?
Com apenas um momento de reflexão, isso pode ser visto como não sendo problema quando
existe qualquer layout razoável de atribuições de longo prazo. Primeiro, o Indivíduo.
O programador tem a oportunidade de ser uma pessoa muito importante,
fazer com que sua vida conte. A principal motivação está no trabalho.
em si Quem não estiver intensamente interessado no trabalho, não terá.
chegou a este ponto de qualquer maneira. O Programador Individual deve ser pago.
bem no topo da escala para trabalhadores técnicos individuais.
comparando o custo com o da programação em equipe, pode-se justificar
salários bastante astronômicos, mas esta não é uma abordagem realista.
com o reconhecimento das possibilidades de ser Programador Individual, condições
do mercado de trabalho prevalecerá - assim como para os cirurgiões cardíacos.
atualmente, uma faixa de US$ 20.000 a US$ 40.000 pareceria razoável
(jovens que trabalham nesta faixa, e seniores de nível de mérito
Principalmente, isso é dinheiro de "sinceridade" e "orgulho" para
Um programador individual.
No entanto, o aspecto mais importante para um Programador Individual-
motivação - também pode ser convertida em um grande trunfo para a empresa:
em atribuições "entre trabalhos de clientes".
Uma tarefa individual para um Programador Individual deve
geralmente equivalem a três a nove meses. Um ano pode ser um pouco longo,
embora não esteja fora de questão, e tarefas mais curtas devem ser dadas
para mais jovens que estão chegando. Essas tarefas serão intensas e
exigente e deve ser intercalado com outras tarefas que envolvam
menos pressão.
Uma tarefa de meio período que deveria ser quase automática é a
manutenção do sistema de programação recém-concluída.
cliente a pessoa mais qualificada para lidar com essa fase do trabalho. Também dá ao Programador Individual feedback sobre o valor do trabalho que ele realiza.
ou ela acabou de fazer. Isso deve ser especialmente valioso para os mais jovens.
pessoas, no seu crescimento para empregos cada vez maiores.
Mas a principal tarefa "entre empregos" deveria ser a investigação
e construção de ferramentas, para si mesmo e para outros programadores individuais no futuro
Existem duas razões principais pelas quais isto pode ser de particular valor para
a empresa.

Primeiro, os programadores individuais são os melhores programadores
ao redor, e eles estão equipados para gerar ferramentas - que, afinal, são
apenas outros sistemas de programação. Temos sorte em programação.
Os cirurgiões cardíacos não utilizam a cirurgia cardíaca para construir
ferramentas para futuras cirurgias cardíacas, como válvulas e bombas artificiais.
são os programadores que constroem ferramentas de programação por meio da programação - como
como compiladores, por exemplo.
Segundo, os Programadores Individuais saberão melhor do que ninguém
caso contrário, quais ferramentas são necessárias "no campo", pois elas estão lá e
estão voltando. Neste contexto, os programadores individuais voltarão.
para o campo pela mesma razão que as pessoas escalam montanhas - "porque
está aí!" Eles ficarão felizes com o descanso e o tempo para refletir e
construir teoria e ferramentas, mas se tiverem o talento necessário, também
têm a inquietação que não os deixa vegetar.

A exposição da gestão é tolerável em projetos individuais?
Esta questão, como as duas anteriores, pode ser respondida mais facilmente do que
pode ser aparente à primeira vista. Um bom argumento pode ser feito para a ideia.
que a exposição da gestão pode ser menor num projecto individual do que
em um projeto de equipe Superficialmente, parece que existe o perigo de perder.
alguém em um projeto de equipe seria menos grave do que perder a pessoa
em um projeto individual Mas um pouco de reflexão mostra que isso não precisa ser feito.
o caso. Há duas razões.
Primeiro, o Programador Individual é a antítese do “louco”
cientista", que está produzindo um programa que funciona, só que ninguém mais pode
descubra como. Em vez disso, os programadores individuais estão envolvidos na programação.
problemas de considerável substância; devem trabalhar sistematicamente;
e manter trilhas bem documentadas para seu próprio uso na conclusão
seus próprios projetos Eles também usarão as principais ferramentas de software da biblioteca.
gerenciamento, na documentação automática, no controle de trabalho e em alto nível
linguagens de programação de origem. Todas essas ferramentas, usadas em comum por
Os Programadores Individuais em seus projetos também impõem, em troca, uma considerável disciplina incorporada. Assim, um Programador Individual deixa um rastro.
de documentação em uma forma familiar a outros Programadores Individuais.
Um dos serviços que devem ser prestados em conjunto à gestão
e para um programador individual em um projeto é uma equipe de revisão de design
ao qual o Programador Individual pode explicar o design e o progresso
para sua própria paz de espírito sobre não negligenciar as coisas, por exemplo.
Esta Equipe deve ter pelo menos um outro Programador Individual
de igual capacidade que está entre empregos e é designado como "backup"
para este trabalho. Se algo acontecer ao primeiro Programador Individual, o
o backup deve ser capaz de intervir com o mínimo de interrupção.
Em segundo lugar, verifica-se que a capacidade de backup assumida no
abordagem de equipe é muitas vezes ilusória - pelas mesmas razões que as comunicações
problemas que surgem nas equipes quando alguém está perdido em um ambiente compartimentado.
projeto, o efeito é muitas vezes mais difícil de neutralizar do que quando
::entrando em um projeto que existe como um todo orgânico, porque as decisões em
pontos de interface foram baseados na divisão do projeto mais do que
em quaisquer propriedades inerentes do problema.

Projetos de programação muito grandes
A maioria dos projetos atuais poderia ser realizada por uma única pessoa,
um programador individual, mas alguns exigirão mais de um, como
o Houston RTCC, OS/360 ou um grande sistema de comando/controle.
No caso, vários Programadores Individuais realizariam em conjunto o
projeto, não como uma equipe, mas como um conjunto de grandes desenvolvedores de subsistemas que
colidem de uma maneira predeterminada entre si. Por exemplo, de uma forma predeterminada.
sistema operacional, um programador individual pode assumir uma tradução de linguagem
ou um processador de gerenciamento de dados que opera como um aplicativo comum
processador de íons no sistema operacional.
Em outro lugar a ideia de desenvolver sistemas de suporte de software
-a construção aproximada em um sistema Kernel é discutida. Esta técnica de evolução.
sistemas operacionais para satisfazer instalações individuais é especialmente adequado
o uso de programadores individuais.
Principais sistemas de aplicações em áreas como defesa e espaço,
"sem exceção, possuem estruturas de subsistemas que podem ser usadas para delimitar
partes de um sistema total para atribuição a programadores individuais.
Para qualquer sistema desse tipo, é necessário que haja um Programador Individual Chefe que
define o sistema em sua totalidade e identifica as entradas e saídas
:exigido do subsistema, mas ele deve se comportar de todas as maneiras como
-er Programador individual e não como líder de equipe comum
senso.

Uma comunidade de programadores individuais
O precedente esboçou características de programadores individuais,
e como essas pessoas podem interagir coletivamente como uma Comunidade
de Programadores Individuais Em resumo, tal Comunidade pode apresentar.
o seguinte tipo de imagem.
Imagine um grupo de cerca de 15 a 50 programadores individuais como um
operação estável, dirigida a alguma área geral de processamento de dados, como
como Sistemas de Comando, Computação Espacial ou Operações Financeiras.
grupo pode possivelmente ser dividido em subcategorias para gerenciamento
a qualquer momento, cerca de metade dos Programadores Individuais.
estarão em empregos ativos, cada um fazendo interface e construindo uma programação
sistema para um cliente. A outra metade estará envolvida com manutenção.
de empregos anteriores, consultoria em empregos ativos, servindo como backups, pesquisando
novas ideias em teoria de programação e realização de trabalhos de construção de ferramentas.
Haverá também um grupo adicional de jovens candidatos a serem
Programadores individuais, agindo de forma muito semelhante ao indivíduo normal
Programadores, mas trabalhando em tarefas de menor escopo e tempo
períodos. Eles estão se transformando em Programadores Individuais desta forma, através de.
um processo de estágio.
É uma honra ser um desses candidatos, assim como é uma honra
para se formar na faculdade de medicina. Os candidatos têm pelo menos um mestrado.
equivalentes em um assunto de interesse para a Comunidade. Eles também têm um
Ph.D. equivalente pelos padrões atuais em ciência da computação e já
saber programar e desenhar programas A candidatura é descobrir.
se eles conseguem manter seu nível de concentração ao longo do período
tempo necessário para concluir grandes projetos de programação.
Há também uma comunidade maior de programadores individuais em
o nível da empresa. A construção de ferramentas em andamento nas diversas disciplinas.
comunidades é coordenada a este nível mais amplo e as ferramentas são disseminadas.
Entre um grupo de profissionais dedicados e seguros de sua
opinião própria sobre si mesmos, não há muito espaço para uma opinião "não inventada"
atitude aqui ". Eles querem todas as ferramentas em que puderem colocar as mãos e
não deveriam competir entre si nessa área.
A gestão desta comunidade de programadores individuais
tem algumas simplicidades inesperadas, em comparação com as operações da equipe.
Nas operações de equipe há sempre o problema de resolver problemas inter-relacionados.
performances individuais. Isso não é um grande problema para um indivíduo.
Programador Você descobre se o cliente gosta do sistema.
o sistema de uma pessoa e o de mais ninguém. O problema também é menor.
promovendo candidatos. Eles estão aprendendo e trabalhando em sistemas de clientes,
também, sozinhos, mas em sistemas menores.
A IBM pode usar programadores individuais de maneira eficaz?
Parece haver poucas dúvidas de que a IBM possa, de fato, pedir e contar
em programadores individuais neste momento e construir comunidades eficazes
de Programadores Individuais nos próximos três a cinco anos.
deve ser feita uma estimativa cuidadosa, mas parece que, com base numa constante
nível de trabalho, um fator de pelo menos dois a cinco poderia ser retirado
das categorias de programadores da empresa, com redução um pouco menor
nos custos devido ao maior nível de pessoal envolvido.
Uma questão que surge é "O que acontece com todos os programadores
temos?" A resposta é fácil. Os bons são convertidos em
Programadores individuais. O restante é absorvido em outras operações de
a empresa, em seu crescimento, onde sua experiência em programação servirá
em boa posição para outros empregos.
Outra questão é "A IBM pode esperar que programadores individuais
assumir as tarefas exigidas?" Não sabemos realmente quão difícil
a programação é, porque faz parte de uma indústria tão jovem.
é evidente que pessoas isoladas podem assumir o tipo de tarefas que
necessidade; isso já aconteceu na programação,· já em pelo menos dezenas de casos,
e possivelmente centenas - por exemplo, o compilador ALGOL que Edgar
Irons escreveu sozinho em um ano e o compilador PL360 de um homem só em
Stanford E neste contexto a dedicação necessária parece ser nenhuma.
mais do que muitos IBMistas já estão investindo em engenharia, manufatura,
marketing e gestão (incluindo a gestão de
programação).

O caso
Contra IR PARA
declarações no PL/1
(1969)
ARTIGO
5
Não é possível programar de maneira sensata sem GO TO's em FORTRAN
ou COBOL Mas é possível em ALGOL ou PL/I.
está disponível de maneiras alternativas para controlar a ramificação. Esta nota é para.
salientar que a nova tecnologia de linguagem em programação mudou
fora do GO TO e o torna de valor duvidoso para uso
em PL/I. Também aponta uma nova possibilidade em PL/1: que os programadores.
podemos e devemos ler programas escritos por outros, não em emergências traumáticas,
mas como um procedimento normal no processo de programação.
Nos primeiros dias da programação, quando os programas eram escritos
diretamente em código de máquina ou, no máximo, em linguagem Assembly, o ramo
declaração foi uma etapa de máquina muito simples de executar e encontrou seu caminho
nas primeiras linguagens de programação por meio da instrução GO TO, que
traduzido muito facilmente nas instruções do branch durante a programação.
idiomas aumentaram em complexidade e poder, a declaração GO TO
permaneceu conceitualmente o mesmo nas mentes dos programadores.
essas linguagens de programação agora fornecem bloqueio e aninhamento
de instruções de programa e para a vinculação dinâmica atrasada de variáveis.
Essas capacidades introduziram sérios efeitos colaterais para o GO TO
declaração em compiladores.
Uma linguagem moderna, como PL/I ou ALGOL, possui uma estrutura de blocos,
por exemplo, BEGIN...END, DO...END, para permitir o agrupamento de declarações em declarações compostas na linguagem, e permite novos
formas de lógica de controle que podem eliminar totalmente as instruções GO TO.
à primeira vista isto pode parecer surpreendente ou pode parecer trivial por meio de duplicação
seções de código ao longo de um programa Mas este não é o caso.
Os programas PL/I podem ser escritos com um mínimo de duplicação de código,
CHAMADAS excessivas e constrangimento ao usar IF-THEN-ELSE, simples
e instruções iterativas DO e ON no lugar de GO TO's.
o loop DO-WHILE, onde a condição WHILE é um valor verdade transformado
desligado dentro do loop no momento adequado, é uma maneira conveniente de lidar
lógica de controle típica que exige GO TO's. Por exemplo, um programa.
que lê dados, faz um cálculo, imprime resultados, depois lê dados e
assim por diante, enquanto os dados ainda precisam ser lidos, podem ser organizados como um único
grupo DO-WHILE, precedido por uma instrução ON ENDFILE para transformar o
WHILE condição para falsa.
da mesma forma, IF-THEN-ELSE, onde as cláusulas THEN e ELSE
podem ser grupos DO ou blocos BEGIN, podem ser usados ​​em várias combinações
para eliminar GO TO's As condições IF para ramificação devem ser feitas com frequência.
ser, mas geralmente reorganizando essas condições de ramificação
adiciona clareza ao programa e controla a simplicidade por si só.
Os blocos BEGIN podem ser usados ​​para lidar com condições de interrupção de maneira conveniente.
As descobertas anteriores são empíricas. Podem até não ser óbvias.
se teoremas formais estivessem disponíveis, esses GO TO's poderiam ser eliminados
na programação diária de PL/I sem que seja excessivamente estranho ou
redundante, mas alguma experiência e tentativa logo descobrirão o fato de que isso é verdade.
é bastante fácil de fazer; na verdade, o mais difícil é simplesmente decidir fazê-lo;
faça isso em primeiro lugar.
Existem, no entanto, razões muito mais profundas do que o estilo de programação
ou gosto por dispensar GO TO's na programação em um Ian moderno- ·
Nenhuma instrução em programação embaralha tão bem a sintaxe e a semântica.
como “GO TO LL” é fácil identificar sua sintática;
digite como uma instrução GO TO, mas o "LL" é um valor que permite o
lógica de controle da instrução para levar a qualquer lugar. Cinco razões pelas quais GO TO's.
não são boas práticas em PL/I são explicadas.
1. A legibilidade dos programas que são escritos sem.
GO TO's podem ser lidos por outras pessoas de cima para baixo, sem a necessidade
qualquer ginástica mental ou façanhas de memória de curto prazo por parte do
leitores A única maneira de o controle sair da linha direta de código.
é por meio das instruções IF-THEN-ELSE, DO, CALL ou ON, cada uma das
que é facilmente compreendido e visualizado na leitura do código.
escrever sem GO TO's, quando BEGIN, DO grupos, IF-THEN-ELSE
declarações, e tais são recuadas de maneira uniforme e cada BEGIN
ou DO tem sua própria instrução END explícita, então se torna particularmente

fácil ver o fluxo de controle apenas pela forma tipográfica do
programa em si.
2. As complexidades da compilação Em um compilador que trata apenas.
com código estático e sem estrutura de bloco dinâmico ou ligação de variáveis,
o GO TO é excepcionalmente fácil de implementar. No entanto, em PL/I, o.
GO TO é uma das declarações mais difíceis de implementar na linguagem.
Quando o GO TO é fornecido, deve haver uma busca pelo rótulo
no bloco que contém o GO TO Se o rótulo for encontrado, este é o mais simples.
caso, e a ramificação pode ser feita diretamente, porém, se a etiqueta for.
não encontrado, então deve ser procurado no próximo bloco externo, se houver,
que inclui o bloco atual. Isso significa desfazer a ligação da variável.
e outras condições dinâmicas associadas ao bloco interno antecipadamente
de transferir para um rótulo fora dele. Se o rótulo não for encontrado nesse bloco,
a busca deve continuar em outros blocos externos, se houver, até que
bem-sucedido ou não. Se não for bem-sucedido, normalmente é necessário voltar.
no bloco interno para produzir diagnósticos apropriados ou outros
ação, conforme necessário. A complexidade de lidar com a instrução GO TO.
está em nítido contraste com o exigido para grupos DO ou IF-THEN-ELSE
instruções, que não envolvem blocos dinâmicos ou ligação de variáveis ​​em
eles mesmos.
3. As Simplicidades da Documentação. Um uso futuro do programa.
A sintaxe do maior benefício potencial está na organização automática de
arquivos de documentação e a geração de perguntas apropriadas sobre
estrutura e conteúdo do programa para os programadores de origem.
de GO TO's torna a semântica de controle do programa transparente
à sintaxe, para que a estrutura dos arquivos de documentação e a interrogação
dos programadores sobre seus programas tornam-se correspondentemente
mais simples.
4. A Otimização do Código GO TO-Free.
código de máquina dos compiladores sempre começa com a determinação de
blocos básicos, ou seja, blocos de código linear no programa a ser executado,
e o gráfico de controle direcionado que conecta esses blocos básicos.
O gráfico de controle direcionado pode ser arbitrariamente complexo e pode tributar
qualquer análise de otimização Em contraste, um programa PL/I sem GO TO.
tem a propriedade de que seus blocos básicos agora são transparentes para
a sintaxe, pois os blocos básicos são segmentos tipográficos de código, delimitados
por instruções IF, BEGIN, DO e ON Por exemplo, durante a execução.
atinge uma instrução IF, sabe-se nesse ponto que a execução
irá para a unidade THEN ou para a unidade ELSE e em nenhum outro lugar.
Assim, por exemplo, uma estratégia de carregamento de registradores deveria carregar ou os registradores
da unidade THEN ou da unidade ELSE, mas nunca um pouco de cada.

30 PRODUTIVIDADE DE SOFTWARE
5. O carregamento e a execução do código GO TO-Free quando o.
blocos básicos e outros segmentos de programas executáveis ​​são transparentes para
a sintaxe, então torna-se possível o controle de carregamento e execução
programas para alocar núcleo e trazer código com base em sintaxe
estrutura Por exemplo, o núcleo pode ser alocado para grupos DO, BEGIN.
blocos, e assim por diante, em vez de simplesmente para um determinado número de bytes de
código de máquina.
Da mesma forma que os GO TO's podem ser eliminados, também se pode
elimine instruções RETURN com o controle sempre passando pelo
declaração END final de um procedimento em PL/I Em procedimentos que não possuem.
parâmetros e não declara variáveis ​​(por exemplo, uma que esteja incluída
em outro procedimento) é possível substituir a instrução PROCEDURE
por uma instrução DO e incluir a instrução DO resultante em linha
(substitua a CALL do procedimento pelo processo macro ou %INCLUDE
declaração) com o mesmo efeito computacional Como resultado, um.
tem uma maneira de manter um "sistema de design" altamente modularizado com
vários recursos para manutenção e depuração e, em seguida, de conversão
isso automaticamente em uma "produção" monolítica, mas de execução mais rápida
sistema."
O que precede é uma possibilidade realista devido à forma como a programação
modularidade geralmente acontece. É frequente na programação isso.
os procedimentos se enquadram em uma de duas classes distintas. A primeira classe é uma em.
qual uma ação comum é executada muitas vezes no decorrer de um programa,
por exemplo, uma rotina do SINE, e o objetivo é fornecer o
código apenas uma vez. É natural nesta classe passar parâmetros explicitamente.
e tornar a sub-rotina completamente independente de quaisquer outros dados em
o programa chamador. Uma segunda classe surge do desejo de um programador.
alcançar modularidade geral em um sistema e identificar certos
atividades do sistema para sua própria conveniência como procedimentos separados.
Mas é típico que a comunicação entre tais procedimentos e o
programa de chamada é mais amplo, não necessariamente através de parâmetros, mas mais
provavelmente através de dados externos ou dados incluídos. Também é comum que tal aconteça.
um procedimento não é chamado tantas vezes, mas muitas vezes apenas uma vez, ou em
na maioria das vezes, é esta segunda categoria que se presta ao que precede.
tratamento e permite a eliminação do processamento de prólogo/epílogo
através de instruções DO in-line.

O projeto de elaboração de um tesauro como auxílio no processamento e pesquisa
informações de arquivos de jornais foram realizadas como parte de um esforço de
O New York Times para coordenar todas as suas instalações de informação cresceu.
dos preparativos para a aplicação da tecnologia informática ao
produção do The New York Times Index O vocabulário e a estrutura.
do Thesaurus baseiam-se, portanto, em grande parte nos do Índice, mas
incluem muitos termos adicionais do arquivo de assunto do The Times
recorte "necrotério" e do catálogo de arquivos verticais do The Times
Biblioteca de Referência Editorial.
Os seguintes trabalhos foram consultados na concepção do formato do
Thesaurus: The ASTIA Thesaurus of Descriptors, 2ª edição, dezembro,
1962; o Manual do Departamento de Defesa para a Construção de um Tesauro Técnico,
Projeto LEX, Escritório de Pesquisa Naval, abril de 1966 e os Engenheiros;
Guia do Conselho Conjunto para Indexação de Fontes e Resumo do
Literatura de Engenharia, fevereiro de 1967. Os títulos de assunto usados ​​no
Catálogo de Dicionário da Biblioteca do Congresso, 7ª edição, 1966, foi consultado
na resolução de certos problemas de terminologia.
O trabalho é um esforço cooperativo da equipe do The New York
Times Index sob a direção geral do Dr. John Rothman, editor.
A enorme tarefa de compilar e anotar as entradas foi realizada por ·
os seguintes funcionários:
Robert A. Barzilay, coordenador
Marvin M. Aledort
William F. Marshall
Robert S. Olsen
Daniel Pinzow
Susan L. Pinzow
George D. Trento
O trabalho de edição final foi compartilhado pelo Dr. Rothman e Thomas R. Royston,
editor assistente.
A programação e as operações do computador foram feitas pela Central
Media Bureau, Inc., de Nova York.
© 1969 pela The New York Times Company. Reimpresso com permissão.

Sobre a segunda edição
Poucos meses após a publicação do Thesaurus, o suficiente
correções e acréscimos se acumularam para tornar aconselhável a publicação
uma revisão completa em vez de páginas individuais com alterações originalmente
planejado.
Ao todo, quase mil alterações foram feitas até o momento em que este
A Segunda Edição estava pronta para sua execução final no computador. Muitos deles estavam.
com base nas sugestões recebidas dos usuários do Thesaurus.
O formato físico também foi melhorado. Esta edição é impressa.
em papel mais pesado, que virará mais facilmente e será mais resistente a
rasgando. Além disso, títulos de continuação foram adicionados quando necessário.
O interesse ativo dos usuários do Thesaurus ajudou a tornar este novo
edição uma ferramenta de referência mais útil Seus comentários serão sempre bem-vindos.
e sinceramente apreciado.
Introdução
A palavra "thesaurus" deriva de uma palavra grega que significa "tesouro".
Aplicado ao dicionário convencional de sinônimos e antônimos,
como o de Roget, é muito adequado; tal dicionário de sinônimos é de fato um tesouro,
mostrando a riqueza, a plenitude e a diversidade da língua.
O tipo de tesauro que evoluiu nas últimas duas décadas
no campo do processamento e recuperação de informações não é um tesouro, então
tanto quanto a chave para um. As riquezas estão em um arquivo de informações – uma coleção.
de livros ou panfletos ou relatórios ou fotografias ou jornais e
o tesauro é um meio para sua exploração.
kind é um dispositivo para ordenar e controlar o arquivo, para que novos itens possam
ser adicionados consistentemente aos itens relacionados e para que todos os itens relevantes sejam
tornado fácil e rapidamente acessível.
O Thesaurus de Descritores do New York Times é um conjunto estruturado
vocabulário de termos destinados a orientar especialistas em informação no processamento
e organização de materiais de jornais e outras obras que tratam
com eventos atuais e assuntos públicos, e para orientar os usuários na busca de coleções
de tais materiais. Porque cobre a mesma grande variedade de assuntos.
tão importante quanto a imprensa diária, será uma ferramenta valiosa, acreditamos, não só
para hemerotecas, mas também para bibliotecas de referência geral, para
instituições, para agências governamentais, para empresas e finanças
organizações - em suma, para qualquer organização que coleta, armazena e usa
informações sobre os acontecimentos de hoje e de ontem.

O Thesaurus consiste em termos (descritores), em uma única ordem alfabética
sequência, que denota os diversos assuntos que podem ser encontrados em
a coleção. Para cada descritor, alguns ou todos os dados a seguir são
dado, na ordem indicada:
1. Termos de qualificação
2. Notas de Escopo
3. Referências "Ver" ou "Ver também" (listadas em ordem alfabética)
4. Referências "Consulte de" (listadas em ordem alfabética)
5. Subtítulos (listados em ordem alfabética).
Eles são projetados para definir descritores e correlacioná-los com um
outro.
Uma página de modelo aparece na página 35. O restante da introdução
explica detalhadamente os vários recursos do Thesaurus e discute
os principais princípios de organização de tal arquivo de informações.
algumas diretrizes gerais para certos tipos de material (por exemplo,
nomes estrangeiros e nomes de empresas) que não são cobertos item por item
no próprio Thesaurus Um breve índice do conteúdo da introdução.
segue:
1.Descritores
Os descritores são principalmente títulos de assuntos.
nomes, nomes de empresas, instituições e organizações, e outros
nomes próprios são incluídos apenas quando exigem o uso de qualificações
termos, notas de escopo, um padrão regular de referências cruzadas ou um
padrão de subdivisões.
O Thesaurus não inclui um descritor para cada indivíduo
membro de uma família haveria pouco propósito em listar cada item.
de móveis, todo tipo de arma, ou todo tipo de animal, vegetal ou
mineral são fornecidos para itens típicos e para aqueles que exigem.
qualquer manuseio especial ou incomum e estes servirão, espera-se, como modelos;
para quaisquer itens semelhantes que não estejam listados.
Sinônimos. Preferências entre termos sinônimos ou quase sinônimos.
são indicados pelas referências ''ver" (AVIAÇÃO. Ver Aeronáutica).
Termos não padrão e descritores recentes incluem termos.
atual nas notícias (como BLACK Power ou BRAIN Drain), embora
eles não são encontrados em catálogos ou dicionários de bibliotecas padrão.
não incluem nomes de marcas ou marcas registradas, termos técnicos normalmente não usados ​​em artigos de jornais, gírias e termos usados ​​exclusivamente
no jargão profissional. Quando coloquialismos, slogans ou moedas incomuns.
são usados ​​como descritores, geralmente aparecem entre aspas.
ou termos obsoletos são incluídos quando isso é considerado útil.
Abreviaturas e siglas são usadas como
descritores, geralmente com referências "ver" ao nome escrito (NATO.

Ver Organização do Tratado do Atlântico Norte). A prática pode ser revertida.
quando a abreviatura é muito mais conhecida e mais amplamente utilizada do que
o termo que representa (DICHLORo-Difenil-Tricloroetano. Ver DDT).
Nenhuma tentativa foi feita para compilar uma lista exaustiva de abreviaturas
e siglas.
Alfabetização Para dar uma descrição completa da alfabetização.
esquema seguido no Thesaurus iria muito além do escopo deste
introdução, mas a seguir estão as principais regras aplicadas na alfabetização;
entradas aqui e recomendado: ordem palavra por palavra em vez de letra por
carta (poluição do ar antes das abreviações de AIRLINES);
(OTAN entre NACIONAL e NATUREZA);
títulos (NEW York, State University of, antes de NEW York Airways);
homógrafos arquivados na ordem de pessoa, lugar, coisa (BROOKLYN,
William; BROOKLYN, NY; Ponte BROOKLYN) ou em ordem alfabética.
de termos qualificativos (MERCÚRIO · (Metal); MERCÚRIO (números do Planeta));
arquivado como se estivesse escrito (Século 20 como Século XX), exceto
onde a ordem numérica é claramente preferível (HENRY vn antes de HENRY
VIII); e termos compostos arquivados como duas palavras (REAL-Time antes).
REALISMO), exceto quando o primeiro componente é um prefixo (TRANS Mundo após
TRÂNSITO) ou um termo de clireção (SUL-Oeste) após SUL).
Especificidade Em geral, os arquivos de informação devem ser organizados de modo a
reunir todos os itens relevantes para uma determinada consulta e ainda permitir resposta imediata
acesso a qualquer item único e específico Neste Thesaurus, a escolha dos descritores.
e o seu grau de especificidade reflecte o vocabulário e o âmbito das actuais
escrita jornalística e procuram antecipar as necessidades dos usuários que consultam
arquivos de jornais, revistas, panfletos, relatórios e similares para informações.
Quando a quantidade de material sobre um assunto é grande (por exemplo,
AERONÁUTICA), são aconselháveis ​​descritores separados para aspectos específicos (AIRLINES,
AVIÕES, AEROPORTOS, etc.).
pequeno e não deve ser disperso, ou quando seus aspectos separados não são
Facilmente segregados, aconselha-se a utilização de um descritor mais abrangente.
(Por exemplo, o descritor PLAsTics é usado para todos os tipos de materiais plásticos,
uma vez que estes raramente são diferenciados nas histórias dos jornais, obviamente;
um descritor tão abrangente seria inadequado para a literatura de
química orgânica.)
Genéricos Porque os campos de assunto em eventos atuais tendem a se sobrepor.
amplamente e os termos são muitas vezes vagos e imprecisos em significado, uma hierarquia
ou a organização classificada dos descritores era impossível de alcançar.
possível, as relações hierárquicas entre os descritores são indicadas por

Ver Organização do Tratado do Atlântico Norte). A prática pode ser revertida.
quando a abreviatura é muito mais conhecida e mais amplamente utilizada do que
o termo que representa (DICHLORo-Difenil-Tricloroetano. Ver DDT).
Nenhuma tentativa foi feita para compilar uma lista exaustiva de abreviaturas
e siglas.
Alfabetização Para dar uma descrição completa da alfabetização.
esquema seguido no Thesaurus iria muito além do escopo deste
introdução, mas a seguir estão as principais regras aplicadas na alfabetização;
entradas aqui e recomendado: ordem palavra por palavra em vez de letra por
carta (poluição do ar antes das abreviações de AIRLINES);
(OTAN entre NACIONAL e NATUREZA);
títulos (NEW York, State University of, antes de NEW York Airways);
homógrafos arquivados na ordem de pessoa, lugar, coisa (BROOKLYN,
William; BROOKLYN, NY; Ponte BROOKLYN) ou em ordem alfabética.
de termos qualificativos (MERCÚRIO · (Metal); MERCÚRIO (números do Planeta));
arquivado como se estivesse escrito (Século 20 como Século XX), exceto
onde a ordem numérica é claramente preferível (HENRY vn antes de HENRY
VIII); e termos compostos arquivados como duas palavras (REAL-Time antes).
REALISMO), exceto quando o primeiro componente é um prefixo (TRANS Mundo após
TRÂNSITO) ou um termo de clireção (SUL-Oeste) após SUL).
Especificidade Em geral, os arquivos de informação devem ser organizados de modo a
reunir todos os itens relevantes para uma determinada consulta e ainda permitir resposta imediata
acesso a qualquer item único e específico Neste Thesaurus, a escolha dos descritores.
e o seu grau de especificidade reflecte o vocabulário e o âmbito das actuais
escrita jornalística e procuram antecipar as necessidades dos usuários que consultam
arquivos de jornais, revistas, panfletos, relatórios e similares para informações.
Quando a quantidade de material sobre um assunto é grande (por exemplo,
AERONÁUTICA), são aconselháveis ​​descritores separados para aspectos específicos (AIRLINES,
AVIÕES, AEROPORTOS, etc.).
pequeno e não deve ser disperso, ou quando seus aspectos separados não são
Facilmente segregados, aconselha-se a utilização de um descritor mais abrangente.
(Por exemplo, o descritor PLAsTics é usado para todos os tipos de materiais plásticos,
uma vez que estes raramente são diferenciados nas histórias dos jornais, obviamente;
um descritor tão abrangente seria inadequado para a literatura de
química orgânica.)
Genéricos Porque os campos de assunto em eventos atuais tendem a se sobrepor.
amplamente e os termos são muitas vezes vagos e imprecisos em significado, uma hierarquia
ou a organização classificada dos descritores era impossível de alcançar.
possível, as relações hierárquicas entre os descritores são indicadas por

por meio de notações de "termo mais amplo" (BT) e "termo mais restrito" (NT) em
referências cruzadas.
Termos geográficos versus termos de assunto. O problema de organizar um
arquivo por assunto ou por local é uma das tarefas mais difíceis enfrentadas por um bibliotecário
(HABITAÇÃO-Nova York ou NOVA York-Habitação?).
em arquivos de coordenadas mecanizadas, o esforço e as despesas necessárias para completar
a duplicação é proibitiva e a escolha entre as duas abordagens
deve ser feita. Nossa preferência pela abordagem do assunto se reflete no
Thesaurus Baseia-se no fato de que a maioria dos desenvolvimentos de notícias são regionais.
em vez de um significado exclusivamente local.
as notícias econômicas tratam de amplas áreas geográficas em todo o mundo;
mundo têm tráfego, poluição do ar, abastecimento de água e moradias em favelas semelhantes
problemas e assim por diante. Portanto, termos geográficos são usados ​​principalmente para fins gerais;
descrições e para material geral sobre economia, política, defesas,
população, história e costumes de uma área, em suma, pelo material;
muito amplo para caber nos descritores de assunto sobre material organizacional.
agências governamentais específicas (formação, orçamento, pessoal) são cobertas por
termos geográficos; suas atividades são cobertas por assuntos apropriados.
Nomes de agências governamentais (exceto agências internacionais e americanas)
agências interestaduais) não são fornecidas como descritores.
feito para fornecer uma lista de agências dos Estados Unidos (Federal) (como subtítulos
nos Estados Unidos), mas porque seus nomes mudam frequentemente e o
o status de alguns está agora em dúvida, a lista pode não estar completa e está sujeita
à revisão frequente.
Ordem das palavras em descritores de múltiplas palavras Para a maioria dos descritores de assuntos.
consistindo em mais de uma palavra, a ordem natural das palavras é preferida
e fornecido aqui (Poluição do AR; não POLUIÇÃO, Ar).
o sobrenome é sempre fornecido primeiro (JOHNSON, Lyndon Baines para estrangeiros).
nomes pessoais, a determinação do "sobrenome" correto costuma ser problemática;
veja a próxima seção para algumas regras gerais.
geralmente são invertidos e colocados em ordem alfabética no elemento de nome próprio
(FILIPINAS, República da; não REPÚBLICA das Filipinas).
os nomes devem estar na ordem natural das palavras (NATIONAL Broadcasting
Empresa; não Empresa de TRANSMISSÃO, Nacional) exceto quando inversão
de um elemento de nome próprio é claramente preferível (MACY, R. H., & Co.;
não R. H. Macy & Co.) (para casos duvidosos, as tabelas do mercado de ações muitas vezes
fornecem um guia útil). Nomes de escolas, universidades e museus.
geralmente deve estar na ordem natural das palavras (MASSACHUSETTS Institute of
Tecnologia), mas há algumas exceções óbvias (CHICAGO, Universidade
de; não UNIVERSIDADE de Chicago). Nomes de empresas, comércio, cívicos e profissionais).
associações, sindicatos, fundações e algumas outras organizações devem inverter o termo de assunto apropriado ou nome pessoal
(KANSAS City, Câmara de Comércio de; Agências de PUBLICIDADE, American
Associação de; União das Liberdades Civis, Associação Americana;
Internacional; SLOAN, Alfred P., Fundação).
usar inversões de ordem de palavras para reunir, na mesma ordem alfabética
localização, todas as organizações preocupadas com o mesmo assunto que utilizam o
descritor para este assunto como parte de seus nomes (por exemplo, todas as organizações
cujos nomes contêm a palavra EDUCAÇÃO).
não é óbvio, ou quando há uma escolha entre dois ou mais possíveis
inversões, as alternativas devem ser cobertas por referências "ver" ao preferido
versão (BROADCASTERS, Associação Nacional de Educação.
Emissoras Educacionais, Associação Nacional de). Algumas referências "ver"
deste tipo estão incluídos no Thesaurus, especialmente sob palavras comuns
como Americano, Geral ou Internacional.

Nomes estrangeiros. Nomes estrangeiros apresentam problemas tanto na determinação
a ordem correta das palavras e na determinação da ortografia adequada para transliterações.
Obras de referência autorizadas, como Who's Who, devem ser consultadas,
mas mesmo estes nem sempre estão de acordo e, claro,
cubra apenas um número limitado de nomes. Conselhos úteis podem ser obtidos.
de oficiais de informação de consulados estrangeiros, missões comerciais e delegações
às Nações Unidas e outras organizações internacionais.
As regras a seguir são oferecidas como um guia geral, mas não são exaustivas,
e há muitas exceções.
a. Nomes britânicos incluindo dois "sobrenomes" (Anthony Wedgwood
Benn) geralmente invertem a partir do segundo destes (BENN, Anthony Wedgwood).
b.Nomes espanhóis incluindo dois "sobrenomes" (Eduardo Frei Montalva) ·
geralmente invertem a partir do primeiro deles (FREI Montalva, Eduardo).
c. Nomes europeus e latino-americanos contendo um partitivo (de, di,
van, von) geralmente invertido do nome após o partitivo (GAULLE,
Charles de; HASSEL, Kai-Uwe von).
d. Nomes contendo um artigo definido geralmente são invertidos do artigo se
são franceses, italianos, espanhóis ou portugueses (LA Guardia, Ernesto de)
e do nome após o artigo se forem alemães ou holandeses
(HEIDE, Gottfried von der).
e. Nomes árabes contendo um partitivo (al, el, ben, ibn) geralmente invertidos
do nome seguindo o partitivo (ATTASSI, Fadhil al; BELLA, Ahmed
ben).
f. Nomes chineses, indochineses e coreanos invertidos a partir do último elemento
se eles foram ocidentalizados (PARK, Chung He), mas funcionam sem inversão se
não (MAO Tse-tung; NGUYEN Cao Ky (se tais nomes se tornarem populares).
conhecido de uma forma incorreta, como "Premier Ky" em vez de "Premier Nguyen Cao Ky", as referências "ver" apropriadas devem ser executadas a partir do
forma incorreta para a forma correta.)
g. Quando nomes estrangeiros puderem ser transliterados de diversas maneiras,
a transliteração preferida deve ser determinada, se possível, e "ver"
referências a ele devem ser executadas a partir de transliterações alternativas.
exemplos mais comuns são os seguintes: Em nomes árabes, use ai em vez disso
de ei (FAISAL, não FEISAL) e use kh em vez de q como primeira letra
(KHALIDI, não QALIDI). Em nomes russos, use ch em vez de tch ou tsch).
(CHERNISHEV, não TCHERNISHEV ou TSCHERNISHEV) e use V em vez de
ff como a última letra (suvoRov, não suvoROFF). Em nomes gregos, use kin em vez disso.
de C ou ch como letra inicial (KARAMANLIS, não CARAMANLIS; KRYSOSTOMOS,
não CHRYSOSTOMos). No entanto, nomes para os quais a alternativa
a transliteração está bem estabelecida (TCHAIKOVSKY, PROKOFIEFF, CONSTANTINE)
devem ser mantidos assim.
Divisões e subsidiárias da corporação A questão de estabelecer ou não.
descritores separados para divisões corporativas e subsidiárias, ou para
transportar material sobre eles sob o nome da empresa controladora, posa
outro grande problema. Em geral, devem ser estabelecidos descritores separados.
para subsidiárias que emitem ações próprias, têm nomes bem conhecidos
distintos daqueles da empresa-mãe, ou de outra forma ter um
identidade (Divisão CHEVROLET da General Motors Corp.; IBM World Trade
Corp.), e então a controladora deverá estar vinculada à subsidiária
por uma referência “ver também” Quando as subsidiárias não possuem uma referência claramente distinta.
identidade, é aconselhável levar material sobre eles sob o nome
da controladora, especialmente quando o material não é consistentemente
identificá-los pelo nome. Por exemplo, é virtualmente impossível usar separados.
descritores para as unidades operacionais no exterior dos principais
empresas petrolíferas. Estas são por vezes referidas pelos seus próprios nomes (ESSO).
Libya Ltd.) e às vezes apenas como unidades da empresa-mãe (Standard
petróleo da afiliada líbia de Nova Jersey), e pode não haver maneira de
determinar se a mesma unidade ou duas unidades diferentes estão envolvidas.
quando a distinção puder ser feita, talvez seja melhor manter o material sobre
a empresa reunida sob um único nome do que dispersá-la entre vários
nomes, alguns dos quais podem ser bastante desconhecidos para os usuários.
Denominações Religiosas Quando a quantidade de material é relativamente.
pequeno, material sobre filiais, órgãos regionais e outras agências de uma denominação
é transportado sob o nome coletivo da denominação, e
não em descritores separados (por exemplo: Igreja Ortodoxa Grega.
sob Igrejas ORTODOXAS;
Igrejas.) Congregações e paróquias individuais, se não intersectárias,
também deve ser incluído sob o nome da denominação, em vez de receberam descritores separados, mas os nomes de igrejas bem conhecidas (como;
Catedral de São Patrício em Nova York) deve ser coberto por referências "ver"
ao nome da denominação.
2. Termos de qualificação
Termos qualificativos são expressões entre parênteses fornecidas após certos descritores
para distinguir entre homógrafos. Por exemplo:
MERCÚRIO (Metal)
MERCÚRIO (Planeta)
Termos qualificativos também podem ser usados ​​para resolver outras ambigüidades contextuais
em alguns descritores. Por exemplo:
QUINTA Emenda (Constituição dos EUA)
3. Notas de Escopo
As notas de escopo são notas que aparecem após certos descritores para definir ou
descrever a gama de assuntos abrangidos pelo descritor.
exemplo:
Dependência, abuso e trânsito de drogas.
Nota: O material aqui inclui narcóticos, estimulantes, drogas alucinatórias e
outros considerados socialmente indesejáveis.
As notas de escopo podem ser usadas em subtítulos para o mesmo propósito, e
também pode ser usado para descrever o sistema de subdivisão do material sob
determinados descritores.
4. Referências cruzadas
As referências cruzadas servem como substitutos para múltiplas entradas e como guias
entre descritores que abrangem material relacionado Eles também são usados ​​em.
subtítulos conforme necessário.
Ao contrário da prática habitual da biblioteca, as referências cruzadas não
geralmente estabelecido entre descritores relacionados que são imediatamente
adjacente no alfabeto (por exemplo, não há referência cruzada de.
Veículos BLINDADOS para Serviços de Automóveis BLINDADOS.) Considerou-se que a conexão entre esses descritores adjacentes é evidente e que as referências cruzadas
haveria supérfluo.
Consulte Referências. "Ver" guia de referências de descritores não usados ​​para "entradas"
no sistema para descritores equivalentes usados ​​preferencialmente.
usado principalmente entre sinônimos (AVIAÇÃO. Ver Aeronáutica), e quando
o material indicado por um descritor é incluído em outro (ORCHESTRAS.
Veja Música).
Veja também Referências. Guia de referências "Veja também" dos descritores usados.
para certas "entradas" no sistema para outros descritores onde material relacionado
é inserido. Eles podem levar de termos mais gerais e mais amplos a termos mais amplos.
termos específicos e mais restritos (Imóveis. Veja também Habitação), ou vice-versa
(TEATRO. Veja também Divertimentos). Eles também podem partir de um descritor.
para outro no mesmo nível hierárquico que pode abranger
tópicos ou diferentes aspectos do mesmo tópico (ESTRADAS. Veja também Tráfego).
Consulte a partir de Referências. As referências "Consulte de" são o inverso de "ver"
e referências "veja também" Mostram todos os descritores vinculados por "veja".
e “ver também” referências ao descritor consultado (AERONÁUTICA. Consulte
da Aviação).
Referências cruzadas qualificadas Numerosas "ver", "ver também" e "referir de"
referências são seguidas por expressões entre parênteses que definem o particular
aspecto de um tópico coberto pela referência cruzada, como em CÃES. Veja também Cegueira.
e os Cegos (para cães-guia).
Notações hierárquicas Muitas referências cruzadas são anotadas para mostrar.
relações hierárquicas, como segue: (NT) quando a referência parte de
um termo mais amplo para um termo mais restrito (Imóveis. Veja também Habitação (BT));
quando a referência leva de um termo mais restrito para um termo mais amplo (TEATRO.
Veja também Divertimentos); e (RT) quando a referência deriva de
um termo para outro no mesmo nível hierárquico para material relacionado
(ESTRADAS. Veja também Tráfego). O uso dessas notações não pôde ser sustentado.
em todo o Thesaurus, no entanto, porque os campos temáticos
cobertos em jornais e outras publicações sobre eventos atuais tendem a
se sobrepõem amplamente e o vocabulário é extremamente variado, complexo e muitas vezes
portanto, nem sempre poderiam existir relações imprecisas e hierárquicas;
determinado (Por exemplo, CRIME e Criminosos. Veja também Tribunais - quais.
destes é o descritor mais restrito e qual é o mais amplo?) Em muitos casos,
a questão da hierarquia era discutível e a escolha foi finalmente governada
pelo descritor a partir do qual a referência cruzada é executada.
HABITAÇÃO. Veja também Zoneamento anotado (NT), embora zoneamento encompassa por todos os tipos de usos do solo, pois a referência cruzada tem como objetivo
cobrir um aspecto específico da habitação, nomeadamente o zoneamento residencial.) Além disso, não
foi feita uma tentativa de incluir referências cruzadas de todos os descritores específicos
em um determinado campo temático ao descritor amplo que denota o campo
como um todo. (Por exemplo, não foram feitas referências cruzadas de prazo mais amplo.
feito a partir de muitos produtos agrícolas específicos, como os GRÃOS, até o
descritor AGRICULTURA e Produtos Agrícolas.)
5.Subtítulos
O Thesaurus lista subtítulos sugeridos para descritores que abrangem
uma grande quantidade de material onde uma categoria de subtítulos consiste em.
nomes de componentes individuais (por exemplo, nomes de países, de
estados, ou de filmes), apenas a categoria é dada, não uma inclusiva
lista de todos os componentes.
Com poucas exceções, os subtítulos são limitados a duas posições hierárquicas.
níveis (subtítulos principais e sub-subtítulos).
geralmente não é aconselhável; torna a estrutura do cordão muito complexa e excessiva;
difícil de pesquisar. Quando surge a necessidade de subdivisão adicional, geralmente é
uma indicação de que o título principal (descritor) é muito amplo, e
que, em vez de subdividi-lo ainda mais, descritores mais restritos deveriam ser
estabelecido.
A maioria dos descritores presta-se tanto a áreas geográficas como temáticas.
No entanto, geralmente não é aconselhável misturar subdivisões geográficas e geográficas.
subtítulos de assunto no mesmo nível (se em EDUCAÇÃO, por exemplo,
tanto Elementar quanto Califórnia são usados ​​como subtítulos no mesmo nível,
qual seria usado para material nas escolas primárias da Califórnia?).
A natureza do material e os interesses dos usuários devem
determinar se as subdivisões devem ser geográficas ou por assunto.
Subtítulos podem aparecer com termos qualificados, notas de escopo e
referências cruzadas, assim como descritores.
6. Orientação e Formato
Como o Thesaurus é baseado no vocabulário usado no processamento de informações
do The New York Times, reflete necessariamente o fato de que
The Times é publicado em Nova York. Assim, os descritores NOVA York.
A cidade e o estado de NOVA York têm subtítulos não fornecidos para outras cidades e
estados, e a cidade de Nova York e o estado de Nova York são usados ​​como subtítulos
sob muitos descritores que não possuem outros nomes de cidades e estados como subtítulos.
Da mesma forma, os descritores de instituições locais (como a Universidade Columbia ou o New York Times) são mostrados com uma estrutura detalhada, não
dado para instituições semelhantes em outros lugares No entanto, a estrutura delineada.
sob a cidade de Nova York, o estado de Nova York e algumas instituições locais podem
ser facilmente aplicado a outras cidades e estados e suas instituições no processamento
jornais locais e outras coleções lá.
Neste contexto, deve salientar-se também que o relatório detalhado
a estrutura mostrada na Eleição PRESIDENCIAL de 1968 aplica-se à eleição
em qualquer ano de eleição presidencial em curso.
mostrado sob JOHNSON, Lyndon Baines, aplica-se a qualquer presidente e pode
ser aplicado, com as modificações necessárias, a governadores, prefeitos, chefes
de governos estrangeiros e outras figuras proeminentes.
Geralmente, o Thesaurus é concebido, como indica o seu subtítulo, como um
guia no processamento e pesquisa de materiais, e não como um corpo de firmas
e regras estritas devem ser observadas.
feitos conforme a natureza dos materiais processados ​​e os interesses de seus
os usuários exigem. No processamento de jornais e outros materiais de eventos atuais.
para recuperação de informações, a flexibilidade é obrigatória e, portanto, frequente
estão previstas alterações no Thesaurus. Essas alterações podem ser iniciadas.
por nós, ou podem ser feitos por usuários individuais para lidar com suas necessidades específicas
problemas e atender às suas necessidades específicas.
É por estas razões que o Thesaurus foi publicado em folhas soltas
As páginas pares foram deixadas em branco para permitir aos usuários.
escreva suas próprias notas à vontade, em frente ao material apropriado do Thesaurus.
As alterações iniciadas por nós estarão em páginas individuais a serem substituídas ou
inseridas O formato de folha solta permite aos usuários inserir folhas separadas.
com seu próprio material conforme desejado.

Um objetivo importante do New York Times está contido na página 13
da Introdução ao Tesauro de Descritores do The New York Times.
Geralmente, o Thesaurus pretende, como diz o seu subtítulo, ser um guia
no processamento e pesquisa de materiais, e não como um corpo de empresas
e regras estritas devem ser desviadas das diretrizes aqui estabelecidas.
ser feita conforme a natureza dos materiais processados ​​e os interesses de
seus usuários exigem no processamento de jornais e outros eventos atuais.
materiais para recuperação de informações, a flexibilidade é obrigatória e, portanto,
estão previstas mudanças frequentes no Thesaurus.
podem ser iniciados por nós ou podem ser feitos por usuários individuais para
lidar com seus problemas específicos e atender às suas necessidades específicas.
Para fornecer o tipo de flexibilidade desejada em arquivos on-line,
é importante que os programas de computador não se baseiem num conjunto de
suposição implícita ou oculta sobre como o Thesaurus é tratado em
a atualidade. Por esta razão, uma descrição estrutural do Thesaurus.
é desenvolvido aqui para promover flexibilidade e crescimento futuros através de um
interface compreendida entre os designers do Thesaurus e
os programadores.
A definição final de um tesauro, quando seguida por todos os
definições intermediárias abaixo, reduz a uma linguagem natural (gigantesca)
sequência, acessível e em ordem alfabética com base em certas subsequências
-Descritores, Veja também Referências, e assim por diante.
Como esta grande cadeia de caracteres deve ser formatada e armazenada em um
sistema de computação (com diretórios auxiliares, ponteiros, contagens, separadores
personagens e assim por diante) é uma questão de estratégia e tática de programação.
É uma questão importante, mas os criadores do Thesaurus não precisam de se preocupar
emaranhados com isso, eles só precisam se preocupar com o Thesaurus.
em sua forma externa, como uma sequência estruturada de linguagem natural que pode
ser consultado e adicionado ou excluído, com certas referências cruzadas automáticas
instalações assim realizadas.
Assim, a questão importante para o designer é “Esta é a estrutura
quero para o Thesaurus?" em contraste com questões de conteúdo, critérios
para colocação de conteúdo, e tal. O objetivo da descrição a seguir.
é permitir que o designer examine essa questão com confiança e
precisão As ferramentas podem parecer um pouco formais e formidáveis ​​à primeira vista, mas acredita-se que a preocupação desaparecerá com um pouco de familiaridade.
O objetivo não é obscurecer, mas sim tornar as análises mais precisas e abrangentes.
para que o designer possa ver a estrutura do Thesaurus em si.
Neste contexto, a descrição desenvolvida abaixo é um tanto
mais geral do que a estrutura atual do Thesaurus. Isso acontece com frequência.
que a simplificação e unificação desejável para o processamento automático
vêm apenas com um certo grau de generalização e isso acontece frequentemente.
que mais flexibilidade, e não menos, acompanha tal generalização.
Nem toda a flexibilidade inerente à estrutura de arquivos proposta é utilizada
nas atividades atuais do Thesaurus, e nunca se espera que tudo isso
ser usado. Mas está lá para ser usado e, mais importante, é conhecido por estar lá.
A Descrição Estrutural
A descrição estrutural do Thesaurus será dada através de uma série
de definições sintáticas (ou "equações sintáticas"), cada uma das quais se expande
um termo do Thesaurus (uma forma genérica para uma parte do Thesaurus) que é
sendo definido em um ou mais padrões usando métodos mais simples e básicos
Qualquer termo assim definido é, em última análise, expandido para natural.
texto do idioma, que é o primitivo não especificado para o Thesaurus.
observado, a descrição se preocupa apenas com a estrutura do Thesaurus
e não com seu conteúdo.
Os termos sintáticos, ou entidades, usados ​​na descrição são fornecidos
na Tabela 6-1, primeiro como termos de linguagem natural e depois de uma forma simbólica mais breve
formulário que será usado por conveniência posteriormente. Observe o Thesaurus.
os termos estão em três categorias. Primeiro, existe um termo primitivo de.
pouco o Thesaurus é finalmente construído, o que é simplesmente natural
texto do idioma. Todos os termos subsequentes são eventualmente decompostos neste.
texto em linguagem natural; isso é responsabilidade dos designers do
Thesaurus Em segundo lugar, há um conjunto de termos usados ​​pelo The New York Times.
que se destinam a ser usados ​​na descrição estrutural exatamente como o
Pessoal do Times os significa. Finalmente, há um conjunto de termos adicionais.
(que será definido por equações sintáticas), que servem como intermediários
entidades sintáticas entre alguns dos termos de nível inferior e superior usados
pelo The New York Times Essas entidades intermediárias são, de fato, conhecidas.
em diversas formas, também ao pessoal do Times;
mais rigorosamente é melhorar a precisão possível em relação aos
descrições de linguagem.
As equações sintáticas das descrições são fornecidas (e numeradas)
na Tabela 6-2, e uma breve explicação é necessária Os termos sintáticos, ou entidades, usados ​​na descrição são fornecidos
na Tabela 6-1, primeiro como termos de linguagem natural e depois de uma forma simbólica mais breve
formulário que será usado por conveniência posteriormente. Observe o Thesaurus.
os termos estão em três categorias. Primeiro, existe um termo primitivo de.
pouco o Thesaurus é finalmente construído, o que é simplesmente natural
texto do idioma. Todos os termos subsequentes são eventualmente decompostos neste.
texto em linguagem natural; isso é responsabilidade dos designers do
Thesaurus Em segundo lugar, há um conjunto de termos usados ​​pelo The New York Times.
que se destinam a ser usados ​​na descrição estrutural exatamente como o
Pessoal do Times os significa. Finalmente, há um conjunto de termos adicionais.
(que será definido por equações sintáticas), que servem como intermediários
entidades sintáticas entre alguns dos termos de nível inferior e superior usados
pelo The New York Times Essas entidades intermediárias são, de fato, conhecidas.
em diversas formas, também ao pessoal do Times;
mais rigorosamente é melhorar a precisão possível em relação aos
descrições de linguagem.
As equações sintáticas das descrições são fornecidas (e numeradas)
na Tabela 6-2, e uma breve explicação é necessária para que
as equações da Tabela 6-2 podem ser compreendidas. Cada equação consiste em um “lado esquerdo” e um “lado direito”.
a entidade sintática sendo definida por essa equação.
é a sua definição.
Existem duas maneiras principais pelas quais uma definição é feita na Tabela
6-2. A primeira forma é através de uma definição informal, dada em linguagem natural.
entre asteriscos Este tipo de definição pode ser usado quando não.
ambigüidades ou mal-entendidos são prováveis. Em qualquer caso, pelo menos um termo é provável.
(um termo primitivo como o primeiro na Tabela 6-2) deve ser definido em
alguma forma informal, caso contrário todo o sistema de definições será circular.
O segundo método de definição é por fórmula sintática, que expressa
um ou mais padrões possíveis de termos, usando alguma notação, que podemos
descreva a seguir.
Observe que cada entidade sintática na Tabela 6-1 começa e termina com
um colchete angular (<, >), que parece incluir um acrônimo significativo
ou palavra. Na verdade, toda a string, incluindo os colchetes angulares, deve ser.
considerado como um símbolo único, e a sequência interna de caracteres é de
apenas significado mnemônico Além dos colchetes angulares (que são ·.
usado para construir símbolos de múltiplos caracteres), também usamos como
metasímbolos é igual a ( =), vírgula (,), colchetes ( [, ]) e colchetes ( {, } ) .
definição de equação sintática A vírgula é usada apenas para separar.
itens em uma lista Os colchetes são usados ​​para delimitar um item;
significa que a aparência daquele item é opcional, ou seja, pode ou pode
não aparecem no padrão dado pela fórmula.
incluir uma lista e significa que exatamente um item da lista deve ser usado
no padrão. Texto em linguagem natural aparecendo sozinho, ou seja, não.
entre colchetes angulares ou asteriscos, representa por si só. Por razões que são.
aparente com um pouco de reflexão, tais ocorrências de linguagem natural são
chamadas constantes sintáticas (A expressão "Veja também" é frequentemente recorrente.
constante sintática no Thesaurus, por exemplo.) A fórmula
do lado direito de uma equação sintática pode, portanto, variar, pelo uso de
colchetes e colchetes, em diversas formas;
equação é que a entidade sintática no lado esquerdo é definida como qualquer
e todos os formulários possíveis do lado direito.
Para ilustrar essas ideias, observe que a Equação 4 da Tabela 6-2 afirma
que <SN> (ou seja, Nota de Escopo) consiste em cinco caracteres, Nota:, seguidos
pela entidade sintática, <TEXT>, que pela Equação 1 é simplesmente
texto em linguagem natural. Ou seja, a Equação 4 configura a constante sintática.
Nota:" como os cinco caracteres iniciais de uma Nota de Escopo, seguidos pelo
variável sintática <TEXT>, que representa qualquer texto (com sentido ou sem sentido)
desejado. As primeiras quatro equações sintáticas podem ser traduzidas de volta.
nas descrições da referência rapidamente. Observe que <QT>.
(Termo de Qualificação) é colocado entre parênteses na Equação 3. A Equação 5 ilustra o uso de colchetes A entidade <HN> (Notação Hierárquica).
é uma das três sequências de quatro caracteres "(BT)", "(NT)" ou "(RT)."
Apenas para verificar a compreensão, observe que uma forma equivalente da Equação 5 é
<HN> = ({BT, NT, RT})
ou mesmo
<HN> = ({B,N,R}T).
A Tabela 6-2 é uma tabela de referência e não uma tabela de exposição.
suas virtudes são sua concisão e precisão na definição da estrutura do Thesaurus.
Mas as equações que levam à Equação 10, para <TESAURO>,
faça um pouco mais de exame e explicação, que veremos a seguir.
A motivação para fazê-lo é que, uma vez compreendida, a Tabela 6-2 é uma visão completa
e mapa oficial da estrutura do Thesaurus.

Mais na Tabela 6-2
A ideia que surge através das entidades de nível superior na Tabela 6-2, de
<TESAURO>, pode ser ilustrado examinando vários exemplos de um
<SAR>-a "Veja também a Referência."
a frase "Veja também", seguida por uma ou mais Referências aos Descritores.
Porém, junto com os Descritores pode ou não vir uma lista de
Itens <QT> (Termo de Qualificação), um <SN> (Nota de Escopo) e um <HN>
(Notação Hierárquica). Construímos essas possibilidades na Equação 13.
(usando a Equação 12 primeiro para definir uma lista de itens <QT>, em contraste com
um único <QT>). Agora com cada referência única definida pela Equação 13.
como <TE> usamos a Equação 14 para definir uma lista em ordem alfabética de tais referências,
nomeando-o <TEL> Além disso, já que algumas referências podem ser para não descritores.
("Veja também países estrangeiros"), também construímos uma lista em ordem alfabética
lista de tais referências, nomeando-a <TL> Agora, finalmente, podemos formar.
<SAR> na Equação 7, conforme a constante sintática "Veja também" seguiu
(opcionalmente) por uma lista de referências de descritores e/ou uma lista de referências não descritoras
referências.
Usamos a expansão (ou síntese) da Equação 7 para ilustrar
um processo semelhante para as Equações 6 e 8. Equação 9, definindo Subtítulos,
é um pouco mais complexo e usa o que é conhecido como "sintático"
recursão" em sua definição. Primeiro, definimos a estrutura possível sob
um "título principal" do Thesaurus como <TS> (Term Structure) na Equação
15. É um <TE>, já definido, seguido (todos opcionalmente) por
ou nenhum de <SR> ou -<SAR>, por <RFR> e por <SUBH> A seguir notamos que um Subtítulo pode ser definido desta forma se percebermos.
dois pontos cruciais:
1. As opções disponíveis incluem todas as possibilidades em Subtítulos, e
então alguns - podemos optar por ignorar as possibilidades adicionais se
nós por favor.
2. A relação de ser um subtítulo (para um título) pode ser relativa
em vez de absoluto, de modo que, por exemplo, um <SUBH> sob um
<SUBH> (isto é, em sua expansão sintática) é um (absoluto)
subsubtítulo.
Assim, o lado direito da Equação 9, que define <SUBH>,
quando ampliado pelas Equações 16 e 15, por sua vez, inclui um item
<SUBH>, que é a entidade que está sendo definida. Isso é chamado assim.
definição recursiva.
Em tópicos mais abstratos existem dificuldades teóricas inerentes
com definições recursivas, mas não há definições práticas aqui.
As equações 9, 15 e 16 dizem, juntas, que qualquer número de "subtítulos
aninhamentos" são possíveis na descrição estrutural - e este é um exemplo
da generalidade desta descrição Na prática, o usuário criará apenas.
um determinado número de tais aninhamentos.
terá o termo <SUBH> faltando no lado direito da Equação
15 (todo o termo [ <SUBH>] é opcional).
A Equação 9 (ou Equação 15) em um arquivo realizado sempre terminará.
Pode agora ser uma surpresa à primeira vista, mas ao definir
um <TSL> na Equação 16, originalmente concebido para ser a lista de
Estruturas de termos que podem estar contidas em um subtítulo, de fato temos
definiu o Thesaurus, e a Equação 10 apenas registra esse fato.
o número de caracteres e entradas pode ser de uma ordem completamente diferente
de magnitude em uma estrutura de termos típica (o apêndice de um descritor)
e todo o Thesaurus, mas a estrutura é idêntica, e isso é tudo que
estão definindo neste momento.
Acesso conversacional
O acesso ao Thesaurus em formato impresso é feito virando as páginas e a olho nu,
cantar a estrutura alfabética inerente à sua definição.
· e o olho representa um potente mecanismo de busca, desde que o material
· não é volumoso e nada mais deve ser feito com os resultados.
No acesso conversacional on-line, entretanto, devemos ser mais explícitos
e preciso na chamada de seções do Thesaurus, no máximo algumas linhas por vez, por meio de comandos explícitos em vez de virar a página implícita
e digitalização. Portanto, descrevemos aqui um sistema específico para conversação.
acesso.
O formato básico do acesso conversacional é "Solicitar e
Display." O usuário fará uma solicitação para alguma seção do Thesaurus,
e o sistema exibirá os resultados dessa solicitação.
seção solicitada ou então uma mensagem de erro, seja tratando do
formato da própria solicitação ou informando que a seção solicitada não poderia
ser localizado. O ponto de entrada básico no Thesaurus é através dos Descritores,
possivelmente especificado pelos Termos de Qualificação e possivelmente no Subtítulo
níveis no Thesaurus Se o Descritor não for um termo preferido,
sua solicitação resultará em uma exibição automática de uma lista Consulte Referência.
Foi localizado o descritor que é um termo preferencial, ele trará um display
contendo termos de qualificação, uma nota de escopo e uma notação hierárquica
na medida em que esses itens estão presentes, chamamos isso de "base".
Descritor." Agora, dado tal Descritor, o usuário pode solicitar acesso
a qualquer uma das três listas possivelmente associadas a ele: Veja também Referências,
a Referência das Referências e os Subtítulos Tendo solicitado um.
destas três listas, o usuário poderá então solicitar Referências ou Subtítulos
simplesmente pedindo o item "Próximo" da lista ou pedindo o
O próprio descritor A resposta de exibição à solicitação "Próximo" é a próxima.
Referência ou Subtítulo, se disponível. Uma Referência pode ser definida.
Descritor ou uma referência indefinida a uma categoria genérica de Descritores.
Se não restarem mais itens na lista (o usuário presumivelmente tendo
digitalizados anteriormente), a mensagem "Fim da lista" será exibida.
pode ser alterado de uma das três listas para qualquer uma das outras por um
solicitação simples em vez de "Próximo" ou por uma solicitação do Descritor.
O usuário que deseja acompanhar um Referenciado ou Subtítulo
Descritor (por exemplo, para examinar suas "Ver também Referências") pode fazer
uma solicitação de "Transferência", que substitui o Descritor base original pelo seu
Descritor Referenciado ou Subtítulo, e o acesso continua a partir deste último
conforme indicado anteriormente. Após uma ou mais solicitações de tal "Transferência",
pode ser feita uma solicitação de "Retorno", que substitui o Descritor base atual
pelo Descritor que o produziu por "Transferência".
de solicitações de "Transferência", um número igual de solicitações de "Devolução" será processado
(na ordem inversa) através do mesmo conjunto de Descritores, de volta ao
original.
As solicitações e exibições anteriores estão resumidas (e numeradas)
na forma de sintaxe na Tabela 6-3. Um exame da tabela será feito.
mostre como cada um dos comandos leva a uma exibição específica.
Normalmente, seria mostrado com a solicitação referente a novas informações.
esperava que certas informações fossem transferidas (como o
Descritor atualmente sendo usado como base, cuja lista de referências está abaixo  exame, e assim por diante), desde que a condição mantida durante o
·ersação.
Observe que a única variável sintática que pode ser usada em uma solicitação
é um <TERM> (um Descritor), seguido opcionalmente por um <QTL>
Lista de termos de qualificação). As variáveis ​​sintáticas exibidas são limitadas a
<TE> (extensão de prazo), <SR> (ver referências) e <TEXT> (para
=>referências enéricas); mas, é claro, apenas essas exibições permitem ao usuário
· percorrer qualquer parte e detalhe do Thesaurus desejado.
g solicitações e exibições são constantes sintáticas.
Ocabulário de itens de solicitação, todos menos um dos quais são constantes, representa
.:. meios simples e de fácil compreensão para acessar qualquer informação desejada
· o Tesauro 

Dicionário de sinônimos.
Criação e Manutenção do esaurus
·."e definir a criação e manutenção do Thesaurus em termos da sintaxe
_tidades da Tabela 6-1 acima do nível da Linguagem Natural primitiva
- ramal Ou seja, consideramos apenas a adição e exclusão de The inteiro-
- itens urus e não porções de texto A adição e exclusão de caracteres.
_;:: ers no texto que compõem um item de arquivo são considerados edição de texto em vez de
~ manutenção do esaurus neste contexto É reconhecido que a edição de texto.
_: uma facilidade futura desejável no processo geral de manutenção do Thesaurus,
e a presente ênfase reflecte apenas uma fase temporal da
-:erests.
O processo de criação do Thesaurus é simplesmente a construção de
_ <TSL> que deve ser definido como Thesaurus.
_ h um Thesaurus deve ser carregado fisicamente no armazenamento, com diretórios,
...=d assim por diante, é uma questão de programação não tratada aqui.) Por exemplo,
-r,e New York Times Thesaurus ojDescriptors, por definição e salvo desvios tipográficos ou lógicos das intenções de seus designers, é um
<TSL>.
O processo de manutenção do Thesaurus também é muito simples em
termos sintáticos. Uma adição ou exclusão do Thesaurus pode ser definida fornecendo-se
um local e uma entidade sintática que deve ser adicionada ou excluída.
podem ser dados nas solicitações de Acesso Conversacional, a saber,
Entrada <TERM> [ <QTL>]
Veja também
Consulte de
Subtítulo
Transferir
prescrever o destino da entidade sintática a ser adicionada ou o
entidade a ser excluída no caso de itens únicos, como uma Nota de Escopo.
ou uma Notação Hierárquica, adição significa substituição se tal
um item já está presente no caso de itens listados, como Veja ou Veja também.
Referências ou subtítulos, a adição é feita automaticamente em ordem alfabética
formulário No caso de exclusão, a exclusão de um Descritor exclui automaticamente.
todos os itens de arquivo acessados ​​por esse descritor também.

Ilustrações
Usamos a página modelo (página 35 do The New York Times Thesaurus -of
Descritores) para ilustrar concretamente as ideias anteriores, incluindo o
descrição estrutural, acesso conversacional e criação de Thesaurus e
manutenção.
Primeiro, considere o conteúdo da página modelo como um dicionário de sinônimos em miniatura.
Possui a estrutura de todo o Thesaurus do New York Times de
Descritores, só que com muito menos texto.
Lista) de exatamente 10 itens <TS> (Estrutura de Termo) em ordem alfabética,
que começa com Descritores:
Protetorado de ADEN
ADOÇÕES
ANÚNCIO
AMÉRICA
AMÉRICA
Controle de natalidade e paternidade planejada
Dicionário de sinônimos.
Criação e Manutenção do esaurus
·."e definir a criação e manutenção do Thesaurus em termos da sintaxe
_tidades da Tabela 6-1 acima do nível da Linguagem Natural primitiva
- ramal Ou seja, consideramos apenas a adição e exclusão de The inteiro-
- itens urus e não porções de texto A adição e exclusão de caracteres.
_;:: ers no texto que compõem um item de arquivo são considerados edição de texto em vez de
~ manutenção do esaurus neste contexto É reconhecido que a edição de texto.
_: uma facilidade futura desejável no processo geral de manutenção do Thesaurus,
e a presente ênfase reflecte apenas uma fase temporal da
-:erests.
O processo de criação do Thesaurus é simplesmente a construção de
_ <TSL> que deve ser definido como Thesaurus.
_ h um Thesaurus deve ser carregado fisicamente no armazenamento, com diretórios,
...=d assim por diante, é uma questão de programação não tratada aqui.) Por exemplo,
-r,e New York Times Thesaurus ojDescriptors, por definição e salvo desvios tipográficos ou lógicos das intenções de seus designers, é um
<TSL>.
O processo de manutenção do Thesaurus também é muito simples em
termos sintáticos. Uma adição ou exclusão do Thesaurus pode ser definida fornecendo-se
um local e uma entidade sintática que deve ser adicionada ou excluída.
podem ser dados nas solicitações de Acesso Conversacional, a saber,
Entrada <TERM> [ <QTL>]
Veja também
Consulte de
Subtítulo
Transferir
prescrever o destino da entidade sintática a ser adicionada ou o
entidade a ser excluída no caso de itens únicos, como uma Nota de Escopo.
ou uma Notação Hierárquica, adição significa substituição se tal
um item já está presente no caso de itens listados, como Veja ou Veja também.
Referências ou subtítulos, a adição é feita automaticamente em ordem alfabética
formulário No caso de exclusão, a exclusão de um Descritor exclui automaticamente.
todos os itens de arquivo acessados ​​por esse descritor também.

Ilustrações
Usamos a página modelo (página 35 do The New York Times Thesaurus -of
Descritores) para ilustrar concretamente as ideias anteriores, incluindo o
descrição estrutural, acesso conversacional e criação de Thesaurus e
manutenção.
Primeiro, considere o conteúdo da página modelo como um dicionário de sinônimos em miniatura.
Possui a estrutura de todo o Thesaurus do New York Times de
Descritores, só que com muito menos texto.
Lista) de exatamente 10 itens <TS> (Estrutura de Termo) em ordem alfabética,
que começa com Descritores:
Protetorado de ADEN
ADOÇÕES
ANÚNCIO
AMÉRICA
AMÉRICA
Controle de natalidade e paternidade planejada

Muçulmanos NEGROS
"Poder Negro"
LISTA NEGRA
(Observe que as Equações 10 e 16 da Tabela 6-2 expressam esse fato estrutural.)
A seguir, qualquer um desses <TS> consiste em um <TE> (Term Extension)
seguido opcionalmente por Referências e Subtítulos (Equação 15).
Alguns <TS> não possuem nenhuma referência ou subtítulo, e alguns <TE>
consistem apenas em um item <TERM> (um Descritor), mas estes são admissíveis
possibilidades nas equações, no entanto, para manter as coisas em ordem.
reconhecemos cada entidade sintática representada na miniatura (ou completa)
Thesaurus, mesmo que uma seção do texto em linguagem natural possa ser
para várias entidades ao mesmo tempo. Por exemplo, o primeiro <TS>,
Protetorado de ADEN
Veja Arábia do Sul, Federação de
representa as entidades diagramadas na Figura 6-1 de forma semelhante, a sétima.
<TS> tem a estrutura da Figura 6-2.

Na verdade, a página do modelo (por design) exibe quase todos:
possibilidade estrutural de urus; pode ser instrutivo localizar a sintática;
uation defil}ipg _qualquer relacionamento str!Jctural fornecido na página do modelo.

Agora considere o Thesaurus em miniatura fornecido pela página do modelo
estar "on-line" para acesso conversacional, embora o olho possa captar.
a página inteira, imagine que não pode e que apenas um item está disponível
para inspeção por vez, invocaremos a opção "Solicitação e Exibição".
modo de acesso conversacional para navegar, a título de ilustração, por esta miniatura
Tesauro Mostramos uma conversa na Tabela 6-4.
Na conversa, a linguagem em si é concisa e esquelética
-porque estamos interessados ​​apenas nos aspectos estruturais do Thesaurus
e em como as operações de solicitação e exibição podem permitir que um usuário navegue
e examine o Thesaurus item por item. Na prática, o lado Display.
seria mais abundante, mantendo informações de "status de retrocesso",
e assim por diante, conforme o espaço de exibição permitir.
A criação do Thesaurus é ilustrada pela própria página modelo: natural
texto de idioma com características estruturais que satisfazem as equações de
Tabela 6-2 Para manutenção do Thesaurus consideramos uma adição e um.
exclusão (observando que uma modificação pode ser considerada uma exclusão seguida
por uma adição). Suponha que desejamos adicionar Televisão (NT) ao Refer).
a partir de Referências de PUBLICIDADE Formamos o Localizador.

Entrada PUBLICIDADE, Consulte de
e o item
<TE> = <TERM> <HN> = Televisão (NT)
ou adição. Em seguida, a Televisão (NT) seria adicionada automaticamente (em ordem alfabética).
ordem) para a referência de referências de PUBLICIDADE.
Da mesma forma, para excluir a Notação Hierárquica (BT) no campo "BLACK
Veja a referência, localizamos por
Entrada "Poder Negro"
e excluir item
<HN> = (BT)
Nele.

Measurements of Program complexity

Introdução
ARTIGO
7
Está cada vez mais claro em sistemas de programação de grande escala que enfrentamos
problemas de complexidade quase pura há quinhentos anos, não o fazíamos.
sabemos que o ar tinha peso, mas saberemos disso daqui a alguns anos.
aprenderemos que a complexidade tem um custo, embora não saibamos
como medir essa complexidade no momento.
Devido à nossa ignorância, gerir uma programação em grande escala
projeto é uma atividade perigosa. Nossas ferramentas técnicas de gerenciamento são inadequadas.
É difícil medir o desempenho na programação.
diagnosticar o problema a tempo de evitá-lo. É difícil avaliar o problema.
status ~f trabalho intermediário, como programas ou design não depurados
especificações e seu valor potencial para o projeto concluído.
Assim, entendemos que “a complexidade cobrará seu preço”,
gostemos ou não. Gerenciar um grande projeto de programação envolve.
aprendendo a pagar o preço da complexidade de tal forma que possamos controlar
o destino do desenvolvimento desse projeto. Esse preço envolverá custos em.
instalações principais e de armazenamento, custos em tempo de execução e custos em horas-homem.
É muito fácil, no calor de pequenas batalhas de programação, esquecer que
o preço deve ser pago - preparar uma "tigela pequena de espaguete" para obter
rendimento mais rápido, ou para economizar núcleo, ou para adiar a documentação até
mais tarde para fazer algo funcionar.
A melhor garantia para aprender a pagar o preço da complexidade da maneira correta é aprender como identificá-la e medi-la.
ideias representam uma abordagem para um aspecto da medição do
do trabalho dos programadores A ênfase está nos procedimentos automáticos, que
pode ser formulado para experiência comum generalizada na gestão
de projetos de programação, e não em procedimentos heurísticos.

Medições de programação
Uma das áreas mais difíceis da programação desde o início foi
foi o da programação de medições. Todos nós apreciamos o valor de
fornecendo medições quantitativas na programação, mas o que quantificar
ainda é uma questão.
O número de instruções é um indicador típico de programação
esforço. Mas em alguns problemas o objetivo é produzir o mínimo possível.
instruções possíveis (por exemplo, em um agendador de sistema operacional),
de modo que o valor do trabalho seja inversamente proporcional ao número de
instruções em vez de proporcional a ele.
de coisas iguais, como capacidade do programador, complexidade do programa,
e disponibilidade da máquina, o número de instruções pode não ser um
estimativa incorreta do tamanho do programa No entanto, isso normalmente faz suposições.
sobre as mesmas coisas que nos propusemos a medir.
Visto em um nível um pouco mais profundo, o local para começar a medição
é a tarefa total que está sendo realizada para um usuário. Esta tarefa total será.
têm algum tamanho e complexidade, que é difícil medir no
Além disso, haverá alguma mistura de hardware e software.
capacidade endereçada à tarefa Por exemplo, a mesma tarefa será mais fácil.
programar em um computador grande e rápido do que em um computador pequeno e lento, onde ambos
espaço e tempo devem ser otimizados, mesmo que a tarefa seja a mesma;
para o usuário, a combinação de software/hardware pode ser diferente.
Existem ideias na teoria matemática da informação que
pode ajudar na quantificação de medições de programação.
o conceito de conteúdo de informação para uma mensagem é quantificado, e isso
conceito pode ser transferido intacto do inglês, digamos, para uma programação
linguagem.
Outra medida do conteúdo da informação pode ser deduzida da
as sequências de execução que os programas geram. Neste caso, um programa.
com muita ramificação produzirá sequências de execução tendo
maior conteúdo de informação do que um programa com pouca ramificação.
segunda medida do conteúdo da informação dá um valor quantitativo para o
A complexidade das operações que um programa gera no computador.

Conteúdo do programa
Usaremos a frase "conteúdo do programa" como abreviação para as informações
conteúdo de um programa, considerado como uma expressão em uma programação
Na verdade, existem várias maneiras alternativas de medir.
e interpretar esse conteúdo do programa, e a pesquisa empírica está claramente em
ordem. Várias alternativas específicas são fornecidas a seguir.
Conteúdo do programa baseado em personagens
Talvez a abordagem mais simples seja considerar um programa fonte como uma string
de caracteres exatamente como aparecem em um pressionamento de tecla.
deseja eliminar espaços em branco extras em tais programas, mas, caso contrário, trate-os
como uma sequência de caracteres simples. Existem duas maneiras pelas quais o conteúdo do programa.
poderia ser determinado. Primeiro, pode-se considerar o universo do caráter.
strings geradas por programadores em uma determinada linguagem fonte,
como PL/I ou Assembleia. Nesse caso, poderia-se acumular estatísticas.
sobre uma ampla variedade de programas de origem existentes que foram considerados
representativo em algum sentido e, a partir disso, calcular quantidades como
conteúdo de informação por personagem. Outro método é considerar cada novo.
programa de origem como um universo em si e construir estatísticas a partir desse único
programa fonte, que então pode ser usado para calcular o conteúdo da informação
por personagem. Os métodos intermediários seriam considerar classes científicas.
programação, programação de sistema, recuperação de armazenamento de informações
programação e assim por diante.
Conteúdo do programa baseado em símbolos
Outro nível de sofisticação seria identificar certos símbolos básicos
em programas fonte, como identificadores, palavras reservadas ou palavras-chave e
caracteres, como caracteres de um novo alfabeto e, novamente, para calcular informações
conteúdo por caractere neste alfabeto recém-derivado. Todas as possibilidades.
no conteúdo do personagem permanece nas escolhas do universo.
o tratamento de identificadores e palavras reservadas ou chave também admite alternativas.
Num certo nível, todos os identificadores podem ser tratados como um único genérico.
personagem, ou podem ser tratados como personagens individuais e distintos,
símbolo por símbolo. Os níveis intermediários tratariam classes de identificadores.
como caracteres genéricos, como identificadores de dados, identificadores de entrada e arquivos
identificadores.

Conteúdo do programa baseado em sintaxe
Ambos os casos anteriores são, na verdade, casos especiais de uma seleção de expressões sintáticas.
elementos em uma linguagem de programação.
geralmente começa com caracteres como os do keypunch,
os transforma em identificadores, palavras reservadas e assim por diante, e então esses
mais adiante em expressões, condições, declarações e assim por diante, para FAZER
grupos, procedimentos e, finalmente, programas. Nos casos anteriores, temos.
particionou a sequência de caracteres físicos em uma nova sequência de elementos sintáticos
em um nível ou outro, no entanto, o próprio programa tem uma hierarquia.
estrutura, conforme implícito na estrutura linear, como identificadores
contidas em declarações, declarações em grupos DO e grupos DO em
procedimentos, e pode-se conceber o cálculo do conteúdo da informação
necessário para definir a estrutura hierárquica que um programa realiza.
existe um conjunto tão amplo de alternativas aqui que uma seleção adicional será desejável,
dependendo em grande parte do próprio idioma de origem e de suas propriedades.
Coisas que podemos aprender
Nosso principal objetivo ao considerar medidas teóricas da informação em
programas é identificar dificuldades intrínsecas e medidas de desempenho
na programação Estas medidas serão, na melhor das hipóteses, imperfeitas, mas poderão.
forneceremos uma boa quantidade de insights e calibração que não temos
agora, a partir de simples instruções ou contagens de declarações.
Os diferentes tipos de conteúdo programático descritos acima podem ter.
vantagens diferentes, dependendo do que procuramos.
uma aparente desvantagem do conteúdo do programa baseado em caracteres é que
pode depender do comprimento dos nomes usados ​​pelos programadores, ou seja,
dois programas que são idênticos, exceto que os nomes curtos em um são substituídos
para nomes longos no outro, pode aparecer com programas diferentes
conteúdo. Não se sabe realmente se isso acontecerá com uma diferença considerável,
e, de facto, a definição do conteúdo da informação terá implicitamente
vantagem do reaparecimento de nomes longos para diminuir o conteúdo da informação
por personagem, no entanto, provavelmente resultará em mais informações.
conteúdo para o programa de origem total No entanto, isso pode não necessariamente.
ser uma falha, por exemplo, na medição do quão difícil tal programa pode ser
seja para código ou keypunch, onde parte do trabalho envolvido está relacionado a
o grande número de caracteres também pode valer a pena dar um programador.
crédito por fazer mais trabalho usando nomes mais longos porque isso ajuda em
a legibilidade do programa e, de fato, pode representar mais trabalho
a parte do programador em lembrar nomes mais longos corretamente.
 mesmo essa escolha de conteúdo de programa baseado em caracteres versus símbolos
acaba não sendo tão simples sem uma investigação mais aprofundada e
consideração.
Qualquer uso de tais medições terá que ser calibrado contra
algum tipo de experiência construída em um ambiente experimental ou de desenvolvimento
período, em que programas com determinadas características já identificadas
foram analisados ​​e os conteúdos programáticos correlacionados com essas características.
Um uso possível é descobrir até que ponto a plena
recursos de uma linguagem de programação estão sendo utilizados em uma programação
sistema Novamente, é uma suposição no momento que a programação é feita a partir de.
um pequeno subconjunto de uma linguagem resultará em menor conteúdo de programa por
caractere ou símbolo do que de outra forma. Por exemplo, menos reservado ou chave.
palavras que identificam vários tipos de declarações podem aparecer e diminuir o
conteúdo do programa dessa forma, quer isso realmente ocorra ou não, deveria.
ser uma questão de investigação empírica.
Olhando mais adiante, podemos perceber que o conteúdo programático pode
dar novas indicações de quão difícil pode ser a depuração de um programa ou quão
difícil de documentar ou compreender por outra pessoa. É claro que ambos.
depuração e documentação são assuntos complexos e não serão resolvidos
de forma definitiva, simplesmente pelo conteúdo do programa, mas parece;
possível que o conteúdo do programa possa reduzir, em uma quantidade significativa, o
residual de incerteza que precisa ser entendido por outros meios.
Conteúdo de execução
Usaremos a frase "conteúdo de execução" como abreviação das informações
conteúdo de uma sequência de execução gerada por um programa Novamente,
existem muitas maneiras alternativas de medir e interpretar esta execução
conteúdo e, ainda mais do que antes, a investigação empírica é necessária.
o conteúdo do programa pode ser aplicado em qualquer momento da vida
de um programa (como trabalho intermediário ainda não depurado ou fragmentos de programa,
por exemplo), o conteúdo da execução só pode ser determinado com um
programa que foi concluído e depurado até o ponto de execução.
Mais uma vez, a evidência empírica é necessária, mas parece que o programa
o conteúdo e o conteúdo de execução podem ser bastante independentes um do outro.
Isto pode não ser verdade, mas se houver relações que se desenvolvam, sabendo
isso seria valioso por si só.
Tal como no caso do conteúdo programático, o leque de alternativas
na verdade, decorre de uma descrição completa da execução do programa em
pergunta. Esta descrição completa é tipicamente representável em termos de
um processo de estado sequencial, onde o programa requer algumas tarefas de máquina

patético ou real- de estado para estado na presença de dados de entrada.
estados são o alfabeto no qual as informações podem ser calculadas na programação.
idiomas onde declarações individuais são identificadas, uma das
a possibilidade mais simples é considerar as afirmações como personagens de uma
alfabeto e a sequência de execução como as instruções reais na ordem
eles são executados. As sequências assim geradas normalmente serão muito maiores.
mais do que estamos acostumados a ver em um contexto de teoria da informação
e, de fato, no caso do conteúdo do programa Mas a base lógica para a computação.
o conteúdo da informação é o mesmo.
Outra abordagem pode considerar elementos sintáticos em um nível mais elevado
nível do que declarações, como procedimentos, grupos e assim por diante, ou simplesmente
pontos de ramificação no programa de origem.
Em níveis mais detalhados, o conteúdo da execução pode muito bem envolver
operações da máquina, em contraste com as operações da linguagem de origem, quando, por
Por exemplo, as ramificações seriam iniciadas em sub-rotinas e macros chamadas
pelo compilador, que fica oculto para o programador.
as investigações não seriam voltadas tanto para a medição do programador
como educação de programadores e no efeito de programas no idioma de origem
no ambiente da máquina.
O que fazer a seguir
A próxima coisa a fazer é desenvolver evidências empíricas de como a informação
o conteúdo depende dos programas reais. O principal esforço necessário é gerar.
um pequeno conjunto de programas de análise, que irão analisar
outros programas para conteúdo de programa ou conteúdo de execução automaticamente.
Existem muitos programas para analisar, e particular
programas podem ser identificados para calibrar as conclusões gerais sobre outros
programas.
Existem três tipos de subprogramas necessários na análise de
conteúdo do programa ou conteúdo de execução: analisadores de programas de origem, execução
analisadores de rastreamento e analisadores de estatísticas de informações.
Os analisadores do programa fonte devem levar em PL/1, Assembly,
Fortran, ou outros programas fonte, e de acordo com várias alternativas
cadeias de caracteres desejadas derivadas de saída para análise posterior.
Os analisadores de rastreamento de execução provavelmente poderiam operar com base
de pré-processar programas fonte e inserir interrupções ou chamadas no
início de cada instrução, bloco ou o que quer que seja rastreado, no qual
momento em que os objetos que estão sendo rastreados podem ser identificados e colocados em uma saída
stream O resultado deve ser uma sequência de caracteres padrão, assim como from.
analisadores de programas, embora possivelmente essas strings possam ser muito
maiores e consistem em alfabetos com muito mais caracteres do que seria
normalmente encontrado no caso de conteúdo do programa.
Os analisadores de estatísticas de informação devem tomar como entrada uma string
de caracteres em formato padrão e como saída várias informações teóricas
quantidades como conteúdo de informação por caractere ou informações
conteúdo para a string. Deve-se enfatizar que essas informações
estatísticas podem ser geradas como quantidades formais, independentemente da estatística
suposições por trás da cadeia de caracteres de entrada, em particular, existem.
certas diferenças entre uma língua natural, como o inglês, e uma língua formal
linguagens como as usadas em programas de origem Uma diferença é a.
extensão de correlação em linguagens formais, em comparação com linguagens naturais;
por exemplo, um programa PL/I legal que contém uma instrução DO é
certamente conterá uma instrução END algum tempo depois, possivelmente muito
mais tarde. Esses tipos de correlações necessárias, independentes de separações,
não são característicos das línguas naturais. Qual é o seu efeito sobre o
o cálculo de estatísticas de informação ainda precisa ser estudado, entre outros.
coisas, essas diferenças exigem uma interpretação ligeiramente diferente do que
a base estatística é. Não é comum em uma linguagem natural calcular o valor.
conteúdo informativo de uma mensagem com base nas estatísticas dessa
mensagem por si só. Isso ocorre, em parte, porque estamos fazendo perguntas diferentes.
na análise de línguas naturais, como quão difícil é transmitir uma
mensagem aleatória em inglês através de um circuito telegráfico, por exemplo.
no presente caso, procuramos distinções entre as próprias mensagens
que podem aparecer devido a padrões sutis, que as estatísticas de informação
pode revelar para nós. Neste caso, pode ser muito sensato considerar.
o conteúdo informativo de uma mensagem ou programa com base no
estatísticas que ele gera. No contexto mais clássico, poderíamos estar perguntando a um.
pergunta como "Se esta mensagem fosse representativa do
língua em que é expresso, então qual é o seu conteúdo informativo?"

Equipes de Programadores Chefes: Técnicas e Procedimentos
Uma oportunidade
Há uma oportunidade de melhorar tanto a capacidade de gerenciamento quanto a produtividade
da programação em um grau substancial Esta oportunidade reside.
na mudança das práticas de programação da arte privada para a ciência pública
e na organização dessas práticas de programação em estruturas de trabalho que
refletir habilidades e responsabilidades apropriadas em um esforço de equipe.
Uma equipe de programadores chefe
Uma Equipe de Programadores Chefe é uma resposta a esta oportunidade.
A Equipe de Programadores é um grupo pequeno, mas altamente estruturado, liderado
por um programador que assume a responsabilidade detalhadamente pelo
desenvolvimento de um projeto de programação A ideia principal de um Chief.
A equipe de programadores deve adotar uma abordagem não estruturada de "time de futebol"
na programação para uma abordagem estruturada de "equipe cirúrgica".
A equipe do programador é composta por membros com habilidades muito específicas
e funções a desempenhar. Um núcleo de equipe típico consiste em um Programador Chefe,
um programador de backup e um bibliotecário de programação.
Bibliotecário é uma secretária ou outro especialista administrativo com treinamento adicional
em lidar com materiais de programação Além do núcleo, mais.
programadores, analistas, redatores técnicos, técnicos ou outros especialistas
também pode ser incorporado.
A Equipe do Programador Chefe permite a aplicação de novos recursos de gerenciamento
padrões e novos padrões técnicos para projetos de programação.
Os padrões de gestão decorrem da especialização de competências e
deveres do pessoal que é treinado de forma independente para diversas funções em
desenvolvimento de sistemas de programação Os padrões técnicos são possíveis.
utilizando habilidades técnicas de nível superior para a programação real
processo, habilidades técnicas que são liberadas através da estruturação do trabalho e
delegação na equipe do programador chefe.
Uma biblioteca de produção de programação
Uma Biblioteca de Produção de Programação (PPL) serve como ponto focal e
um ingrediente crítico na equipe de programadores-chefe.
desenvolver projeto de programação de forma contínua e visível A equipe.
A interface dos membros entre a programação e as atividades administrativas é através
este projeto visível O Bibliotecário de Programação é responsável por manter.
o PPL. O Programador Chefe é responsável pelo seu conteúdo.
Esta estrutura de responsabilidade permite um novo nível de padronização de gestão
na manutenção de registros do projeto O PPL é uma "linha de montagem".
conceito, no qual as pessoas trabalham em um produto comum e visível, em vez de
carregando pedaços de trabalho de volta para seus “bancos”.
O PPL também representa uma importante ferramenta de programação para produtividade,
isolando e delegando atividades administrativas fora da programação.
Como tal, permite que um programador exerça uma gama mais ampla de
controle detalhado sobre a programação. Isso, por sua vez, permite menos programadores.
fazer o mesmo trabalho, o que, por sua vez, reduz os recursos de comunicação.
requisitos, e o tempo ganho permite uma gama ainda maior de
controle detalhado na programação. Com técnicas avançadas de programação.
e padrões técnicos, discutidos mais abaixo, este intervalo de
o controle detalhado pode ser expandido em uma ordem de magnitude além da atual
prática; o PPL desempenha um papel crucial nesta expansão potencial.
Padrões Técnicos em Programação
Novos padrões técnicos desempenham um papel fundamental na equipe de programadores-chefe
Desenvolvimentos teóricos recentes fornecem uma base para maiores
disciplina do que antes, o que garante resultados mais uniformes e repetíveis
processos de desenvolvimento de programas. Um Programador Chefe é altamente disciplinado.
programador - o completo oposto do "cientista louco" produzindo uma criatura que ninguém mais entende. O PPL impõe um adicional.
disciplina em toda a equipe de programadores chefes.
Requer bons programadores para trabalhar dentro dessas novas tecnologias
padrões, assim como é preciso um bom engenheiro para projetar um dispositivo complexo
usando apenas algumas unidades padronizadas Na programação hoje em dia existe.
muitas vezes uma confusão entre criatividade e variabilidade - elas não são as
mesmo. Um grande ato de criatividade em programação é encontrar simplicidades profundas.
em um processo complexo e escrever programas que sejam facilmente lidos e
compreendido por outros. Este é um teste importante para um bom programador.

Uma redução vem do uso de um Programador de Backup, um
colega do Programador Chefe em questões de design de sistema, para que um
a segunda pessoa está totalmente familiarizada com o projeto em desenvolvimento e sua justificativa.
Outra função importante do Programador de Backup pode ser
fornecer condições de teste independentes para o sistema.
Além disso, o Programador de Backup pode atuar como assistente de pesquisa
para o Programador Chefe em questões de estratégia de programação e
Já foi observado que o uso do OS/360 é formidável.
mas o seu uso imaginativo e inteligente pode significar diferenças muito grandes
na quantidade e tipo de código detalhado que pode ser necessário.
maneira como um Programador de Backup pode fornecer a um Programador Chefe mais
liberdade para se concentrar nos problemas centrais do sistema;
desenvolvimento, usando resultados de investigações periféricas que foram designadas
para o programador de backup.
O bibliotecário de programação
O trabalho de um Bibliotecário de Programação é padrão para todos os Programadores Chefes
Equipe e é independente do assunto do projeto.
É manter os registros de um projeto em desenvolvimento, tanto
formato interno legível por máquina e um formato externo legível por humanos.
Os registros externos de um projeto da Equipe de Programadores Chefe são
mantido em um conjunto de listagens arquivadas, que definem o status atual e
histórico anterior do projeto O status atual é mantido em folha solta.
cadernos, cada um encabeçado por um diretório e seguido por uma lista em ordem alfabética
lista de módulos membros. Quando membros e diretórios são atualizados.
e substituídas nos cadernos de status, as cópias substituídas são arquivadas
em diários cronológicos Todos os resultados das execuções de depuração também são mantidos.
em diários.
Os programadores constroem e alteram o status do projeto escrevendo programas
ou dados em folhas de codificação ou marcando membros de status na PPL.
É responsabilidade do bibliotecário introduzir esses dados no
Essa responsabilidade é realizada por meio de um conjunto de registros interligados.
procedimentos de escritório e procedimentos de máquina Parte dos procedimentos de escritório.
tratam da entrada de dados no PPL.
arquivamento da saída dos procedimentos da máquina; é esse processo de arquivamento que
mantém o projeto visível.
Os programadores também recorrem ao Bibliotecário para toda montagem, compilação,
edição de ligação e execuções de depuração necessárias no projeto.
os resultados dessas execuções são arquivados automaticamente pelo Bibliotecário como parte do
o projeto visível.

A ideia da equipe
Observe que apoiamos um Programador Chefe não apenas com ferramentas, mas
com uma equipe de especialistas, cada um com ferramentas especiais.
apoia o Programador Chefe no design técnico e
nível de estratégia de programação O Bibliotecário de Programação apóia o
Programador Chefe no nível administrativo e de manipulação de dados. Outros programadores.
e os analistas desempenham funções definidas com precisão pelos Programadores Chefes
para atender aos requisitos do projeto, projetando e codificando módulos que são
originalmente especificado e finalmente aceito pelo Programador Chefe no
sistema.
Um cirurgião e uma enfermeira se comunicam em um conciso "esponja e bisturi"
nível, com pouco espaço para mal-entendidos e pouco tempo desperdiçado.
O médico nunca diz: "Sra. Jones, estou realizando um exame cardiovascular
operação, etc., e usei este bisturi que agora pode ter algum
germes nele, etc., então você poderia esterilizá-lo, etc., e devolvê-lo para
o rack, etc." Em vez disso, as interações entre esponja e bisturi são independentes
do tipo de cirurgia, e o papel do enfermeiro pode ser pré-estruturado e
ensinado na escola de enfermagem, não na sala de cirurgia.
A relação entre Programador e Bibliotecário pode ser precisa
e eficiente por desenvolvimentos e padrões semelhantes. Simplesmente marcando.
uma correção ou adição em uma listagem do PPL por um programador lidera
a uma resposta automática do Bibliotecário para incorporar as novas informações
no PPL.
A visibilidade da PPL e as operações administrativas automáticas
que o mantêm permitem que os programadores se concentrem na programação
assuntos e comunicar de forma mais precisa e eficaz através de
o PPL.
A simplificação do trabalho que é possível através da utilização de facilidades
como OS/360 efetivamente em uma equipe de programadores chefe parece ser
considerável. Permite o controle técnico detalhado de um projeto de programação.
por um Programador Chefe que recebeu recursos suficientes
em outros membros da equipe para lidar com as complexidades do OS/360,
requisitos funcionais do sistema e os problemas administrativos de criação e
manutenção de definições de sistemas.
O programador-chefe como profissional
A abordagem da Equipe do Programador Chefe por meio da atribuição de cargos e do trabalho
delegação libera um Programador Chefe para ser um profissional em todos
sentido. A primeira obrigação de um profissional é atender as necessidades do cliente e atendê-las bem. Essa obrigação para com o cliente envolve questões financeiras.
bem como considerações técnicas Na programação, envolve fazer o
"planos certos" para realizar um projeto para aprovação do cliente e depois
fazer os "planos certos" na execução do projeto, dentro de um prazo e
orçamento em dólares.
O Programador Chefe é um programador com alta competência técnica,
não apenas em detalhes e técnica, mas também em sistemas amplos
análise e design. As ferramentas do Programador Chefe são programação.
linguagens e sistemas, e ele ou ela deve conhecê-los em amplitude e
profundidade Também é essencial conhecer as necessidades dos clientes e agir de forma eficaz.
resolver qualquer disparidade entre essas necessidades e as ferramentas de programação
disponível.
Em particular, observe os relacionamentos da equipe de programadores chefes,
que são pré-estruturados, permitindo ao Programador Chefe e outras equipes
membros olhem para fora, para as necessidades e possibilidades técnicas do cliente, em vez de
do que para dentro. Essa liberdade de se concentrar nas necessidades do cliente, com
instalações de produção definidas automaticamente, é um objetivo importante na
Definindo uma equipe de programadores chefe.

sobre a validação estatística de programas de computador
Resumo
9
Técnicas de inferência estatística são introduzidas na questão da
correção do programa pela introdução intencional, mas aleatória, de
erros de programação em um programa antes de um processo de teste nele. A
introdução de tais erros permite um cálculo de confiança por meio de
um processo de Asserção, Inserção, Teste (AIT).
Palavras-chave e frases
teste
correção de programas
validação estatística de programas
A Correção de Programas
confiabilidade do programa
garantia de sistemas
A correção de programas de computador é de crescente preocupação e importância.
A correção é geralmente tratada como um problema lógico, conforme descrito
por Floyd [4], Naur [7], Dijkstra [1] e outros. Até agora, as
provas de correção foram realizadas apenas para programas relativamente pequenos. Um
dos maiores exemplos é devido a London [6]. No entanto, King [5] tem
mecanizado um processo de correção, baseado em um provador de teoremas geral, usando as ideias de Floyd. Mesmo assim, ideias de correção têm sido usadas informalmente
para orientar grandes esforços de programação em design e codificação, como
relatado por Dijkstra [2] no Sistema T.H.E. O autor também atesta
uma influência considerável nas práticas de programação, devido às ideias de
correção.
No entanto, questões de correção e confiabilidade de grandes sistemas de
programação ainda são cruciais como questões práticas, independentemente de as técnicas de
correção atuais poderem abordá-las. Grandes sistemas estão sendo testados,
e erros encontrados em sistemas verificados, todos os dias. Até agora, os erros
encontrados são tratados como eventos únicos e não são muito usados ​​para lançar luz
sobre quais outros erros podem permanecer. É um clichê na programação de grandes sistemas
que nenhum grande sistema pode estar livre de erros. Isso pode ou não
ser assim no futuro, mas mesmo agora não é um clichê muito útil.
Inferência estatística sobre correção
Apresentamos técnicas de inferência estatística sobre a correção de
programas de computador e estimativas de máxima verossimilhança do número de
erros não encontrados em qualquer estágio de um processo de teste. Os conceitos estatísticos
são realizados aqui, em parte, para motivar um desenvolvimento correspondente
que é necessário em conceitos de programação.
Dado um grande programa de computador para validar, sua correção é uma
questão de fato e não uma questão de probabilidade. Mas podemos converter essa
questão de fato em uma questão de inferência estatística, ou estimativa,
por meio da introdução intencional, mas aleatória, de erros de programação em um programa. Esses erros então calibram um processo de teste e
permitem inferência estatística sobre a eficácia do processo de teste
em si.
O ideal estatístico é introduzir erros em um programa de computador
que tenham a mesma chance de serem encontrados que os erros já
lá, se houver algum. Este é um problema de teoria de programa não trivial.
Os erros presentes em um programa em qualquer ponto do tempo dependem do
histórico de atividades de busca de falhas que foram aplicadas a ele até
então. Por exemplo, se um programa foi compilado com sucesso, então
certos erros de sintaxe não estarão presentes, ou então o compilador os teria
localizado. Assumimos aqui que esse problema de introduzir
erros é resolvido, a fim de motivar o trabalho para desenvolver soluções razoáveis ​​para ele. Porque uma vez que esse problema é resolvido, então o raciocínio estatístico
que se segue é relativamente direto, mas bastante poderoso em
comparação com as informações atuais que temos sobre a validação de programas de
computador.

Na verdade, a questão do número de erros de programação em um
programa precisa ser formulada cuidadosamente porque há muitas maneiras de
consertar um programa que tem erros nele — incluindo escrever um programa totalmente novo
que em nada se assemelha ao programa original. Informalmente, pensamos
em corrigir um erro em termos de alterar ou adicionar uma declaração (por
exemplo, uma unidade elementar de execução ou declaração em um programa).
A correção pode exigir a adição de uma declaração composta também. Isso
por sua vez sugere a ideia de introduzir erros por um processo aleatório cujas
ações básicas são alterar ou excluir declarações. Não é difícil elaborar
processos automáticos (aleatórios) para várias linguagens de programação
para introduzir erros, mas manter a sintaxe correta, para recompilação e
teste. Presumivelmente, essas frequências de erro podem ser definidas para refletir a real
experiência de erros de programação encontrados em uma determinada linguagem em um determinado
estágio de teste. Essas ideias são preliminares e, como observado, os conceitos estatísticos
destinam-se a motivar uma investigação mais profunda sobre esses problemas teóricos de programa.

Um modelo estatístico de erros de programa de computador
Para separar a teoria da programação e a teoria estatística, definimos
um modelo abstrato do processo que temos em mente. Nosso modelo contém um
"sistema", conjuntos de "erros indígenas" e "erros de calibração" e um "processo
de teste". O processo de teste pode ser execuções do sistema ou algum
processo de prova de correção parcial.
Começamos com um sistema contendo um número desconhecido de erros indígenas,
que são o objeto da investigação. Temos permissão
para inserir no sistema uma série de erros de calibração e então executar
o processo de teste para encontrar erros - calibração ou indígenas. Em qualquer
ponto do processo de teste, assumimos que há uma chance igual para
a recuperação de qualquer um dos erros, indígenas ou de calibração, que ainda permanecem
no sistema. Durante o processo de teste, um certo número de erros indígenas pode ser encontrado. Usamos essas circunstâncias para fazer
afirmações estatísticas sobre quais erros indígenas ainda podem permanecer no
sistema.
Feller [3], na página 43, analisa uma situação semelhante em termos de estimativa
do número de peixes em um lago. O processo descrito ali é pegar
peixes, marcá-los e fazer uma nova captura de peixes para determinar
quantos dos capturados foram marcados. Ele mostra ali que a distribuição hipergeométrica
descreve as probabilidades das várias possibilidades.
Em nossa aplicação, é claro, "lago" é sinônimo de "sistema", "peixes não
marcados" é sinônimo de "erros indígenas", "peixes marcados" de
'erros de calibração" e "captura de peixes" de "processo de teste".

Um estimador de máxima verossimilhança para erros indígenas
Em qualquer ponto do processo de teste, assuma os seguintes parâmetros.
y = erros de calibração inseridos inicialmente.
u = erros indígenas encontrados até o momento.
v = erros de calibração encontrados até o momento.
Feller também mostra que o estimador de máxima verossimilhança para o original
número de erros indígenas — digamos, x — é a parte inteira da expressão
yujv. Desnecessário dizer que esse estimador de máxima verossimilhança estará ele próprio
sujeito a erro estatístico, mas fornece uma indicação objetiva dos erros restantes
em um programa à medida que um processo de teste prossegue.
Um processo de afirmação, inserção e teste. para inferência estatística
Formulamos um processo de afirmação, inserção e teste (AIT) de amostra que consiste
nas seguintes ações.
1. Afirma-se que um dado sistema não tem mais do que um número selecionado
de erros indígenas, digamos, k ~ 0.
2. Um número positivo selecionado de erros de calibração é inserido no
sistema, digamos, j > 0.
3. O sistema é testado até que os j erros calibrados tenham sido encontrados,
e o número de erros indígenas encontrados durante esse processo é
registrado também, digamos, i. Observe que, sob nossa hipótese, i é uma variável aleatória.
4. Uma confiança, C, é computada como
{
0
C= j
j + k + 1
se i > k
se i ~ k.
A justificativa para C é dada da seguinte forma. Se i > k, é óbvio que a
afirmação é falsa, e a confiança nela é zero. Se i ~ k, a afirmação
pode ou não ser verdadeira. Para cada hipótese possível para a qual a afirmação
é falsa, calculamos a probabilidade em tal processo AIT de que i >
k, ou seja, que rejeitaríamos corretamente a afirmação. Com uma hipótese

de h erros indígenas a probabilidade de encontrar i deles antes que o jésimo
erro de calibração seja encontrado é ( cf. Feller)
(1) .. (~)C~1)( 1)
p(h,z,J) = ( h + j ) h - i + 1
i + j - 1
h ~ i, i ~ 0, j > 0
isto é, encontramos quaisquer i erros indígenas e quaisquer j - 1 erros de calibração, em
qualquer ordem, e então encontramos o erro de calibração restante entre os
h - i + 1 erros restantes.
A probabilidade de rejeitarmos corretamente uma afirmação falsa é dada por
h
(2) c(h, j, k) = ~ p(h, i, j) h > k, j > 0, k ;::: 0.
i= k+l
Agora, para a afirmação ser falsa, h deve ser um inteiro maior que k;
consideramos todas as possibilidades e o valor mínimo possível, a saber,
(3) C(j, k) = minh>k, c(h, j, k) j > 0, k;::: 0.
Pode ser provado, então, que o valor de C é (veja o Apêndice abaixo)
(4) C(j, k) = c(k+ l,j,k) = j+i+
1
j > 0, k;::: 0,
conforme usado acima.
É fácil ver como generalizar esse processo AIT simples. O
teste poderia ser concluído quando uma certa função dos erros indígenas
foi encontrada, em vez de todos eles, com novos níveis de confiança.
Regras de parada mais complexas para o teste poderiam ser usadas, com base em ambos
erros calibrados e indígenas encontrados, por exemplo.
O Processo AIT: Interpretação e Exemplos
O processo AIT produz uma declaração de confiança sobre um processo de programação
e teste, não sobre um sistema específico em teste. Esta é uma distinção fundamental
frequentemente mal compreendida na inferência estatística. Como já
notado, o número de erros indígenas no sistema é um número fixo, não
menos fixo por causa da nossa ignorância sobre ele. Nossa confiança está no

de h erros indígenas a probabilidade de encontrar i deles antes que o jésimo
erro de calibração seja encontrado é ( cf. Feller)
(1) .. (~)C~1)( 1)
p(h,z,J) = ( h + j ) h - i + 1
i + j - 1
h ~ i, i ~ 0, j > 0
isto é, encontramos quaisquer i erros indígenas e quaisquer j - 1 erros de calibração, em
qualquer ordem, e então encontramos o erro de calibração restante entre os
h - i + 1 erros restantes.
A probabilidade de rejeitarmos corretamente uma afirmação falsa é dada por
h
(2) c(h, j, k) = ~ p(h, i, j) h > k, j > 0, k ;::: 0.
i= k+l
Agora, para a afirmação ser falsa, h deve ser um inteiro maior que k;
consideramos todas as possibilidades e o valor mínimo possível, a saber,
(3) C(j, k) = minh>k, c(h, j, k) j > 0, k;::: 0.
Pode ser provado, então, que o valor de C é (veja o Apêndice abaixo)
(4) C(j, k) = c(k+ l,j,k) = j+i+
1
j > 0, k;::: 0,
conforme usado acima.
É fácil ver como generalizar esse processo AIT simples. O
teste poderia ser concluído quando uma certa função dos erros indígenas
foi encontrada, em vez de todos eles, com novos níveis de confiança.
Regras de parada mais complexas para o teste poderiam ser usadas, com base em ambos
erros calibrados e indígenas encontrados, por exemplo.
O Processo AIT: Interpretação e Exemplos
O processo AIT produz uma declaração de confiança sobre um processo de programação
e teste, não sobre um sistema específico em teste. Esta é uma distinção fundamental
frequentemente mal compreendida na inferência estatística. Como já
observado, o número de erros indígenas no sistema é um número fixo, não
menos fixo por causa da nossa ignorância sobre ele. Nossa confiança está no processo AIT, pois ele é aplicado repetidamente a muitos desses sistemas; rejeitaremos
corretamente uma afirmação falsa em uma certa fração do tempo. C é um valor
conservador para essa fração.
Um caso especial de interesse no AIT é aquele em que k = 0 - a afirmação
é que o sistema está correto (sem erros). Então C simplifica para j I (j + 1).
Assim, vários níveis de confiança na correção de um sistema podem ser
obtidos inserindo vários números de erros de calibração e encontrando
apenas esses erros no processo de teste. Algumas amostras são fornecidas na Tabela
9-1.
A Tabela 9-2 fornece alguns valores de C para pequenos valores dos parâmetros
de Asserção, k, e Inserção, j. É fácil ver uma propriedade geral
da tabela de valores de confiança: quanto maior o limite afirmado, ou
menor o número de erros inseridos, mais fácil é passar no teste, mas
menos confiança o processo AIT produz. Esta propriedade indica
uma estratégia pragmática geral para AIT, que equilibra uma estimativa do
estado de um sistema com um objetivo em estabelecer um nível de confiança.
Se o objetivo em confiança for irrealisticamente alto, AIT normalmente não fornecerá
nenhuma confiança, e um novo AIT será necessário para estabelecer qualquer
confiança. Se a afirmação for irrealisticamente frouxa (em altos números de
erros), a confiança é, portanto, degradada. (É importante ·perceber que
afirmar cinco erros e não encontrar nenhum dá uma confiança muito menor do que
afirmar nenhum erro e não encontrar nenhum - quando cinco erros são afirmados, não encontrar
nenhum e encontrar cinco são equivalentes a essa afirmação).

O gráfico AIT
Durante o processo de teste, os erros serão encontrados cronologicamente, e assim que
um erro de calibração for encontrado, um estimador de máxima verossimilhança
está disponível para o número de erros indígenas. Esta estimativa irá
flutuar de uma forma um tanto previsível, geralmente subindo com cada erro indígena
encontrado e descendo com cada erro calibrado encontrado. Um gráfico
de tais estimativas pode fornecer um relatório de status visual do processo de teste
conforme ele progride ao longo do tempo, digamos, ao longo de várias semanas. Por exemplo, suponha
um AIT com parâmetros
k=6
j = 9
produza um teste com erros encontrados na seguinte sequência, I = indígena,
C = erro calibrado;
CCICIICCCICCCIC
Os estimadores de máxima verossimilhança em cada estágio do teste são como
mostrado na Tabela 9-3.
TABELA 9-3.
Tipo de erro [yu!y]
1 c 0
2 c 0
3 I 4
4 c 3
5 I 6
6 I 9
7 c 6
8 c 5
9 c 4
10 I 6
11 c 5
12 c 4
13 I 5
14 c 5
Estas informações podem ser resumidas em um único gráfico para fins de gerenciamento.
No início do teste, o gráfico tem o formato da Figura
9-1.

A confiança do teste é calculada a partir de j, k: ou seja, jj(j + k + 1) = 9/16
= .56; a barreira à direita é j + k, pois se mais de j + k erros forem
encontrados, há mais de k erros indígenas e o AIT falha; a
linha horizontal é um alvo para ficar abaixo e certamente acabar abaixo
para um teste bem-sucedido.
Usando a suposição anterior sobre erros encontrados, mostramos o
teste concluído na Figura 9-2.
A qualquer momento do teste, o gráfico até aquele momento é conhecido e
uma imagem cumulativa do progresso do teste está disponível. Este teste foi bem-sucedido
(a curva de máxima verossimilhança acabou dentro das barreiras), embora
"parecesse ruim" no erro 6.
Agradecimento
Agradecimento a M. M. Kessler pelas discussões e pela referência ao
tratamento de Feller dos aspectos combinatórios do problema.
Referências
1. Dijkstra, E. W. "Uma abordagem construtiva para o problema da
correção do programa." BIT8 (1968): 174-186.
2. Dijkstra, E. W. "A estrutura do sistema de multiprogramação 'T.H.E.'." Comm. ACM 11 (1968): 341-346.
3. Feller, W. Uma introdução à teoria da probabilidade e suas aplicações.
2ª ed. Nova York: John Wiley, 1957.
4. Floyd, R. W. "Atribuindo significados a programas." Em Proceedings of
the Symposium in Applied Mathematics, vol. 19, editado por J. T.
Schwartz, pp. 19-32. Providence, R. I.: American Mathematical
Society, 1967.
5. King, J. C. "Um verificador de programa." Tese de doutorado, Carnegie-Mellon University,
Pittsburgh, 1969.
6. London, R. L. "Certificação do Algoritmo 245 Treesort 3: Prova
de Algoritmos - Um Novo Tipo de Certificação." Comm. ACM 13
(1970): 371-373.
7. Naur, P. "Prova de Algoritmos por Instantâneos Gerais." BIT 6
(1966): 310-316.

Programação OS/360

Introdução
ARTIGO
10
A programação efetiva do OS/360 requer uma compreensão abrangente
dos conceitos e facilidades do OS/360. As facilidades coletivas de programação
do OS/360 podem ser consideradas como um processador multilíngue; e, em particular
na programação do OS/360, o objetivo deve ser:
1. programar o máximo possível em JCL (Job Control Language);
então, como próximo recurso,
2. programar o máximo possível em LEL (Linkage Editing Language);
então, como último recurso,
3. programar em um ou mais Assembly, PL/1, BSL, Fortran, Cobol,
e assim por diante.
Nesta estratégia, buscamos resolver problemas de design de programa e
codificação no nível mais alto possível na hierarquia de linguagens, de tal
maneira a resolver esses problemas com o mínimo de código possível escrito
para esse propósito. Por exemplo, é preferível resolver um problema em gerenciamento de dados
em JCL com cartões de descrição de dados (DD) e utilitários, em vez de
escrever programas em PL/1 ou Cobol para atingir os mesmos fins.
Os recursos do OS/360 são complexos, arbitrários e difíceis de usar.
No passado, programadores de nível sênior, por um bom motivo, eram relutantes
em se envolver diretamente com todos os detalhes e aparentes acidentes do JCL,
particularmente as descrições de dados necessárias nele. Como resultado, esse pessoal sênior
frequentemente resolveu problemas de programação de um ponto de vista IBSYS
(o sistema operacional IBM 7094), e assim por diante, em quadros-negros e em memorandos (por exemplo, um ponto de verificação, problema de reinicialização) e então
enviar mais pessoal júnior para implementar essas soluções funcionais em
as linguagens de programação disponíveis, como PL/I ou Assembly. Esse modo
de operação frequentemente reinventa recursos que já estão presentes no OS/360.
O código reinventado precisa ser mantido, documentado e de outra forma
integrado ao sistema geral com uma sobrecarga e despesa gerais
adequadas ao seu tamanho. Na verdade, no entanto, se o pessoal de nível sênior estiver
ciente dos recursos do OS/360, particularmente do JCL (por exemplo, em
lidar com um ponto de verificação, problema de reinicialização), o que era uma solução de quadro-negro e memorando
levando a um esforço considerável de programação por pessoal júnior
pode muito bem se tornar uma adição de JCL de algumas linhas ao sistema, na qual o
pessoal sênior tem controle total e direto sobre o que está acontecendo
e o benefício de todas as futuras melhorias e manutenções do OS/360.
OS/360 como um sistema natural
OS/360, como um processador multilíngue, parece ser mais bem visto como um "sistema
natural" do que racional neste momento. Para ter certeza, em seus estágios de planejamento
havia um senso definido de racionalidade nele. Mas a essa altura ele
cresceu em uma coleção bastante caseira de recursos que são chamados
em formatos muitas vezes misteriosos. No entanto, apesar de toda a sua simplicidade, o OS/360
é de longe o ambiente de programação mais poderoso já fornecido
a programadores para programação de produção. Como resultado, se
considerarmos o OS/360 como um sistema natural, como uma vaca, estamos em uma condição mental muito mais saudável
do que se tentarmos considerá-lo como um sistema racional. No
último caso, a maioria dos programadores de nível sênior simplesmente fica brava e não consegue
realizar muito. Nós simplesmente usamos uma vaca, sem questionar se ela
deveria ter quatro ou seis pernas, se sua temperatura corporal deveria ser
93 ou 99 graus, e assim por diante, e há um grande benefício a ser
obtido com isso. Essa é nossa atitude aqui em relação ao OS/360.
Descrever o OS/360 como o sistema natural que ele realmente representa não é
uma tarefa fácil. Os manuais fornecem muitos insights, generalizações e
observações sobre o OS/360, mas eles representam apenas isso - não realmente informações
completas. A única informação realmente confiável sobre o OS/360
é o próprio código, e o principal propósito da documentação é tornar esse
tipo de exame desnecessário. No entanto, há lugares, quando alguém
está procurando obter o máximo possível deste ou daquele recurso, que você .
não pode confiar nos manuais, você não pode confiar nos PLMs, você precisa ir ao
código em si. Isso não vai acontecer com frequência, mas vai acontecer.
Podemos fazer cada vez melhor na descrição do OS/360, assim como fazemos
na descrição de vacas na zoologia descritiva. Tentamos tal descrição, particularmente com relação a JCL e LEL, a fim de colocar essas linguagens
em uma base melhor para que o pessoal sênior use diretamente na definição
e controle do desenvolvimento de sistemas de programação. Isso envolve, em primeiro lugar
tratar tanto a JCL quanto a LEL como linguagens de programação genuínas.
Está bem claro que JCL é uma linguagem de programação. Ela incorpora ideias
de execução condicional, parâmetros simbólicos, passagem de algoritmos e assim
por diante, que são marcas registradas das linguagens de programação. LEL é mais difícil de ver como
uma linguagem. A edição de ligação é uma generalização da montagem, na qual
as "instruções" são módulos de carga e módulos de objeto, em vez de instruções
codificadas manualmente de uma linha ou algo assim. É um fato simples que a edição de ligação,
exceto pelo tamanho dessas "instruções", tem exatamente a mesma função
que o montador, requer tabelas de símbolos, requer uma segunda passagem para resolver
referências e assim por diante. Portanto, consideramos LEL como uma linguagem real.
Comparado com sistemas operacionais mais simples, parece que o papel
dos utilitários do OS/360 é mais frequentemente negligenciado ou reinventado, em parte porque
esses utilitários, como concebidos no OS/360, são mais complexos e menos diretamente
utilizáveis ​​do que em sistemas anteriores e em parte por causa das complexidades do
próprio JCL. Por exemplo, é relativamente difícil fazer uma operação de utilitário simples,
como listar um baralho de cartas, no OS/360, mas com um pouco mais de dificuldade
pode-se fazer alguns trabalhos de manipulação de dados muito substanciais, como descarregar
um conjunto de dados particionados do disco para uma fita.
JCL como uma Linguagem de Programação
JCL ocupa um lugar particular no OS/360. É a linguagem de programação do sistema
geralmente referida como a linguagem de controle, que é interpretada
automaticamente pelo OS/360. Todas as outras linguagens no OS/360 têm um
processador de linguagem específico, que trata programas como dados e os converte em
novos dados que são eventualmente tratados como programas por referências no JCL. Mas
um programa PL/I, por exemplo, não tem mais conexão com o OS/360 do que
um arquivo a ser classificado ou qualquer outra entrada para um programa de processamento.
O desenvolvimento histórico das linguagens de controle de tarefas começou com
a ideia de "alguns cartões de controle" para permitir melhor utilização do hardware.
No começo, esses cartões de controle faziam coisas muito simples e representavam
uma interpretação muito simples de comandos. Mas no OS/360 esses cartões de controle
invocam um controle extensivo de tarefas de gerenciamento de dados e outras atividades,
e a linguagem para invocar essas atividades mais sofisticadas
cresceu um tanto aleatoriamente. Embora o JCL tenha crescido sem
o benefício de um conceito de design motivador central, ele ainda é uma linguagem de programação
e permite o desenvolvimento de um estilo de programação para melhor
entendimento e manutenção de programas JCL. Em particular, o JCL admite uma sintaxe que é razoavelmente direta se suprimirmos as
possibilidades padrão que foram historicamente usadas no JCL para a conveniência
de programadores individuais. Por exemplo, as instruções JCL consistem em um
operador e uma série de operandos opcionais. Esses operandos podem ser agrupados
em um único cartão, de modo que uma linha de JCL pareça muito com algo sem sentido,
ou os operandos podem ser separados, linha por linha, e exibir mais estrutura
e simplicidade para o leitor.
A sintaxe de JCL, que cresceu de forma bastante aleatória,
fornece uma variedade desconcertante de formas - por exemplo, parâmetros ausentes,
várias vírgulas e assim por diante, mas essa variedade pode ser reduzida
em uma extensão considerável sem reduzir a função, tomando certas
formas como preferidas e exibindo-as na sintaxe de forma completa e sempre
aparecendo. Na ilustração, o parâmetro de disposição, DISP, pode ser
configurado simplesmente como NEW para indicar que um conjunto de dados deve ser criado em uma
etapa de trabalho específica. No entanto, se uma disposição no final da etapa do trabalho for necessária,
os parâmetros devem ser definidos como (NEW, OLD), ou seja, não
somente é necessário um segundo suboperando, OLD, mas também incluir
parênteses e uma vírgula separadora. Se, além disso, alguém deseja manipular
uma disposição ABEND para esse conjunto de dados na etapa do trabalho, é necessário
definir um terceiro suboperando, por exemplo, (NEW, KEEP, PASS). Devido
às condições padrão, também é possível encontrar um operando como (NEW, ,
PASS), etc. Uma maneira de simplificar todas essas considerações é simplesmente definir
os operandos de disposição para sempre conter três suboperandos — um para
entrada, um para saída e um para saída anormal — sempre entre parênteses
e separados por vírgulas. Então a sintaxe se torna mais fácil de descrever;
e, de fato, se esses operandos forem sempre escritos, não há
perigo de erros do programador ou mal-entendidos devido a padrões ocultos
. Tal sintaxe é dada na Tabela 10-1.

Programação JCL
Além do vocabulário de JCL e suas funções, buscamos desenvolver uma
racionalidade e estilo para programas escritos nele. Fazemos isso organizando
cada tipo de declaração em uma sequência ordenada de escolhas de parâmetros.
Essa sequência ordenada fornece ao programador uma lista de verificação para garantir que todos
os parâmetros críticos sejam incluídos em uma declaração.
No formato típico, definimos parâmetros, um por linha, para facilitar
a inspeção e interpretação. Os procedimentos catalogados contêm essencialmente
declarações EXEC e DD, e para cada uma dessas declarações JCL, definimos
a seguinte sequência de escolhas de parâmetros.

Programação de cima para baixo em grandes sistemas

Resumo
A programação estruturada pode ser usada para desenvolver um grande sistema em uma
estrutura de árvore em evolução de módulos de programa aninhados, sem controle
ramificação entre módulos, exceto para chamadas de módulo definidas na estrutura
de árvore. Ao limitar o tamanho e a complexidade dos módulos, a depuração de unidade
pode ser feita por leitura sistemática, e os módulos podem ser executados
diretamente no sistema em evolução em um processo de teste de cima para baixo.
Introdução
A programação de grandes sistemas hoje é dominada pelo problema de integração e
depuração porque é comumente assumido que erros de lógica são
inevitáveis ​​em sistemas de programação (em contraste com erros de sintaxe, que
são detectados por tradutores). Não há dúvida de que os programadores são
falíveis e sempre serão. Mas agora parece possível organizar e
disciplinar o design do programa e o processo de codificação para (1) evitar
a maioria dos erros de lógica em primeiro lugar e (2) detectar os erros restantes
com mais segurança e facilidade do que antes.
Usaremos o termo "programação estruturada" para denotar um complexo
de ideias de organização e disciplina no processo de programação.

Existem dois princípios principais envolvidos. Primeiro, começando com uma especificação funcional, mostraremos que é possível gerar uma sequência de sistemas intermediários de código e subespecificações funcionais para que, a cada passo, cada sistema possa ser verificado como correto, ou seja, logicamente equivalente ao seu sistema predecessor. O sistema inicial é a especificação funcional para o programa, cada sistema intermediário inclui o código de seu predecessor e o sistema final é o código do programa. A transitividade dessas equivalências passo a passo garante a correção do código final com relação às especificações funcionais iniciais. O código do programa é gerado de "cima para baixo" nessa sequência de sistemas intermediários. Segundo, também pode ser mostrado que a lógica de controle de cada sistema sucessivo de código e subespecificações funcionais pode ser completamente organizada em termos de algumas estruturas básicas de controle, cada uma com uma única entrada e uma única saída. Três estruturas básicas de controle
suficientes para lógica de controle são (1) sequenciamento simples, (2) IF-THEN-ELSE,
e (3) estruturas DO-WHILE, já conhecidas em várias linguagens, por
exemplo, PL/I [9]. Para eficiência, uma estrutura CASE também pode ser desejável,
por exemplo, conforme definido em PL360 [15].
As expansões iteradas de especificações funcionais e de subespecificações funcionais intermediárias
em código e possivelmente em subespecificações funcionais mais detalhadas
refletem um rigoroso processo passo a passo
de design de programa. Cada subespecificação funcional definida em um sistema intermediário
representa apenas um mapeamento de dados iniciais em dados finais
para algum segmento de codificação ainda a ser especificado. O processo de expansão
descreve os meios selecionados para esse mapeamento, usando possivelmente mapeamentos mais detalhados
a serem descritos de forma semelhante posteriormente.
Em termos tradicionais, esse processo de design de programação é realizado
de cima para baixo no papel, usando fluxogramas ou quaisquer outros objetos conceituais
disponíveis para descrever a estrutura de design selecionada para cada parte do
sistema. Uma vez que o design é concluído, os módulos resultantes definidos são
codificados, testados em unidade, integrados em subsistemas, depois em um sistema e
finalmente depurados como um sistema, em um processo de codificação e teste de baixo para cima.
No processo de programação estruturada, essa estrutura de design é
realizada diretamente no código, que pode ter pelo menos a sintaxe verificada e
possivelmente executada, com stubs de programa representando subespecificações funcionais.
Em vez de fluxogramas de papel, o design estruturado é definido em
código IF-THEN-ELSE e DO-WHILE, que conectam subespecificações
recém-definidas. Na verdade, stubs de programa podem ser usados ​​para simular os
requisitos estimados de núcleo e rendimento do código ainda a ser desenvolvido
para determinadas subespecificações funcionais, durante execuções de sistemas
intermediários.
O processo de expansão funcional pode ser realizado literalmente em
uma página de código por vez, na qual novas subespecificações funcionais são denotadas por nomes de membros fictícios de uma biblioteca de programação, que
eventualmente conterá o código para o próximo nível de expansão. Tal página,
chamada de segmento, é identificada por um nome e uma subespecificação funcional
correspondente no segmento de nível mais alto no sistema de
programação. Os segmentos de um programa formam uma estrutura de árvore.
Uma subespecificação funcional, como um mapeamento de dados iniciais para
dados finais, não tem lógica de controle implícita, e isso é refletido em seu
segmento correspondente. Um segmento tem apenas uma entrada, no topo; e uma
saída, na parte inferior. Se outros segmentos forem nomeados dentro dele, tais segmentos
são, por sua vez, inseridos na parte superior e saídos na parte inferior, de volta ao
segmento de nomenclatura. Como tal, um segmento nomeado se comporta precisamente como uma simples
declaração de transformação de dados (possivelmente bastante complexa, de acordo com sua
subespecificação funcional), sem quaisquer possíveis efeitos colaterais no
controle do programa.
O problema de provar a correção de qualquer expansão de uma
subespecificação funcional é, portanto, reduzido a provar a correção
de um programa de no máximo uma página, na qual possivelmente existem várias
subespecificações nomeadas. A verificação do segmento fornecido requer uma
prova de que a subespecificação do segmento é atendida pelo código e subespecificações nomeadas.
Essas subespecificações nomeadas serão subsequentemente verificadas,
possivelmente em termos de subespecificações ainda mais detalhadas, até que segmentos
com nada além de código sejam alcançados e verificados.
O processo anterior fornece um formato rigoroso para uma atividade
que todos os programadores fazem, mais ou menos, e bons programadores fazem bem,
em projetar programas. Mas ele converte ainda mais o design em código diretamente
e fornece um veículo para manter a integridade do desenvolvimento
sistema passo a passo. A codificação é produzida "de cima para baixo", em vez de
"de baixo para cima", como exigido pelos padrões tradicionais. O código de integração e controle
é produzido antes do código funcional, e nenhuma verificação de unidade de
módulos ocorre. 
Alguns antecedentes
E. W. Dijkstra forneceu vários argumentos esclarecedores para as ideias
de programação estruturada [2, 3, 4] e exibiu uma aplicação substancial
dela no desenvolvimento do sistema T.H.E. [5]. O teorema crítico
de que a lógica de controle de qualquer programa pode ser representada nas
três estruturas básicas de controle de sequenciamento simples, IF-THEN-ELSE e
estruturas DO-WHILE é devido a C. Bohm e G. Jacopini [1]. O resultado
de Bohm e Jacopini permite um novo nível de disciplina no processo de programação
que, como Dijkstra [4] também aponta, pode ajudar a reduzir a termos práticos o problema de provar a correção do programa nos atuais
sistemas de programação reais.
Há vários desenvolvimentos importantes na comprovação da correção do programa
na literatura recente, que no mínimo indicam procedimentos
que os programadores podem seguir na documentação e na argumentação heurística
para a correção dos programas que desenvolvem. Com base nas
ideias de Floyd [6] e Naur [14], London e associados produziram
provas formais de programas substanciais, eles próprios escritos para outros propósitos
sem métodos de prova em mente [8, 12]; King [11] e, mais recentemente,
Good [7] elaboraram essas ideias com procedimentos automáticos e semiautomáticos
para prova.
Na verdade, o problema da correção integra as questões de especificação e
documentação na programação de forma natural, inevitável e
precisa. A documentação de um programa deve fornecer evidências
de que o programa atende às suas especificações funcionais. Não se pode provar que um
programa está correto sem uma definição do que ele deve fazer
sua especificação funcional. E evidências suficientes de que um programa atende
sua especificação funcional podem servir como sua documentação.
Pode parecer à primeira vista que provar que um sistema está correto
(isto é, não se afastar de suas especificações funcionais originais), passo
a passo na implementação, seria agonizantemente lento e totalmente impraticável.
Na verdade, tal impressão está sem dúvida por trás da abordagem usual
de codificação "de baixo para cima" a partir de designs de papel. No entanto, quando as atividades de integração
e depuração são levadas em conta também, então o
processo de construção e verificação passo a passo pode acabar não sendo
tão lento, afinal.
Nosso ponto de vista também está muito próximo dos conceitos de "programação funcional", sob a interpretação de que as especificações funcionais são
de fato funções matemáticas sem efeitos colaterais no controle e que
conectivos IF-THEN-ELSE, DO-WHILE e assim por diante são formas convenientes
para definir funções compostas em termos de outras funções.

A ideia de programas estruturados
Estamos interessados ​​em escrever programas que sejam altamente legíveis, cujas
principais características estruturais sejam dadas em forma hierárquica e estejam
intimamente ligadas às especificações funcionais e documentação. Na verdade,
estamos interessados ​​em escrever programas que possam ser lidos sequencialmente em
pequenos segmentos, cada um com menos de uma página de comprimento, de modo que cada segmento possa

DO I= J TO K;
statement 1
statement 2
statement n
END;
and clauses of IF-THEN-ELSE statements such as
IF X> 1 THEN
statement 1
ELSE
statement

No último caso, se as instruções forem elas próprias blocos DO-END, o
DO, END são recuados um nível e as instruções dentro deles são
recuadas ainda mais, como

IF X> 1 THEN
DO;
END;
ELSE
DO;
END;
statement 1
statement 2
statement k
statement k + 1
statement n

Em geral, DO-END e IF-THEN-ELSE podem ser aninhados um no outro
indefinidamente dessa forma.
Programas estruturados por segmentos
Como pode não ser óbvio no início como um programa estruturado pode
ser desenvolvido, começamos com uma abordagem mais convencional. Suponha que qualquer
programa grande tenha sido escrito em PL/I - digamos, vários milhares de linhas de
código - por qualquer meio de design e codificação disponível. O teorema de
Bohm e Jacopini [1] é provado construtivamente, de modo que é possível,
mecanicamente, transformar o programa que temos em mente em um programa GO TO
livre. Normalmente, usando insight de programação, isso pode ser feito
com pouca perda de eficiência. Agora estamos em posição de imaginar um programa PL/1 de cem páginas já escrito em código GO TO-livre. Embora
seja altamente estruturado, tal programa ainda não é muito legível. A extensão
de um loop DO principal pode ser de 50 ou 60 páginas, ou uma declaração IF-THEN-ELSE
ocupar dez ou 15 páginas. Há simplesmente mais do que o olho pode
confortavelmente absorver ou a mente reter para o propósito de programação.
No entanto, com nosso programa imaginário nesta forma estruturada,
podemos começar um processo que podemos repetir várias vezes até que tenhamos o
programa inteiro definido. Este processo é formular um esqueleto de programa de uma página
que representa aquele programa de cem páginas. Fazemos isso selecionando
algumas das linhas de código mais importantes no programa original e então preenchendo o que está entre essas linhas por nomes. Cada novo nome
será referente a um novo segmento a ser armazenado em uma biblioteca e chamado por um
recurso de macro. Dessa forma, produzimos um segmento de programa com algo
menos de 50 linhas, para que caiba em uma página. Este segmento de programa
será uma mistura de instruções de controle e chamadas de macro, com possivelmente
algumas instruções de inicialização, arquivo ou atribuição também.
O programador deve usar um senso de proporção e importância
na identificação do que é a floresta e quais são as árvores deste
programa de cem páginas. Corresponde a escrever o "fluxograma de alto nível" para o
programa inteiro, exceto que um segmento de programa completamente rigoroso é
escrito aqui. Um aspecto fundamental de qualquer segmento referido por nome é que
seu controle deve entrar no topo e sair na parte inferior, e não ter
outros meios de entrada ou saída de outras partes do programa. Assim, ao
ler um nome de segmento, em qualquer ponto, o leitor pode ter certeza de que
o controle passará por esse segmento e não afetará de outra forma a lógica de
controle na página que está sendo lida.
Para satisfazer o requisito de entrada e saída do segmento, precisamos
apenas ter certeza de incluir todas as instruções lógicas de controle correspondentes em uma página.
Por exemplo, o END para qualquer DO e o ELSE para qualquer IF-THEN devem
ser colocados no mesmo segmento.
Para fins de ilustração, este primeiro segmento pode consistir em algumas
20 instruções lógicas de controle, como DO-WHILEs, IF-THEN-ELSEs, talvez
outras dez instruções de inicialização de chave e algumas dez chamadas de macro.
Essas dez chamadas de macro podem envolver algo como dez páginas de programação
cada, embora possa haver uma variedade considerável entre seus tamanhos.
Agora podemos repetir este processo para cada um desses dez segmentos.
Novamente, queremos escolher cerca de 40 a 50 instruções de controle, nomes de segmento
e assim por diante, que melhor descrevam o caráter geral desse segmento
de programa e relegar mais detalhes para o próximo nível de segmentos.
Continuamos a repetir o processo até que tenhamos contabilizado todo o código
no programa original. Nosso resultado final é um programa, de qualquer tamanho original
qualquer que seja, que foi organizado em um conjunto de segmentos de membros nomeados,
cada um dos quais pode ser lido de cima para baixo sem quaisquer efeitos colaterais
na lógica de controle, além do que está naquela página específica. Um
programador pode acessar qualquer nível de informação sobre o programa, de
dados altamente resumidos nos segmentos de nível superior a detalhes completos
nos níveis inferiores.
Em nossa ilustração, este programa de cem páginas pode se expandir em
cerca de 150 segmentos separados porque (1) os nomes dos segmentos ocupam uma
certa quantidade de espaço e (2) os segmentos, se mantidos em um máximo de uma página,
podem ter em média apenas dois terços completos em cada página. Cada página
deve representar alguma unidade natural do programa, e pode ser natural
preencher apenas metade de uma página em alguns casos.

Criando Programas Estruturados
Na seção anterior, assumimos que um programa de grande porte de alguma forma
existia, já escrito com lógica de controle estruturada, e discutimos como
poderíamos reorganizar conceitualmente o programa em um conjunto de segmentos
mais legíveis. Nesta seção, observamos como podemos criar tais programas
estruturados, um segmento de cada vez, de forma natural. É evidente que os
segmentos de programa, como os definimos, são unidades naturais de documentação e
especificação, e descreveremos um processo que desenvolve código, subespecificações
e documentação simultaneamente. Primeiro, notamos que uma
especificação funcional corresponde à ideia matemática de uma função. É um
mapeamento de entradas em saídas, sem considerar como esse mapeamento pode
ser realizado. Cada segmento definido no desenvolvimento anterior representa
uma transformação de dados, ou seja, um mapeamento de certos valores
iniciais em valores finais. Na verdade, valores intermediários podem ser criados em
dados também. Correspondendo a esse mapeamento de dados iniciais para finais está uma
subespecificação que normalmente será deduzida diretamente da especificação
para o segmento de nomenclatura. Ela representa parte do trabalho a ser feito
no segmento. A página inteira de código e novos nomes de segmento devem
produzir precisamente o mapeamento requerido pela especificação funcional
daquele segmento de nomenclatura.
Quando todos os segmentos nomeados tiverem sido atribuídos a especificações funcionais,
então a ação lógica daquele segmento de nomenclatura pode ser deduzida
do código e daquelas especificações nomeadas. Métodos de comprovação da
correção de programas podem ser aplicados a esta única página. As especificações
podem ser muito complexas para realizar uma prova completamente rigorosa de
correção, mas no mínimo há em uma página uma descrição lógica
de uma função que pode ser comparada heuristicamente com a especificação funcional
para aquele segmento. A argumentação de que a função
de fato duplica a especificação funcional para aquele segmento é a documentação
para aquele segmento.
Nosso ponto principal é observar que o processo de codificação pode ocorrer
praticamente na mesma ordem que o processo de extração de código de
nosso grande programa imaginário na seção anterior. Ou seja, armado com
um design de programa, pode-se escrever o primeiro segmento, que serve como um esqueleto
para todo o programa, usando nomes de segmento quando apropriado para
se referir ao código que será escrito mais tarde. Na verdade, simplesmente tomando a precaução
de inserir membros fictícios em uma biblioteca com esses nomes de segmento
, pode-se compilar ou montar, e até mesmo possivelmente executar, este
programa esqueleto enquanto a codificação restante é continuada. Muitas vezes,
faz sentido colocar uma declaração de gravação temporária, "cheguei aqui OK", como
uma única declaração executável em tal membro fictício. Mais elaboradamente,

um membro fictício pode ser usado para alocar núcleo e simular o tempo de processamento
necessário durante as execuções do sistema intermediário que o contém.
Agora, os segmentos no próximo nível podem ser escritos da mesma
maneira, referindo-se conforme apropriado aos segmentos a serem escritos posteriormente (também configurando
segmentos fictícios conforme são nomeados na biblioteca). À medida que cada segmento fictício
é preenchido com seu código na biblioteca, a recompilação
do segmento que o inclui produzirá automaticamente versões atualizadas e expandidas
do programa em desenvolvimento. Problemas de sintaxe e lógica de controle
geralmente serão isolados dentro dos novos segmentos para que a depuração
e o checkout funcionem correspondentemente bem com tais problemas tão
isolados.
É claro que a criatividade e o senso de proporção
do programador podem desempenhar um grande papel na eficiência deste processo de programação. O
código que entra nas seções anteriores deve ser ditado, até certo ponto,
não apenas por questões gerais de importância, mas também pela questão de
obter segmentos executáveis ​​razoavelmente cedo no processo de codificação. Por
exemplo, se a lógica de controle de um módulo esqueleto depende de certas
variáveis ​​de controle, suas declarações e manipulações podem precisar ser
criadas em níveis razoavelmente altos na hierarquia. Dessa forma, a lógica de controle
do esqueleto pode ser executada e depurada, mesmo no programa esqueleto
ainda.
Observe que vários programadores podem estar envolvidos na atividade anterior
simultaneamente. Uma vez que o programa esqueleto inicial é escrito, cada
programador pode assumir um segmento separado e trabalhar independentemente
dentro da estrutura de um projeto geral de programa. A estrutura hierárquica
dos programas contribui para uma interface limpa entre os programadores.
Em qualquer ponto da programação, os segmentos já existentes fornecem
uma estrutura precisa e concisa para encaixar o resto do trabalho a
ser feito.
Descrição e expansão da função
Observamos acima que o processo de programação estruturada representa
uma expansão passo a passo de uma função matemática em funções matemáticas
mais simples, usando estruturas de controle como IF-THEN-ELSE e
DO-WHILE. Normalmente, pensamos nessa expansão em termos de uma página
de código por vez. No entanto, podemos dividir essa expansão em etapas muito
mais elementares, ou seja, em uma única estrutura de controle por vez.
Neste caso, fazemos a pergunta "Qual instrução de programa elementar
pode ser usada para expandir a função?" A expansão escolhida implicará uma ou mais especificações funcionais subsequentes, que surgem da
especificação original. Cada uma dessas novas especificações funcionais pode ser
tratada exatamente como a especificação funcional original, e as mesmas
perguntas podem ser feitas sobre elas.
Como resultado, o processo de programação de cima para baixo é uma expansão
de especificações funcionais para funções cada vez mais simples até que, finalmente,
as instruções da própria linguagem de programação sejam alcançadas. Parte desse
processo é mostrada abaixo, expandindo a especificação funcional "Adicionar
membro à biblioteca". Essa especificação funcional exigirá mais
descrição, mas a divisão em subfunções por meio de instruções de programação
pode ser realizada conforme indicado aqui.
No exemplo, as letras únicas que identificam os nomes das funções serão
nomes de bibliotecas com vários caracteres, e as pequenas frases entre aspas podem
ser descrições muito substanciais de condições ou processos lógicos.

Técnicas de programação: da arte privada à prática pública
Uma ciência da programação
ARTIGO
12
O computador introduziu uma necessidade de sistemas altamente complexos e formulados com precisão
em uma escala nunca antes tentada. Os sistemas podem ser grandes
e altamente complexos, mas se seres humanos ou mesmo componentes analógicos forem
intrínsecos a eles, então várias tolerâncias de erro são possíveis, que tais
componentes podem ajustar e compensar. Mas um sistema digital, hardware
e software, não apenas torna a ideia de precisão perfeita possível
-ele requer precisão perfeita para operação satisfatória. Essa completa
intolerância ao menor erro dá à programação um novo caráter,
desconhecido anteriormente, em seus requisitos de precisão em grande escala.
A combinação desse novo requisito de precisão e a
demanda comercial por programação de computadores em larga escala
criou muitos valores falsos e relacionamentos distorcidos na última década.
Eles surgem da pressão intensa para atingir resultados complexos e precisos
de forma prática, sem fundamentos teóricos adequados. Como resultado,
uma grande quantidade de programação hoje usa pessoas e máquinas de forma altamente ineficiente,
como o único meio atualmente conhecido para atingir um fim prático.
Uma coisa é entender os mecanismos de um computador como
o OS/360 e escrever um conjunto de operações detalhadas que produzirão
uma folha de pagamento, por exemplo. Outra coisa é produzir um sistema de programação de folha de pagamento que tenha valor técnico intrínseco por si só, valor técnico
que permita que outros o entendam prontamente ou adicionem a ele,
ou permita que ele use o hardware de forma eficiente.
No primeiro caso, tem-se apenas o problema de escrever todas
as condições e casos que podem ocorrer e lidar com eles individualmente
com o repertório de instruções do computador. No segundo caso, tem-se
um problema no design e implementação de sistemas gerais. Este problema
é mal definido, e alta criatividade e habilidade profissional são necessárias
para lidar com ele de forma eficaz.
Existem, desde o início das atividades de programação,
certos princípios gerais da teoria geral de sistemas que bons programadores
identificaram e praticaram de uma forma ou de outra. Isso inclui
desenvolver projetos de sistemas de um nível bruto para mais e mais detalhes
até que o detalhe de um computador seja alcançado, dividir um sistema em módulos
de tal forma que a interação mínima ocorra por meio de interfaces de módulo,
criar bibliotecas de sub-rotinas padrão e usar linguagens de programação
para o processo de codificação.
Esses princípios gerais acabarão se encontrando codificados
e integrados em uma ciência geral da programação. É prematuro
dizer que há uma ciência da programação no momento, mas está
se tornando possível mover a programação de uma arte privada (embora
suportada por vários princípios de maneiras ad hoc) para uma
ciência pública (na qual os processos de trabalho são repetíveis e compreensíveis
por pessoas que não sejam os programadores originais). Uma abordagem de Programador Chefe
liderará nesta área reintroduzindo capacidades técnicas
de alto nível na programação, o que permitirá a propagação de princípios
e seu uso em assuntos práticos, com feedback resultante na
ciência emergente da programação.
Dois Princípios Técnicos Principais
A programação em uma Equipe de Programadores Chefes é baseada principalmente em uma renovação
e uma reaplicação de ideias clássicas no desenvolvimento de sistemas, como
a modularidade do sistema e a construção de interface limpa. No entanto, há
também dois princípios-chave, relativamente novos em sua aplicação à programação,
que desempenham um papel importante na definição das técnicas da Equipe de Programadores Chefes. .
O primeiro princípio técnico-chave é que a lógica de controle de qualquer
sistema de programação pode ser projetada e codificada de uma forma altamente estruturada.
De fato, sistemas de programação arbitrariamente grandes e complexos podem ser representados pela iteração e aninhamento de um pequeno número de estruturas básicas e
de lógica de controle padrão.

Este princípio tem um análogo no design de hardware, onde é
sabe-se que circuitos lógicos arbitrários podem ser formados a partir de portas elementares AND,
OR e NOT. Este é um padrão em engenharia tão difundido
que é quase esquecido como tal. Mas é baseado em um teorema em álgebra booleana
que funções lógicas arbitrariamente complexas podem ser expressas em termos
de operações AND, OR e NOT. Como tal, representa um padrão
baseado em uma base teórica sólida que não requer suporte de gerenciamento ad hoc, caso a caso, na prática real. Em vez disso, é o
fardo de um engenheiro profissional projetar circuitos lógicos a partir desses
componentes básicos. Caso contrário, há dúvidas consideráveis ​​sobre a
competência dessa pessoa como engenheiro.
Uma aplicação prática deste princípio é escrever programas PL/1
sem instruções GO TO explícitas neles. Em vez disso, a lógica de controle de ramificação
pode ser efetuada inteiramente em termos de loops DO e condições IF-THENELSE
e ON. O código resultante é lido estritamente de cima para
baixo, tipograficamente, e é muito mais facilmente compreendido por isso.
É preciso mais habilidade e análise para escrever tal código, mas a depuração e
manutenção são muito simplificadas. Ainda mais importante, tal programação estruturada
pode aumentar o alcance de controle detalhado de um único programador
em uma grande quantidade.
O segundo princípio técnico fundamental é que os programas podem ser codificados
em uma sequência que não requer hipóteses de interface simultâneas. Ou seja,
os programas podem ser codificados de tal forma que cada interface seja definida
inicialmente no próprio processo de codificação e referenciada posteriormente em sua forma
codificada.
Este princípio tem um análogo na teoria de funções computáveis.
O ponto-chave na caracterização de uma função computável é que sua avaliação
pode ser realizada em uma sequência de computações elementares, nenhuma das
que envolve resolver um sistema simultâneo de equações. Qualquer programa
que deve ser executado em um computador pode ser codificado em uma sequência de execução,
e o próprio fato de que o computador avalia apenas funções computáveis
significa que nenhuma interface pode ser definida hipoteticamente e
simultaneamente na computação.
Na aplicação prática, esse princípio leva à programação "de cima para baixo"
onde o código é gerado em uma sequência de execução, por exemplo,
primeiro o código de controle de tarefa, depois o código do editor de vinculação e, então, o código-fonte. O
oposto (e procedimento de implementação típico) é a programação "de baixo para cima",
onde os módulos de origem são escritos e testados em unidade para começar
e depois integrados em subsistemas e, finalmente, sistemas. Esse processo de integração
de fato testa as soluções propostas de problemas de interface simultânea
gerados pela programação de nível inferior; e os problemas de integração e depuração do sistema surgem das imperfeições dessas
soluções propostas. A programação de cima para baixo contorna o problema de integração
pela própria sequência de codificação.
Padrões, criatividade e variabilidade
Muitas reações aos padrões na programação mostram uma confusão básica
entre criatividade e variabilidade. Programar hoje em dia é uma atividade altamente
variável. Dois programadores podem resolver o mesmo problema com
programas muito diferentes; ou seja, os resultados são altamente variáveis. Dois
engenheiros solicitados a projetar um "half adder" com uso econômico de portas
serão muito menos variáveis ​​em suas soluções, mas, na verdade, não menos criativos
do que dois programadores em um projeto de programação típico. Levados ao
extremo, dois matemáticos solicitados a resolver uma equação diferencial podem
usar métodos diferentes de pensar sobre problemas, mas chegarão a
soluções idênticas e ainda serão extremamente criativos no processo.
O processo de programação atual é principalmente escrever todas as
coisas que precisam ser feitas em uma determinada situação. Existem muitas
sequências diferentes que podem realizar a mesma coisa na maioria das situações, e isso
se reflete em extrema variabilidade. Um grande problema na programação
no momento atual é simplesmente não esquecer nada - isto é, lidar com todos os
casos possíveis e inventar quaisquer dados intermediários necessários para realizar
os resultados finais. Assim, enquanto a programação for principalmente o trabalho de
escrever tudo em alguma ordem, ela é de fato altamente variável. Mas
isso em si não é criativo.
É possível ser criativo na programação, e isso lida com
questões muito mais mal definidas, como minimizar a quantidade de dados intermediários
necessários, ou a quantidade de armazenamento de programa, ou a quantidade
de tempo de execução, e assim por diante. Encontrar as profundas simplicidades em uma complicada
coleção de coisas a serem feitas é a criatividade na programação.
No entanto, não são os padrões que inibem essa criatividade no processo de
programação; é simplesmente a falta de criatividade dos próprios
programadores.

Controlando a complexidade por meio de padrões técnicos
Um dos principais propósitos na criação de novos padrões técnicos em programação
é controlar a complexidade. A complexidade na programação parece às vezes
ser uma "mercadoria gratuita". Ela não aparece no núcleo ou no tempo de processamento, e sempre parece ser algo que pode ser tratado indefinidamente
no nível local.
Nesse contexto, é uma digressão esclarecedora lembrar que
500 anos atrás, ninguém sabia que o ar tinha peso. Imagine, por exemplo,
as frustrações de um fabricante de bombas d'água, construindo bombas para tirar
água de poços. Ao apertar as vedações, pode-se elevar a água cada vez
mais alto - cinco pés, dez pés, depois 15 pés e assim por diante, até chegar a 34
pés. Assim que se sabe que o ar tem peso e é, de fato, o
peso de uma coluna de 34 pés de água, então a frustração desaparece
imediatamente. Conhecer o peso do ar permite um melhor projeto de bomba, por
exemplo, em bombas de múltiplos estágios, se a água tiver que ser elevada mais de
34 pés.
Temos uma situação semelhante na programação hoje. A complexidade
tem um "peso" de algum tipo, mas não sabemos qual é. Sabemos
cada vez mais pela experiência prática que a complexidade cobrará seu
preço de forma qualitativa, mas ainda não podemos medir essa complexidade em
termos operacionais que, por exemplo, nos fariam rejeitar um
módulo de programa porque ele tinha "muitas unidades de complexidade nele". (Essas
unidades de medida estarão, com toda a probabilidade, em "bits de informação". Mas
como efetuar as medições ainda requer desenvolvimento e refinamento.)
No entanto, temos noções qualitativas de complexidade, e os padrões
podem ser usados ​​para controlar a complexidade de forma qualitativa, quer
possamos medi-la efetivamente ou não. Um tipo de padrão que podemos usar para
controlar a complexidade é estrutural, como no primeiro princípio observado acima.
Então podemos exigir que os programas sejam escritos em certas formas estruturais
em vez de serem simplesmente gráficos de controle complexos arbitrários gerados à
vontade do programador. A base técnica para o padrão é mostrar que
fluxogramas arbitrariamente complexos podem ser reformulados em termos equivalentes como
fluxogramas altamente estruturados que satisfazem certos padrões. Isso é como
teoremas na álgebra booleana que afirmam a priori que meio somadores podem ser
escritos em termos de portas AND, OR e NOT.
Nós definimos, por meio de padrões, processos de trabalho que são mais repetíveis.
As pessoas podem pensar de forma diferente sobre o mesmo problema, mas, assim como
os matemáticos acima, podem chegar à mesma equação diferencial.
Quando os problemas e padrões são suficientemente bem declarados,
as pessoas chegarão às mesmas respostas. Na programação no momento,
não definimos nem os problemas nem as ferramentas com padrões suficientes,
mas à medida que melhoramos nossos padrões, os processos de trabalho na programação
se tornarão cada vez mais repetíveis em termos de resultados finais.

Programação Estruturada
Há novos resultados na teoria dos grafos que mostram que a lógica de controle de
qualquer sistema de programação pode ser projetada e codificada de uma forma
altamente estruturada. Qualquer sistema de programação, não importa quão grande ou complexo, pode ser
representado como um conjunto finito de fluxogramas (mecanismos de interrupção de hardware
podem ser usados ​​para transferir o controle de um fluxograma para outro em tal
sistema de programação). Os novos resultados teóricos lidam com a conversão
de fluxogramas arbitrariamente grandes e complexos em formas padrão para que eles
possam ser representados pela iteração e aninhamento de um pequeno número de estruturas lógicas de controle básicas e
padrão.
Um conjunto suficiente de estruturas lógicas de controle básicas consiste em três
membros:
1. Uma sequência de duas operações (Figura 12-1).
2. Uma ramificação condicional para uma de duas operações e reunidas (uma
instrução IF-THEN-ELSE) (Figura 12-2).
3. Repetir uma operação enquanto alguma condição é verdadeira (uma
instrução DO-WHILE) (Figura 12-3)

O teorema básico (devido a Bohm e Jacopini, "Flow Diagrams,
Turing Machines, and Languages ​​with Only Two Formation Rules,"
Comm. ACM 9, maio de 1966) é que qualquer fluxograma pode ser representado em
uma forma equivalente como uma estrutura iterada e aninhada nessas três figuras básicas
e padrão.
Observe que cada estrutura tem uma entrada e uma saída e pode
ser substituída por qualquer caixa em uma estrutura, de modo que fluxogramas complexos podem
resultar. O ponto-chave (não óbvio aqui) é que um fluxograma arbitrário
tem um representante equivalente na classe assim construída. De fato, a Figura
12-1, uma sequência simples, é tão natural que rivaliza com o número zero (em
álgebra) na dificuldade de sua descoberta como uma figura estrutural genuína.
Desnecessário dizer que não há nenhuma razão convincente na programação para
usar um conjunto tão mínimo de figuras básicas, e parece prático aumentar
a declaração DO com diversas variações, como "loops Fortran
DO" comuns para fornecer mais flexibilidade para programadores e
maior adaptabilidade a características dadas da máquina.
Quando convertido em termos PL/I, o teorema anterior demonstra
que programas PL/I podem ser escritos em termos de declarações IF-THEN-ELSE
e DO-WHILE. Observe que a ideia de um GO TO geral
nunca é introduzida nessas estruturas básicas e, portanto, nunca é necessária em uma
representação. Por questões de eficiência, pode-se de fato desejar
usar GO TOs ocasionalmente em alguns programas PL/I, mas não por
nenhuma necessidade lógica. O uso de GO TOs pode ser feito em uma base de exceção,
de modo que justificativa e documentação especiais seriam necessárias
em qualquer uso desse tipo.
Uma característica importante de programas escritos nessas estruturas é
que eles podem ser literalmente lidos de cima para baixo tipograficamente; não
nunca há nenhum "salto" como é tão típico ao tentar ler código que contém GO TOs gerais. Essa propriedade de legibilidade é uma grande
vantagem na depuração, manutenção ou referência de código em
momentos posteriores. Outra vantagem de benefício possivelmente ainda maior é o
trabalho adicional de design de programa que é necessário para produzir tal
código estruturado. O programador deve pensar no problema de processamento,
não apenas anotando tudo o que precisa ser feito, mas anotando
de tal forma que não haja reflexões posteriores com subsequentes
saltos e saltos para trás nem uso indiscriminado de uma seção de código
de vários locais porque "simplesmente acontece" de fazer algo no
momento da codificação. Em vez disso, o programador deve pensar na lógica de controle
do módulo completamente de uma vez, a fim de fornecer a
estrutura estrutural adequada para o controle. Isso significa que os programas
serão escritos de maneiras muito mais uniformes porque há menos liberdade
para variedade arbitrária do que há com GO TOs gerais.
Essa programação estruturada também pode ser realizada na linguagem assembly do OS/360
usando recursos de macroprocessamento. O macroprocessamento 360
é suficientemente poderoso para permitir que macros de estrutura de bloco padrão
sejam desenvolvidas para que programas em linguagem assembly possam ser escritos sem
rótulos de instruções ou ramificações, exceto aqueles gerados nas macros padrão.
A linguagem assembler também tem facilidade suficiente (embora raramente
seja usada) para permitir a representação tipográfica da lógica de controle por meio de
recuo, ou seja, para que o código aninhado (dentro de um loop DO, por
exemplo) seja recuado para mostrar esse aninhamento tipograficamente.
Espera-se que os programadores-chefes escrevam em formas
altamente estruturadas; isso representa um alto grau de criatividade da parte deles. Isso serve
a uma função importante ao permitir a comunicação em um nível preciso entre
o programador-chefe e o programador de backup e quaisquer outros programadores
a quem a codificação é delegada. Ou seja, o programador-chefe
espera ler e entender todo o código que entra no sistema, não
importa quem o escreveu. Se outros escreverem código na mesma estrutura de blocos
de maneira, isso facilita a leitura do código pelo Programador Chefe para verificar
seu conteúdo e correção para o sistema em desenvolvimento.

Programação de cima para baixo
Há um novo princípio na implementação do sistema que tem sido seguido
intuitivamente no desenvolvimento de módulos (mas não no desenvolvimento de sistemas) por
algum tempo. É produzir código em sequência de execução, ou seja, codificar
somente instruções que podem ser executadas pela máquina porque todas as instruções
anteriores necessárias já foram codificadas. Observe que esse princípio está sendo aplicado aqui à sequência na qual o código é criado, não
à sequência na qual ele é executado.
Em geral, o desenvolvimento do sistema evoluiu como um processo "de baixo para cima",
onde os módulos de nível mais baixo são codificados, depois o próximo nível,
até os subsistemas e sistemas. Na abordagem de cima para baixo, o código de nível do sistema é escrito primeiro, depois o código do subsistema e assim por diante, até
os níveis mais baixos de código.
Essas duas formas de codificação têm uma contrapartida direta na teoria
de funções computáveis. Funções computáveis ​​têm a propriedade, em qualquer
ponto de computação, de que todos os elementos necessários para calcular o próximo
valor já foram computados. Isto é, nunca se incorre em um conjunto de
equações simultâneas, mesmo que essas equações possam ser bem definidas
e tenham uma solução única. Note que uma solução para um sistema de
equações lineares simultâneas não está incluída na teoria de funções computáveis;
mas um algoritmo para resolver tal sistema (em etapas finitas)
está incluído.
Seria possível desenvolver uma teoria muito mais complexa de computabilidade
na qual equações simultâneas fossem permitidas. Tal teoria
poderia exigir que em cada ponto de computação existisse um conjunto de
equações para várias variáveis ​​que tivessem uma solução única. Seria
muito mais complexo do que a teoria comum de funções computáveis,
e nenhum desenvolvimento real de tal teoria estendida sequer existe.
No entanto, é este último processo altamente complexo que tem
acontecido no desenvolvimento do sistema o tempo todo. Isto é, enquanto codificam nos
módulos de baixo nível na abordagem de baixo para cima, os programadores estão assumindo
interfaces hipotéticas. Isto é, eles estão tentando resolver "equações
de interface simultâneas" em seu processo de programação para chegar a um
conjunto consistente de módulos de baixo nível. O próximo nível de módulos verifica essas consistências,
e, de fato, uma grande parte da depuração e retrabalho é
geralmente necessária por causa de inconsistências inadvertidas que aparecem. Este
processo de combinar mais e mais módulos representa, em uma teoria
de computabilidade, o processo de resolver equações de interface simultâneas em
níveis cada vez mais altos até que finalmente todo o sistema de interface tenha sido
"resolvido" ou o programa tenha sido depurado.
Em contraste, o princípio definido acima segue a abordagem
de função computável. A prova de que isso é possível vem diretamente
da execução da máquina em si. O hardware não pode executar dados hipotéticos.
Sua função é sempre produzir novos dados a partir de dados antigos de uma forma
computável.
Em termos de programação, isso significa que um conjunto de dados externo deve
ser definido em seu formato, e assim por diante, antes que um arquivo possa acessá-lo. O arquivo
deve ser definido com seus registros antes que um programa possa fazer uso de dados
dele, e assim por diante. Observe no processo que não há interfaces hipotéticas e nenhum ponto lógico em que confusão ou mal-entendido
possa surgir. A falibilidade humana não pode ser eliminada, mas podemos eliminar
a comunicação hipotética da interface, e isso pode de fato eliminar
a maioria dos erros que agora são cometidos por meio da falibilidade humana
na programação.
À primeira vista, a ideia de programação de cima para baixo pode soar
proibitiva em termos de tempo de codificação decorrido. É típico em um grande projeto
começar a codificação nos níveis mais baixos cedo porque parece haver
muito disso e a sensação é que será o gargalo no desenvolvimento
processo. Isso provavelmente acabará sendo falso; é como!
que o que realmente acontece em projetos é que no momento da integração.
os programas são verificados, modificados e corrigidos com mais do que tempo suficiente
despendido neles para escrevê-los do início para firmar interfaces.
Para muitos sistemas de programação, não se espera que escrever de cima para baixo leve
mais tempo decorrido do que escrever de baixo para cima, particularmente com as
linguagens de alto nível e recursos de macroprocessamento que estão disponíveis
hoje.
Há outra faceta dos padrões de implementação de sistemas e da
abordagem de cima para baixo. Ela lida com uma ideia chamada "programação de linha principal".
Normalmente, a maioria dos programas tem caminhos que podem ser chamados de caminhos de linha principal
porque esse é o caminho de controle esperado para a execução típica do programa
e o código de "exceção" adicional que lida com condições incomuns ou de erro.
É comum no desenvolvimento de programação escrever código de linha principal
e fazê-lo rodar primeiro e então escrever dados de exceção mais tarde
em um ritmo mais lento. Isso pode ser feito na abordagem de cima para baixo
simplesmente reconhecendo que dados de depuração podem ser escritos de cima para baixo
também. Ou seja, dados de depuração devem ser escritos para exercitar o caminho de linha principal
para começar, e ser aumentados mais tarde, conforme caminhos de exceção são desenvolvidos
no código, para exercitar esse código. Novamente, o princípio é exatamente o
mesmo, só que agora em relação a dados de depuração e código de programação como uma unidade
em uma abordagem de cima para baixo. (Deve ser destacado aqui que os dados de depuração
são diferenciados dos dados de teste, que são definidos no ponto de especificação funcional
do sistema e não são mencionados aqui. Os dados de depuração
referidos aqui são usados ​​no desenvolvimento para identificar a falibilidade do programador
e servem como uma verificação contínua no desenvolvimento do sistema até o momento
para o programador. Claro, na aceitação o sistema deve ser submetido
a dados solicitados por especificações funcionais, mas isso é considerado
como um assunto separado, fora do desenvolvimento da programação em si.)
No OS/360, por exemplo, o controle de tarefas, editor de vinculação, "supervisão"
e "gerenciamento de dados" código-fonte é escrito nessa ordem, e somente
então os módulos-fonte que normalmente dão a um sistema sua capacidade funcional.
Assim, o desenvolvimento do sistema prossegue por meio da adição controlada
de novos módulos a um sistema sempre verificado. Ou seja, programas de supervisão são executados no início da fase de desenvolvimento, primeiro chamando módulos
fictícios nos quais módulos funcionais posteriores podem ser substituídos. O sistema
é então desenvolvido expandindo o conjunto de módulos que ele pode chamar e
executar. Neste processo, o Programador Chefe pode manter controle completo
e direto sobre o sistema, geralmente tendo escrito o núcleo e
especificando e verificando pessoalmente os módulos produzidos por outros
programadores ou especialistas no próprio ambiente do sistema para o qual eles
são destinados.
A abordagem de cima para baixo permite o uso efetivo de linguagens do OS/360
em um projeto. Não importa o que seja escrito em memorandos ou discutido em
reuniões, a máquina acabará lendo o que é perfurado em cartões em
linguagens do OS/360. Conceitos que não podem ser declarados em linguagens do OS/360
não podem ser utilizados na máquina. Em vez disso, as especificações de interface do módulo
podem ser feitas inteiramente em linguagens do OS/360, com menos oportunidade para mal-entendidos
e erros. Como foi observado, na abordagem de programação de cima para baixo
não há programação para interfaces hipotéticas ou temporárias;
cada interface é definida em um ponto logicamente definido no projeto
e usada como uma referência totalmente especificada a partir daí.
Fundamentos matemáticos para programação estruturada
Introdução

O primeiro nome em programação estruturada é Edsger W. Dijkstra (Holanda),
que originou um conjunto de ideias e uma série de exemplos para
pensamento claro na construção de programas. Essas ideias são poderosas
ferramentas para conectar mentalmente o texto estático de um programa com o dinâmico
processo que ele invoca na execução. Essa nova correspondência entre programa
e processo permite um novo nível de precisão na programação.
De fato, é argumentado aqui que a precisão agora possível na programação
mudará suas características industriais de uma atividade frustrante de tentativa e erro
para uma atividade sistemática e com controle de qualidade.
No entanto, para introduzir e impor tal programação de precisão
como uma atividade industrial, as ideias de programação estruturada
devem ser formuladas como padrões técnicos, não simplesmente como boas ideias para
serem usadas quando conveniente, mas como princípios básicos que são sempre válidos.
Um bom exemplo de um padrão técnico ocorre no projeto de circuitos lógicos.
Lá, sabe-se a partir de teoremas básicos em álgebra booleana que qualquer circuito lógico, não importa quão complexo seja seu requisito, pode ser construído usando apenas portas AND, OR e NOT. Nosso interesse é semelhante: fornecer uma garantia matemática, para fins de gerenciamento, de que um padrão técnico é sólido e prático. Essa garantia matemática se deve, em grande parte, a Corrado Bohm e Giuseppe Jacopini (Itália), que mostraram como provar que lógicas de controle de programa relativamente simples (estruturadas) eram capazes de expressar quaisquer requisitos de programa. A experiência prática inicial com programação estruturada indica que há mais do que um lado técnico na questão. Há um efeito psicológico também, quando os programadores aprendem sobre seu novo poder de escrever programas corretamente. Esse novo poder motiva, por sua vez, um novo nível de concentração, o que ajuda a evitar erros de descuido. Essa nova psicologia de precisão tem uma contrapartida matemática na teoria da correção do programa, que formulamos de uma nova maneira. A abordagem matemática que adotamos na formulação de programação estruturada
e o problema de correção enfatiza esses aspectos combinatórios
para demonstrar aos programadores que a programação correta
envolve apenas seleção combinatória e não problemas que exigem
precisão perfeita em uma escala contínua. Por isso, estamos confiantes
de que os programadores logo trabalharão em um nível de produtividade e precisão
que parecerá incrível em comparação com a experiência inicial com o
problema de programação.

Complexidade e precisão na programação
O computador digital introduziu uma necessidade de sistemas lógicos altamente complexos,
formulados com precisão, em uma escala nunca antes tentada. Os sistemas
podem ser grandes e altamente complexos, mas se seres humanos, ou mesmo dispositivos analógicos,
forem componentes neles, então várias tolerâncias de erro são possíveis,
às quais tais componentes podem se ajustar e compensar. No entanto,
um computador digital, em hardware e software, não apenas torna a
ideia de precisão perfeita possível - ele requer precisão perfeita para uma operação
satisfatória. Essa intolerância completa ao menor erro lógico
dá à programação um novo caráter, pouco conhecido anteriormente, em seus requisitos
de precisão em larga escala.
A combinação desse novo requisito de precisão e a
demanda comercial por programação de computadores em larga escala
criou muitos valores falsos e relacionamentos distorcidos na última década.
Eles surgem da pressão intensa para atingir resultados complexos e precisos
de forma prática, sem fundamentos técnicos adequados. Como resultado, uma·
grande parte da programação usa pessoas e computadores de forma altamente ineficiente.
como o único meio atualmente conhecido para atingir um fim prático.
É universalmente aceito hoje que a programação é uma atividade propensa a erros. Presume-se que qualquer grande sistema de programação tenha erros;
apenas os muito ingênuos acreditariam no contrário. O processo de depuração
de programas e sistemas é uma arte misteriosa. De fato, mais tempo do programador
é gasto na depuração do que no design e codificação de programas na maioria dos grandes
sistemas. Mas praticamente não há literatura sistemática sobre esse grande
empreendimento.
No entanto, embora erros na lógica do programa sempre tenham sido uma fonte
de frustração, mesmo para os mais cuidadosos e meticulosos, isso pode não ser
necessariamente assim no futuro. A programação é muito jovem como atividade humana -
cerca de 20 anos. Ela praticamente não tem fundamentos técnicos ainda.
Imagine a engenharia quando tinha 20 anos. Seja em 1620
ou 1770, ela também não estava em muito boa forma técnica naquele estágio! À medida que
fundamentos técnicos são desenvolvidos para a programação, seu caráter
sofrerá mudanças radicais.
Afirmamos aqui que tal mudança radical é possível agora, que
na programação estruturada as técnicas e ferramentas estão à mão para permitir
um nível inteiramente novo de precisão na programação.

Este novo nível de precisão será caracterizado por programas de
grande tamanho (de dezenas de milhares a milhões de instruções) que têm um
tempo médio entre erros detectados de um ano ou mais. Mas para atingir
esse nível de precisão, uma nova atitude em relação às expectativas de programação
será necessária também nos programadores.

A Psicologia da Precisão
Uma criança pode aprender a jogar o jogo da velha perfeitamente, mas uma pessoa
nunca pode aprender a serrar um tabuleiro exatamente ao meio. Jogar jogo da velha é um
problema combinatório, selecionando a cada alternativa uma de um número finito
de possibilidades. Serrar um tabuleiro exatamente ao meio é um problema físico
para o qual nenhum nível discreto de precisão é suficiente.
A criança que aprendeu a jogar jogo da velha nunca precisa cometer um
erro, exceto por perda de concentração. Em qualquer jogo que a criança
acredite importante (digamos, jogado por uma barra de chocolate), ela é capaz
de jogar perfeitamente.
A programação de computadores é uma atividade combinatória, como jogo da velha,
não como serrar um tabuleiro ao meio. Não requer resolução perfeita em
medição e controle; requer apenas escolhas corretas de conjuntos finitos
de possibilidades a cada passo. A diferença entre jogo da velha e
programação de computadores é a complexidade. O propósito da programação estruturada
é controlar a complexidade por meio da teoria e disciplina. E com
a complexidade sob melhor controle, agora parece que as pessoas podem escrever programas de computador
substanciais corretamente. Na verdade, assim como uma criança passa de tatear e frustração para confiança e competência no jogo da velha,
as pessoas agora podem encontrar terreno sólido para o desenvolvimento de programas.
As crianças, ao aprender a jogar jogo da velha, logo desenvolvem um pouco de teoria,
lidando com "quadrados centrais", "quadrados de canto", "quadrados laterais" e a
autodisciplina para bloquear possíveis derrotas antes de construir suas
próprias ameaças. Na programação, teoria e disciplina são críticas também no nível de atividade intelectual de um adulto. A programação estruturada é uma dessas teorias,
fornecendo uma maneira sistemática de lidar com a complexidade no design e desenvolvimento de programas. Ela torna possível uma disciplina para design e
construção de programas em um nível de precisão não possível anteriormente.
Mas para crianças, saber jogar jogo da velha perfeitamente não é
suficiente. Elas devem saber que sabem. Esse conhecimento de que sabem é um
ingrediente vital na autodisciplina — saber que são capazes de analisar
o tabuleiro e não precisam adivinhar e esperar.
É o mesmo com programadores. Se os programadores sabem que o que
está em suas mentes está correto, então colocar isso no papel precisamente é mais
importante, assim como verificar detalhes de definições de dados e o que quer que seja, no
processo de codificação. Por outro lado, se os programadores pensam que o que está em
suas mentes provavelmente está certo, mas estão subconscientemente contando com depuração
e execuções de integração para resolver erros de lógica e interface, então
todo o processo de colocar isso no papel e no computador sofre
de pequenas maneiras para depois atormentá-los.
É preciso algum aprendizado por parte de programadores experientes para
descobrir que programas estruturados podem ser escritos com
precisão lógica e de interface sem precedentes. Assim como com a criança, não basta ser
capaz de programar com precisão. Os programadores devem conhecer suas capacidades
para programação de precisão a fim de fornecer a concentração para corresponder
às suas capacidades.

O Problema da Complexidade
Quinhentos anos atrás, não se sabia que o ar que respiramos e
atravessamos tão livremente tinha peso. É difícil colocar o ar em uma balança, ou mesmo
identificar como qualquer quantidade específica para pesagem. Mas agora sabemos
que o ar tem peso — ao nível do mar, o peso de uma coluna de água de 34 pés
de altura.
É fácil imaginar, em retrospectiva, as frustrações de um fabricante de bombas
de poço, cujo "departamento de pesquisa" está operando na teoria
de que "a natureza abomina o vácuo". A água pode ser elevada em um cano de poço 15,
20, depois 25 pés, usando um êmbolo e apertando suas vedações cada vez
melhor. Tudo isso parece apenas confirmar a "teoria atual" sobre a operação de tais bombas. Mas a 35 pés, a frustração total se instala. Não importa
quão apertadas sejam as vedações, a água não pode ser elevada.
Na programação de computadores hoje, ainda não sabemos que "complexidade
tem peso". Como não é facilmente medido ou descrito, como requisitos de armazenamento
ou rendimento, muitas vezes ignoramos a complexidade de um programa ou subprograma
planejado. Mas quando essa complexidade excede certos limites
desconhecidos, a frustração se instala. Programas de computador naufragam sob seu
próprio peso lógico ou se tornam tão incapacitados que a manutenção é precária
e a modificação é impossível. Problemas de armazenamento e rendimento podem
sempre ser corrigidos, de uma forma ou de outra. Mas problemas de complexidade podem
raramente ser adequadamente reconhecidos, muito menos corrigidos.
A síndrome de criar problemas insolúveis de complexidade por causa
de problemas antecipados de armazenamento e rendimento é bem conhecida.
É o trabalho de amadores. Surge em uma arrogância equivocada de que "o que
aconteceu com eles não vai acontecer comigo!" Mas continua acontecendo,
e de novo.

A Ideia de Programação Estruturada
Intimamente relacionada a muitas ideias originais de E. Dijkstra [1 0] e usando resultados-chave de C. Bohm e G. Jacopini [5], P. Naur [31] e R. Floyd [13],
a programação estruturada é baseada em novos fundamentos matemáticos para
programação (em contraste com o uso da programação para implementar processos matemáticos
ou estudar fundamentos da matemática). Ela identifica
o processo de programação com uma expansão passo a passo de funções matemáticas
em estruturas de conectivos lógicos e subfunções, realizadas
até que as subfunções derivadas possam ser diretamente realizadas na linguagem de programação
que está sendo usada. A documentação de um programa é identificada
com prova da correção dessas expansões. Aspectos dessa abordagem
são ilustrados também no trabalho de Ashcroft e Manna [3], Hoare [17],
e Wirth [39]. Uma aplicação importante para um sistema de programação de tamanho
considerável é descrita por Baker [4].
Quatro resultados matemáticos são centrais para essa abordagem. Um resultado,
um "Teorema da Estrutura" devido em forma original a Bohm e Jacopini, garante
que qualquer lógica de programa de fluxograma pode ser representada por expansões
de apenas três tipos de estruturas, por exemplo, (1) f THEN
/?, (2) IF p THEN f ELSE g, (3) WHILE p DOt, onde f e g são
fluxogramas com uma entrada e uma saída, p é um teste, e THEN, IF, ELSE,
WHILE e DO são conectivos lógicos. Isso está em nítido contraste com a
prática de programação usual de fluxograma de lógica de controle arbitrária com
operações de ramificação de controle irrestritas.

Em linguagens de programação estruturadas em blocos, como Algol ou PL/I,
tais programas estruturados podem ser livres de GO TO e podem ser lidos sequencialmente
sem pular mentalmente de um ponto a outro. Em um sentido mais profundo
a propriedade livre de GO TO é superficial. Programas estruturados devem ser
caracterizados não simplesmente pela ausência de GO TOs, mas pela presença
de estrutura. Programas estruturados podem ser organizados em árvores de
"segmentos" de programa, de modo que cada segmento tenha no máximo algum
tamanho prescrito, por exemplo, uma página (cerca de 50 linhas) de comprimento, e com entrada apenas
no topo e saída na parte inferior do segmento. Segmentos se referem a outros
segmentos no próximo nível em tais árvores, cada um por um único nome, para representar
uma operação de processamento de dados generalizada naquele ponto, sem efeitos colaterais
no controle. Dessa forma, o tamanho e a complexidade de qualquer sistema de programação
podem ser manipulados por uma estrutura de árvore de segmentos, onde cada segmento, seja
de alto ou baixo nível na hierarquia do sistema, é de tamanho e complexidade precisamente
limitados. O Teorema da Estrutura tem uma prova construtiva, que por si só fornece
insights sobre técnicas de design e construção de programas. Embora
um fluxograma possa ser de qualquer tamanho, o Teorema da Estrutura garante que sua
lógica de controle pode ser representada em uma base finita, com uma correspondente
redução na complexidade característica de fluxogramas arbitrários. O
Teorema da Estrutura também fornece uma forma canônica para documentar e
validar programas, para ajudar a definir procedimentos operacionais na programação.
O segundo resultado matemático é um "Corolário de Cima para Baixo", que
garante que programas estruturados podem ser escritos ou lidos "de cima para baixo",
isto é, de tal forma que a correção de cada segmento de um programa
depende apenas de segmentos já escritos ou lidos e das especificações
funcionais de quaisquer segmentos adicionais referidos pelo nome. A aplicação
deste corolário requer uma mudança radical na maneira como a maioria dos programadores
pensa hoje, embora os defensores da "programação funcional" tenham
proposto tais ideias independentemente (como Zurcher e Randell [40], Landin
[22], Strachey [37], Burge [6] e Scott [35]). É uma prática quase universal
no momento atual escrever grandes programas "de baixo para cima" - codificação
e teste de unidade de módulos de programa, depois subsistemas e, finalmente, integração e teste de sistemas. Na programação de cima para baixo, o código de integração
é escrito primeiro, no sistema, depois nos níveis de subsistema, e os módulos
funcionais são escritos por último. Conforme discutido por Mills [29], de cima para baixo programação
pode eliminar a necessidade de suposições de interface simultâneas
que frequentemente resultam em erros de sistema durante a integração.
O terceiro resultado matemático é um "Teorema da Correção", que
mostra como o problema da correção de programas estruturados pode ser
reduzido a questões teóricas de função às quais práticas matemáticas
padrão se aplicam. Essas questões necessariamente entram no contexto de intenções e operações disponíveis para escrever programas. Normalmente, elas
exigirão estruturas e procedimentos matemáticos específicos para sua resolução.
De fato, para programas complexos, a questão matemática pode ser
mais abrangente e detalhada do que é prático resolver em algum nível aceitável
de rigor matemático. Em qualquer caso, as questões podem ser formuladas
em uma base sistemática, e julgamentos técnicos podem então ser aplicados
para determinar o nível de validação que é viável e desejável para um
determinado programa.
Nesta conexão, notamos que a matemática consiste em um conjunto de
práticas lógicas, sem nenhuma reivindicação inerente de rigor ou verdade absolutos (por
exemplo, veja Wilder [38, p. 196]). A matemática é uma invenção humana e
sujeita a falibilidades humanas, apesar da aura de verdades sobrenaturais
frequentemente encontradas em um mundo escolar. Mesmo assim, a redução do problema
dos significados do programa a tais práticas matemáticas permite a classificação
e tratamento de ideias em termos de processos que foram submetidos
a consideráveis ​​análises e críticas pela humanidade.
O quarto resultado matemático é um "Teorema da Expansão", que
define a liberdade disponível na expansão de qualquer especificação funcional
em uma estrutura no próximo nível. Talvez o aspecto mais surpreendente
deste resultado seja quão pouca liberdade um programador tem em expandir corretamente
programas de cima para baixo. Por exemplo, ficará claro na definição da estrutura
"SE p ENTÃO f SENÃO g" que a escolha de p define automaticamente f e
g - que a única liberdade em tal estrutura está em seu predicado. Ainda mais
surpreendente é o resultado de que na expansão "WHILE p DO f" não existe liberdade
na seleção de p - o predicado de loop será visto
como totalmente determinado pela própria especificação funcional.

Nossa motivação neste resultado final é exibir a programação como uma
análise, em vez de uma síntese, atividade, ou seja, identificar o processo de programação de cima para baixo
como uma sequência de decomposições e partições de
especificações e subespecificações funcionais, cada uma das quais produz
subespecificações mais simples de lidar, até que finalmente o nível de instruções ou declarações da linguagem de programação
seja alcançado. Isso contrasta com a programação
como uma síntese de instruções ou declarações que "realizam"
as especificações funcionais. É nessa distinção que a programação
surge como uma atividade combinatória prontamente percebida.
A Correção de Programas Estruturados
Com a programação estruturada, os programadores são capazes de programação de alta
precisão, mas, como no jogo da velha, é importante para sua concentração
conhecer sua própria capacidade para essa alta precisão. O Teorema da Correção
fornece conceitos e procedimentos para realizar essa precisão na programação. As provas de correção são demonstrações de criação humana para
consumo humano. Não existe uma prova absoluta de
correção lógica. Existem apenas graus de rigor, como "inglês técnico", "prova de periódico matemático", "lógica formal" e assim por diante, cada um dos quais é uma descrição informal de mecanismos para criar acordo
e crença em um processo de raciocínio.
É claro que todo um espectro de rigor será útil em provas de
correção. Um programa casual, usado em uma investigação experimental, pode
garantir não mais do que algumas linhas de explicação. Um programa muito usado
- digamos, um editor de texto ou um compilador - pode garantir uma
prova muito mais formal. London forneceu vários exemplos realistas de prova em um
nível matemático [23, 24, 25], incluindo a prova de um
compilador LISP otimizador. Jones [20] deu um exemplo de uma prova em termos mais formais.
King [21] e Good [14] desenvolveram máquinas mais automáticas.
Dijkstra [9] ilustrou ideias menos formais que podem ser ainda mais convincentes
em alguns programas. A persuasão de uma prova depende não apenas
de sua formalidade, mas de sua brevidade. Infelizmente, formalidade e brevidade
não costumam cooperar, e o programador tem um problema de equilíbrio difícil
na seleção do melhor compromisso entre formalidade e brevidade.
Nossa abordagem é funcional (ou denotacional, como usada por Ashcroft
[2]), em vez de computacional; em vez de provar afirmações sobre etapas computacionais
em um programa (como introduzido por Naur [32], Floyd [12],
e outros), formulamos afirmações sobre funções cujos valores são
computados por programas e subprogramas. Nessa abordagem, a definição teórica de conjuntos
de uma função como um conjunto de pares ordenados é de conveniência crítica.
Por exemplo, um subprograma IF-THEN-ELSE corresponde a uma partição
de uma função correspondente em dois subconjuntos de pares ordenados, que, como
subfunções, correspondem à cláusula THEN e à cláusula ELSE do
subprograma original.
Conforme observado, programas estruturados admitem decomposições em subprogramas
de tipos muito simples, como os subprogramas THEN, IF-THEN-ELSE e DOWHILE
. Nosso principal interesse é mostrar que cada tipo leva
a uma afirmação lógica característica sobre a correção de um subprograma.
Essas afirmações são eventualmente incorporadas em questões teóricas de funções,
lidando com composição e partição de funções; por exemplo, para alguns
conjuntos f, g, h, (não necessariamente distintos), deve ser provado que
f=g*h ou f = g u h.
Essas relações afirmam igualdades entre conjuntos de pares ordenados. Existem
muitas maneiras aceitáveis ​​na prática matemática atual de provar tais
afirmações, como uma indução sobre alguma característica estrutural comum dos conjuntos envolvidos. Mas tais maneiras estão fora do nosso interesse atual em formular
as próprias afirmações.
Reconhecemos, com Floyd [12], que a questão da correção do programa
é simplesmente a questão do significado do programa, isto é, saber o que
um programa faz. Qualquer programa, incluindo puro jargão, exibe algum
comportamento, e está correto com relação a esse comportamento, independentemente de
quais outras capacidades podem ser previstas para ele. Neste contexto, é crucial
distinguir entre correção e capacidade. Um programa em construção
de cima para baixo pode estar correto em todos os estágios, mas não é capaz de seus
eventuais requisitos até ser concluído. Um erro em um programa é uma
ação inesperada. Uma descrição teórica da função do comportamento de um
programa pode, portanto, ser considerada uma descrição pura ou uma prescrição normativa,
mas o problema da correção se resume ao acordo
entre uma descrição funcional e um comportamento do programa.

Funções
Adotamos a noção matemática comum de que uma função é um conjunto de
pares ordenados (veja Halmos [15]), digamos,
tal que se (x, y) E /, (u, v) E /, x = u, então y = v. A relação (x, y)
E f é frequentemente escrita como
Y = f(x),
e x é chamado de argumento, e y é chamado de valor da função f. Os
conjuntos de primeiro e segundo membros dos pares ordenados de uma função são
chamados de domínio e intervalo da função, respectivamente. No exemplo
acima,
domínio (f) = {x, x2, .. . }
intervalo (f) = {y1, Y2, ... }
Observe que essas definições para domínio e intervalo incluem apenas argumentos
e valores da função, e nenhum outro elemento.
Como uma função é um conjunto, faz sentido usar os termos "função
vazia", ​​"subfunção", "partição de função" e assim por diante, com a palavra,
sufixo ou prefixo "conjunto" substituído por "função" sempre que as condições
exigidas por uma função puderem ser garantidas. Instâncias que violam essas condições incluem o caso do conjunto de potência (o conjunto de subconjuntos
de uma função não é em si uma função, mas é um conjunto de funções) e a união
de funções (a unicidade de um valor para um determinado argumento pode ser perdida
na formação da união de duas funções). No entanto, a união de funções disjuntas
ou interseção de duas funções é novamente uma função, assim como a
diferença (conjunto) de duas funções.
Funções e regras
Na descrição de uma função f como um conjunto de pares ordenados, geralmente é conveniente
dar uma regra para calcular o segundo membro a partir do primeiro,
como em
f = { (x, y) I y = x2 + 3x + 2}
ou
(x,x2 +3x+2) Ef
ou mesmo
f(x) = x2 + 3x + 2,
onde o domínio (f) é dado em algum contexto mais amplo. Uma regra usada na definição
de uma função dessa forma não é única. Por exemplo, se
x2 + 3x + 2 = (x + 1) (x + 2),
então a nova função e regra
g={(u,v) I v = (u+l)(u+2)}
ou
g(u) = (u + 1) (u + 2)
define o mesmo conjunto de antes, ou seja, f = g (como conjuntos).
Se uma função for finita, sua enumeração pode servir em uma regra. A
regra é encontrar qualquer argumento dado como um primeiro membro de um par ordenado,
se possível, e extrair o segundo membro, se encontrado, como o valor para
esse argumento. Caso contrário, se a enumeração for impossível ou impraticável,
uma regra deve ser expressa como um algoritmo, possivelmente muito complexo, mas com
resultado inequívoco para cada argumento.
Na programação, há uma correspondência direta com o relacionamento
entre funções e regras - é entre especificações funcionais e
programas. O problema da correção do programa então se torna o problema
de mostrar que uma determinada função é definida por uma determinada regra. Talvez a
forma mais simples do problema de correção do programa seja definida pela função regras de enumeração, ou "tabela de consulta". Se um programa de tabela de consulta foi
anteriormente provado como correto, então qualquer especificação funcional finita,
inserida como uma tabela, pode ser verificada como correta verificando as entradas da tabela
aqui.
Como funções são meramente conjuntos de pares ordenados, consideramos a
ideia usual de uma "função parcial" como um relacionamento entre dois conjuntos,
um dos quais é o domínio de alguma função sob consideração. No nosso
caso, usamos o termo regra parcial para significar uma regra de computação nem sempre
definida sobre algum conjunto dado.
Composição e conclusão de funções
Além das operações diretamente herdadas de conjuntos, a composição de funções é
baseada no fato de que funções são conjuntos de pares ordenados. Uma composição
de duas funções é uma nova função que representa o uso sucessivo dos
valores de uma função como argumentos da outra. Isto é, definimos
a nova composição de função, usando uma notação infixa:
f * g = {(x, y) I 3: z (z = g(x) I\ Y = f(z))}.
Se o intervalo (g) e o domínio (f) forem disjuntos, então f * g é a função vazia;
caso contrário, j * g é apenas o conjunto de pares ordenados que é definido através da
aplicação de g então f aos argumentos de g para obter valores de f.
Por outro lado, dizemos que um par ordenado de funções, (f, g), é uma
decomposição de uma função, h, se h = f * g. Claramente, para qualquer função h,
pode haver muitas decomposições.
É claro que a composição de função é associativa, isto é, que
(f * g) * h = f * (g * h)
para todas as funções f, g e h; portanto, os parênteses c_.:m devem ser omitidos sem
ambiguidade, como em
f * g *h.
Então a composição de uma função consigo mesma pode também ser denotada simplesmente
por uma notação de expoente:
regras de enumeração, ou "tabela de consulta". Se um programa de tabela de consulta foi
anteriormente provado como correto, então qualquer especificação funcional finita,
inserida como uma tabela, pode ser verificada como correta verificando as entradas da tabela
aqui.
Como funções são meramente conjuntos de pares ordenados, consideramos a
ideia usual de uma "função parcial" como um relacionamento entre dois conjuntos,
um dos quais é o domínio de alguma função sob consideração. No nosso
caso, usamos o termo regra parcial para significar uma regra de computação nem sempre
definida sobre algum conjunto dado.
Composição e conclusão de funções
Além das operações diretamente herdadas de conjuntos, a composição de funções é
baseada no fato de que funções são conjuntos de pares ordenados. Uma composição
de duas funções é uma nova função que representa o uso sucessivo dos
valores de uma função como argumentos da outra. Isto é, definimos
a nova composição de função, usando uma notação infixa:
f * g = {(x, y) I 3: z (z = g(x) I\ Y = f(z))}.
Se o intervalo (g) e o domínio (f) forem disjuntos, então f * g é a função vazia;
caso contrário, j * g é apenas o conjunto de pares ordenados que é definido através da
aplicação de g então f aos argumentos de g para obter valores de f.
Por outro lado, dizemos que um par ordenado de funções, (f, g), é uma
decomposição de uma função, h, se h = f * g. Claramente, para qualquer função h,
pode haver muitas decomposições.
É claro que a composição de função é associativa, isto é, que
(f * g) * h = f * (g * h)
para todas as funções f, g e h; portanto, os parênteses c_.:m devem ser omitidos sem
ambiguidade, como em
f * g *h.
Então a composição de uma função consigo mesma pode . também ser denotada simplesmente
por uma notação de expoente: f2 =f*f
/
3 = j * j2 = f2 * f = f * f * f
/
4 = f * f3 = f * f * f * f.

Ocasionalmente será conveniente permitir um expoente zero e interpretar
f0 como uma função identidade (veja abaixo).
Dada uma função, consideramos sua composição repetida consigo mesma,
reutilizando valores como novos argumentos até que, se alguma vez, tais valores não sejam membros
do domínio da função. O número de composições então
possíveis depende do argumento original, é claro. Assim, definimos uma
completude de função, digamos, para a função f, como
*f* ={(x,y) l3:k((x,y)Efk) Ay¢domain(f)}.
Funções Especiais
Identificamos para conveniência futura, várias classes gerais de funções,
a saber:
1. Funções de identidade:
I= {f I (x,y) E f :J y=x}
2. Funções constantes:
C(a) = {f I (x,y) E f :J y=a}
3. Funções de permutação:
P = {f I domínio (f) = intervalo {f)}
4. Pares de funções inversas:
R = { {f, g) I t * g = g * t E I}
(Se {f, g) E R , dizemos g = t- 1 ou f = g-1.)
Programas
Abstraímos a ideia comumente conhecida de um programa (de computador) como um
conjunto finito de funções, chamadas instruções, cada uma com um domínio finito contido
em um conjunto comum, chamado espaço de dados, e um intervalo finito contido
no produto cartesiano do espaço de dados e do programa, chamado espaço de
estado. Os membros do espaço de dados e do espaço de estado são chamados de valores de dados
e valores de estado, respectivamente.
Uma execução de programa é uma sequência de valores de estado, digamos,
S;=(d;,/;) , i=O, 1, ...
tal que
S; + J =fi (d;), i=O, 1, ...
que termina, se alguma vez, quando f;(di) deixa de existir - isto é, quando d; i domínio
(f;). O valor de estado s0 é chamado de valor inicial da execução. Se
a execução for finita, digamos,
S = So, S1, ... , Sn = t,
então t é chamado de valor final da execução.
Como o espaço de estado de um programa é finito, é decidível, para
cada valor inicial, s, se essa execução termina e, se sim, qual
o valor final, t, é. Portanto, um programa define automaticamente uma função
de pares ordenados (s, t) definidos por execuções de término, chamada de função
de programa. Se um programa é dado por um conjunto P, denotamos sua função
de programa por [P]. Em retrospecto, um programa é uma regra específica (não única)
para calcular os valores de sua função de programa.
Um subprograma é um subconjunto de um programa, que herda seu espaço de estado.
Uma execução de subprograma é uma subsequência contígua de uma execução de programa
que termina, se alguma vez, quando uma instrução que não está no subprograma
aparece no valor de estado. A cada subprograma corresponde uma
função de subprograma também.
Gráficos de controle
As instruções (funções) de um programa determinam um gráfico de controle
direcionado cujos nós são instruções e cujas linhas direcionadas são as próximas
instruções possíveis. Um nó de tal gráfico pode ter várias linhas de entrada
e várias linhas de saída, que denotam a direção do fluxo de controle,
conforme mostrado na Figura 13-1.
Uma instrução (nó) tem uma decomposição natural entre controle
e efeitos de dados que podem ser exibidos por sua partição (de seu conjunto de
pares ordenados) em subconjuntos, cada um dos quais contém valores idênticos (próximos)
componentes de instrução. O nó de instrução exibido na Figura 13-1
então tem a forma na Figura 13-2, onde o diamante (nó de controle) representa
uma função de identidade para valores no espaço de dados e um quadrado
(nó de processo) representa uma função constante para valores no programa
(próxima instrução). Como o programa (conjunto) é finito, esta partição pode ser 

Uma execução de programa é uma sequência de valores de estado, digamos,
S;=(d;,/;) , i=O, 1, ...
tal que
S; + J =fi (d;), i=O, 1, ...
que termina, se alguma vez, quando f;(di) deixa de existir - isto é, quando d; i domínio
(f;). O valor de estado s0 é chamado de valor inicial da execução. Se
a execução for finita, digamos,
S = So, S1, ... , Sn = t,
então t é chamado de valor final da execução.
Como o espaço de estado de um programa é finito, é decidível, para
cada valor inicial, s, se essa execução termina e, se sim, qual
o valor final, t, é. Portanto, um programa define automaticamente uma função
de pares ordenados (s, t) definidos por execuções de término, chamada de função
de programa. Se um programa é dado por um conjunto P, denotamos sua função
de programa por [P]. Em retrospecto, um programa é uma regra específica (não única)
para calcular os valores de sua função de programa.
Um subprograma é um subconjunto de um programa, que herda seu espaço de estado.
Uma execução de subprograma é uma subsequência contígua de uma execução de programa
que termina, se alguma vez, quando uma instrução que não está no subprograma
aparece no valor de estado. A cada subprograma corresponde uma
função de subprograma também.
Gráficos de controle
As instruções (funções) de um programa determinam um gráfico de controle
direcionado cujos nós são instruções e cujas linhas direcionadas são as próximas
instruções possíveis. Um nó de tal gráfico pode ter várias linhas de entrada
e várias linhas de saída, que denotam a direção do fluxo de controle,
conforme mostrado na Figura 13-1.
Uma instrução (nó) tem uma decomposição natural entre controle
e efeitos de dados que podem ser exibidos por sua partição (de seu conjunto de
pares ordenados) em subconjuntos, cada um dos quais contém valores idênticos (próximos)
componentes de instrução. O nó de instrução exibido na Figura 13-1
então tem a forma na Figura 13-2, onde o diamante (nó de controle) representa
uma função de identidade para valores no espaço de dados e um quadrado
(nó de processo) representa uma função constante para valores no programa
(próxima instrução). Como o programa (conjunto) é finito, essa partição pode ser refinada para que os nós de controle contenham exatamente duas linhas de saída, chamadas
nós de predicado.
A partir dessas considerações, somos levados a gráficos direcionados com
nós de predicado e processo da forma mostrada na Figura 13-3.
Será conveniente introduzir uma simetria em tais gráficos direcionados
aumentando o programa original com instruções "no-op" (nós de coleta), que coletam e transferem o controle de exatamente duas
linhas de entrada cada, que diagramamos conforme mostrado na Figura 13-4. Os gráficos de controle
também são chamados de esquemas de programa (consulte Ia nov [19]).
Programas em forma de fluxograma
Podemos representar um programa em forma de fluxograma. Um fluxograma é definido por
um gráfico de controle e por operações e testes a serem realizados em dados em uma sequência determinada por esse gráfico de controle. Conforme observado, consideramos gráficos de controle
com apenas três tipos de nós (veja a Figura 13-5). As linhas superior
e inferior de um nó predicado são rotuladas como "Verdadeiro" e "Falso",
respectivamente, apenas para ser definitivo, a menos que indicado de outra forma.
Em um fluxograma, cada nó de processo é associado a uma função, ou
transformação de dados, e cada nó predicado é associado a uma
função de predicado, ou um teste de dados de valor binário. Cada linha de um fluxograma é
associada a um conjunto de estados de dados possíveis. Um conjunto de estados de dados pode ser
o conjunto de todos os estados de máquina possíveis, para um programa em uma linguagem de máquina,
ou pode ser o conjunto de todas as variáveis ​​alocadas em um ponto em um programa
em uma linguagem de programação. A função associada a um nó de processo
mapeia um conjunto de estados de dados associados à sua linha jnput em um conjunto de dados
estados associados à sua linha de saída. Uma função f de X para Y é identificada
em um fluxograma como

Este mapeamento é uma subfunção, digamos, g, off, a saber:
g = {(x, y) I x EX A (x, y) E fAy E Y}.
Se x ¢ X, nenhuma entrada desse tipo é possível; se y ¢ Y, nenhuma saída desse tipo é possível; se
x E X mas (x, y) ~ para y ~ Y, a operação não é concluída.
A função predicado associada a um nó predicado mapeia o
conjunto de estados de dados associados à sua linha de entrada no conjunto {Verdadeiro, Falso}

mas não transforma os dados de outra forma; isto é, a figura do fluxograma é associada
aos mapeamentos de identidade dos dados da entrada para a saída. Mas para
concluir o teste satisfatoriamente, a condição
xE XI\ (((x, True) E pl\x E Y) V ((x, False) EpA xE Z))
deve ser satisfeita.
O nó coletor também é associado a um mapeamento de identidade,
da figura do fluxograma.
X
z
Além disso, para concluir a transferência de controle, a condição
(x E X A x E Z) V (y E Y A y E Z)
deve ser satisfeita. Na prática inicial e na teoria de programação atual, os
conjuntos associados às linhas de controle são frequentemente considerados idênticos - um conjunto de "vetor de
estado". No entanto, com o escopo de dados e a alocação dinâmica de armazenamento,
conforme encontrado na prática contemporânea, o espaço de dados é variável, em vez de
constante, em um programa ou fluxograma.

Execução do Programa
A execução de um programa é facilmente visualizada em um fluxograma, usando o
gráfico de controle para identificar a sequência de operações e testes em dados necessários.
Por exemplo, considere o programa f em forma de fluxograma, conforme mostrado
na Figura 13-6.
T v
u
FIGURA 13-6
Sempre que possível, os dados iniciais r E R são convertidos por f em dados
intermediários s E S, então t E T e v E V, ou u E U, então wE W, e finalmente
em dados finais x E X, pelas funções g, h e k, sob o controle
do predicado p. Isto é, a função de programa (f] do programa f tem valores,
quando eles existem, dados por
x = k(h(g(r)))
x = k(g(r))
Mais precisamente, queremos dizer
se
se
p(g(r)) =True
p(g(r)) =False.
[f]={(r,x) lrERA(3:s,v((r,s)EgA (s,True)E pi\
(s,v) E hA (v,x) E k)) V (3:s ((r,s) EgA
(s, False) EpA (s, x) E k)) A x EX}.
Programas Próprios
Definimos um programa próprio como um programa no qual:
1. há precisamente uma linha de entrada e uma linha de saída, e
2. para cada nó, existe um caminho da linha de entrada através daquele
nó até a linha de saída.

Note que admitimos a possibilidade de programas sem nós e
uma única linha de entrada/saída. Chamamos tal programa de A. Claramente, a função
do programa [A] é uma função identidade; [A] E /. Na ilustração, os fluxogramas
na Figura 13-7 não são programas propriamente ditos.

Note que admitimos a possibilidade de programas sem nós e
uma única linha de entrada/saída. Chamamos tal programa de A. Claramente, a função
do programa [A] é uma função identidade; [A] E /. Na ilustração, os fluxogramas
na Figura 13-7 não são programas próprios.

Esta definição de programas próprios é motivada principalmente pela
intercambialidade de programas próprios e nós de processo em programas maiores.
Doravante, consideramos "programa próprio" e "programa" como sinônimos.
Se necessário, usaremos o termo "programa impróprio" para nos referir
a um programa que não é um programa próprio.

Equivalência de Programa
Diremos que dois programas próprios são equivalentes quando definem
a mesma função de programa, tenham ou não gráficos de controle idênticos
, exijam o mesmo número de operações e assim por diante. Por exemplo,
os dois programas
têm a mesma função de programa, assim como os dois programas na Figura 13-8.
Ou seja, dois programas são equivalentes se eles definem a mesma função
de programa, mesmo que os programas possam representar regras diferentes para calcular
os valores da função do programa. Em particular, dado o programa f
e sua função de programa [f], o novo programa g
domínio ( [ f]) I I :ange ( [!])
----'-"--~·~. [!] . •
é equivalente a f. Neste caso, g é uma versão de consulta de tabela de f.

Expansões de Programa
Se um programa contém um nó de processo, como
pode acontecer, que uma regra para calcular os valores de f seja definida como
outro programa. Chamamos tal programa de expansão da função
f, como mostrado na Figura 13-9.
Neste caso, afirma-se que a função de programa do último
programa é f. Ou seja, qualquer expansão de uma função é simplesmente uma regra para
computar seus valores, possivelmente usando outras funções e predicados para
fazer isso.
Programas com loops podem ou não terminar. Esta propriedade de término particiona um conjunto de entrada R em R1 e R - R1, onde R1 é o
subconjunto de entradas para as quais as avaliações terminam. Se R1 7 R, então o
programa define uma regra parcial em vez de uma regra. Observe que, de fato, um programa
pode terminar ao atingir uma linha de saída (término normal) ou
ao atingir um nó com um valor de dados que não está no domínio da função
correspondente (término de operação anormal) ou ao atingir uma linha
com um valor de dados que não está no espaço de dados (término de armazenamento anormal).
Rótulos de gráfico de controle
O conjunto de todos os gráficos de controle de programas adequados pode ser enumerado e
rotulado. O início de tal enumeração é dado na Figura 13-10.
De fato, alguns desses gráficos de controle recebem rótulos mnemônicos
especiais em várias linguagens de programação. Por exemplo, os seguintes rótulos
na Figura 13-11 são comuns. (IF-THEN é 9, na enumeração iniciada
acima, IF-THEN-ELSE pode ser 37, 42 e assim por diante.)
No entanto, não há nada de especial sobre esses gráficos, exceto por
sua simplicidade. Qualquer gráfico de controle possivelmente mais complicado do que estes pode ser rotulado assim se for útil. Em particular, rotulamos a sequência
de dois nós de processo
BLOCK
para referência futura.
Fórmulas de Programa
Um programa pode ser dado como uma fórmula, associando uma ordenação com o
conjunto de nós de processo, nós de predicado e linhas de controle de seu gráfico de controle
e listando o rótulo de seu gráfico de controle, seguido por rótulos para as
funções, predicados e conjuntos de estado do programa. Para conveniência de notação
usaremos parênteses e vírgulas para denotar a estrutura de lista
de uma fórmula de programa; por exemplo,
(A, p, q, /, g, h, R, S, T, U) significa um programa dado por um gráfico de controle rotulado A, com predicados p
e q, funções f, g e h, e conjuntos de estados R, S, T e U, associados com
os nós e linhas de A. Por exemplo, define um programa cuja ação em uma entrada r E R é produzir a saída t E T se ela existir,
tal que ou, mais precisamente,
A lista
[(BLOCK, f, g, R, S, T)] = {(r, t) \ 3: s (r E R
lisE S II tE T II (r, s) E f II (s, t) E g)}.
(IF-THEN-ELSE, p, f. g, R, S, T, U, V, W)
define um programa Note que admitimos a possibilidade de programas sem nós e
uma única linha de entrada/saída. Chamamos tal programa de A. Claramente, a função
do programa [A] é uma função identidade; [A] E /. Na ilustração, os fluxogramas
na Figura 13-7 não são programas próprios.

Esta definição de programas próprios é motivada principalmente pela
intercambialidade de programas próprios e nós de processo em programas maiores.
Doravante, consideramos "programa próprio" e "programa" como sinônimos.
Se necessário, usaremos o termo "programa impróprio" para nos referir
a um programa que não é um programa próprio.

Equivalência de Programa
Diremos que dois programas próprios são equivalentes quando definem
a mesma função de programa, tenham ou não gráficos de controle idênticos
, exijam o mesmo número de operações e assim por diante. Por exemplo,
os dois programas
têm a mesma função de programa, assim como os dois programas na Figura 13-8.
Ou seja, dois programas são equivalentes se eles definem a mesma função
de programa, mesmo que os programas possam representar regras diferentes para calcular
os valores da função do programa. Em particular, dado o programa f
e sua função de programa [f], o novo programa g
domínio ( [ f]) I I :ange ( [!])
----'-"--~·~. [!] . •
é equivalente a f. Neste caso, g é uma versão de consulta de tabela de f.

Expansões de Programa
Se um programa contém um nó de processo, como
pode acontecer, que uma regra para calcular os valores de f seja definida como
outro programa. Chamamos tal programa de expansão da função
f, como mostrado na Figura 13-9.
Neste caso, afirma-se que a função de programa do último
programa é f. Ou seja, qualquer expansão de uma função é simplesmente uma regra para
computar seus valores, possivelmente usando outras funções e predicados para
fazer isso.
Programas com loops podem ou não terminar. Esta propriedade de término particiona um conjunto de entrada R em R1 e R - R1, onde R1 é o
subconjunto de entradas para as quais as avaliações terminam. Se R1 7 R, então o
programa define uma regra parcial em vez de uma regra. Observe que, de fato, um programa
pode terminar ao atingir uma linha de saída (término normal) ou
ao atingir um nó com um valor de dados que não está no domínio da função
correspondente (término de operação anormal) ou ao atingir uma linha
com um valor de dados que não está no espaço de dados (término de armazenamento anormal).
Rótulos de gráfico de controle
O conjunto de todos os gráficos de controle de programas adequados pode ser enumerado e
rotulado. O início de tal enumeração é dado na Figura 13-10.
De fato, alguns desses gráficos de controle recebem rótulos mnemônicos
especiais em várias linguagens de programação. Por exemplo, os seguintes rótulos
na Figura 13-11 são comuns. (IF-THEN é 9, na enumeração iniciada
acima, IF-THEN-ELSE pode ser 37, 42 e assim por diante.)
No entanto, não há nada de especial sobre esses gráficos, exceto por
sua simplicidade. Qualquer gráfico de controle possivelmente mais complicado do que estes pode ser rotulado assim se for útil. Em particular, rotulamos a sequência
de dois nós de processo
BLOCK
para referência futura.
Fórmulas de Programa
Um programa pode ser dado como uma fórmula, associando uma ordenação com o
conjunto de nós de processo, nós de predicado e linhas de controle de seu gráfico de controle
e listando o rótulo de seu gráfico de controle, seguido por rótulos para as
funções, predicados e conjuntos de estado do programa. Para conveniência de notação
usaremos parênteses e vírgulas para denotar a estrutura de lista
de uma fórmula de programa; por exemplo,
(A, p, q, /, g, h, R, S, T, U) significa um programa dado por um gráfico de controle rotulado A, com predicados p
e q, funções f, g e h, e conjuntos de estados R, S, T e U, associados com
os nós e linhas de A. Por exemplo, define um programa cuja ação em uma entrada r E R é produzir a saída t E T se ela existir,
tal que ou, mais precisamente,
A lista
[(BLOCK, f, g, R, S, T)] = {(r, t) \ 3: s (r E R
lisE S II tE T II (r, s) E f II (s, t) E g)}.
(IF-THEN-ELSE, p, f. g, R, S, T, U, V, W)
define um programa que mapeia qualquer r E R em algum wE W, se existir, tal que
Mais precisamente,
{
f(r) if p(r) =True
w = g(r) if p(r) =False.
[(IF-THEN-ELSE, p, f, g, R, S, T, U, V, W)]
={(r, w) IrE RAw E W A (((r, True) EpA rES A (r, w) E f
wE U) V ( (r, False) E p A r E T A (r, w) EgA wE V)) }.
Em grande parte do que se segue, a lista de conjuntos de dados não é central para as
ideias em desenvolvimento. Neste caso, eles serão suprimidos. No entanto
tais conjuntos de dados são sempre implícitos para descrições e discussões de programas
Como a composição de funções é associativa, isto é,
(f*g) *h=f"' (g*h),
então também é a formação de BLOCK, isto é,
[(BLOCK, [(BLOCK, f, g)], h)]= [(BLOCK, f, [(BLOCK, g, h))]],
e nenhuma ambiguidade resulta ao estender o significado de BLOCK para vários nós, por exemplo
(BLOCK3, f, g, h)= (BLOCK, (BLOCK, f, g), h),
e assim por diante. Em particular, permitimos zero ou um nó em um BLOCK como na
Figura 13-12. Então, por exemplo, temos a identidade
f = [(BLOCKl, f, domain(!), range(/))].

Pode acontecer que uma função listada em uma fórmula de programa seja ela própria
uma função de programa dada por outra fórmula, como
(IF-THEN, p, [(BLOCK, g, h)]).
Nós estendemos a ideia de fórmula de programa para permitir a substituição de uma
função de programa por sua fórmula de programa, como
(IF-THEN, p, (BLOCK, g, h)).
É claro que, embora sejam programas diferentes, eles têm funções de programa idênticas,
apenas pela definição de funções de programa.
Descrições de programa
Fluxogramas e fórmulas são simplesmente duas maneiras alternativas de descrever
regras (possivelmente parciais), com alguma estrutura interna, em termos de outras
regras (ou regras parciais). Ainda outro método de descrição está no texto da
linguagem de programação, como
e
e
IF p THEN
f
ELSE
g
END IF
WHILEp DO
f
END DO
BLOCK
f
g
END BLOCK
e assim por diante. Achamos todos os três tipos de descrição úteis em várias circunstâncias
na programação. Normalmente, os fluxogramas são úteis em discussões gerais
por causa de seus gráficos, as fórmulas são úteis para declarar e provar propriedades teóricas de tais regras, e o texto é útil na
construção real de grandes programas complexos. Por exemplo, o mesmo
programa é dado na fórmula
(IF-THEN-ELSE, p, (DO-WHILE, q, f), (BLOCK, g, h)),
no fluxograma ou no texto do programa
IF p THEN
WHILE q DO
f
END DO
ELSE
BLOCK
g
h
END BLOCK
END IF

Programas Estruturados
À medida que os fluxogramas aumentam de tamanho, podemos frequentemente identificar padrões que dão
mais coerência e compreensibilidade a um fluxograma inteiro. Por exemplo,
o gráfico de controle na Figura 13-13 tem três subestruturas aninhadas definidas, que são gráficos de controle para programas adequados, que tornam o todo mais
facilmente considerado. Mas o gráfico de controle na Figura 13-14 não admite tal
estruturação. Ao simplesmente continuar este último padrão indefinidamente, é fácil
ver que existem gráficos de controle indecomponíveis de qualquer tamanho.
Tendo notado que programas de tamanho arbitrário podem ser indecomponíveis,
adicionamos a seguir a possibilidade de operações e testes em dados fora
dos conjuntos de dados originais de um programa. As operações e testes adicionais
correspondem à configuração e teste de "flag". Mas podemos colocar essas operações
no conceito de uma pilha push down para mostrar sua economia. Além
das funções e predicados originais de um determinado programa,
introduzimos três novas funções e um predicado.

Mais especificamente, definimos nós de processo com funções chamadas
TRUE, FALSE e POP, e um nó predicado com função chamada
TOP, que adiciona valores de verdade True e False, remove e testa tais valores de verdade
em um conjunto de dados de entrada, respectivamente. Ou seja, para qualquer conjunto de dados Y, e y
E Y e z E {True, False},
TRUE(y) = (y, True)
FALSE(y) = (y, False)
POP(y, z) = y
TOP(y, z) = z

Essas novas funções e predicado nos permitem construir lógica de
controle explícita na forma de sinalizadores. Por exemplo, um programa cuja estrutura de
controle está no padrão indecomponível acima é mostrado na Figura 13-15.
Este programa é equivalente ao novo programa, onde a linha de saída X
e a linha de retorno Y são marcadas, e a marca é testada posteriormente.
Apenas os conjuntos de dados originais foram mostrados na Figura 13-16; os
restantes podem ser inferidos das definições acima. Uma inspeção mais detalhada
revelará que o efeito líquido de TRUE, FALSE, POP e TOP é
apresentar apenas o conjunto de dados original correto para cada uma das funções originais
e predicados do programa. Pode não ser óbvio que este programa
equivalente tenha algum valor neste caso. Parece um pouco mais complexo, exceto
que agora há uma subestrutura, um programa adequado, que contém
todas as funções e predicados originais e, além disso, não tem nenhum loop
nele. Esta aplicação em particular prevê uma construção fundamental na
prova do Teorema da Estrutura principal abaixo. Como resultado, este novo programa
agora pode ser decomposto em duas seções, das formas mostradas na Figura
13-17, onde o nó do processo f é dado pela Figura 13-18.
Antes de provar este Teorema, introduzimos um lema simples, que
conta as linhas de controle de um programa adequado em termos de sua função e
nós de predicado.

O Número de Linhas de Controle em um Programa Próprio
Lema: Se o número de função, predicado e nós coletores for ¢, -rr e
1', respectivamente, e o número de linhas de controle (isto é, arestas) for e, em um
programa próprio, então
e
e=I+<P+3-rr.
Prova: Para provar este lema, conte as "caras e coroas" das
linhas de controle, adjacentes a todos os nós, e na entrada e saída do
programa, para obter a Tabela 13-1.
TABELA 13-1
Predicado de função de controle Coleta
Linha Entrada Nó Nó Nó Saída Total
Cara <P 7r 2y <P + 7r + 2'Y + 1
Coroa <P 2-rr i' <P + 27T + i' + 1
Como o número total de caras deve ser igual ao número total de coroas e
cada uma deve ser igual a e,
<P + -rr + 2i' + 1 = e = <P + 21r + i' + 1,
e as equações do lema seguem.
Teorema da estrutura
Teorema: Qualquer programa próprio é equivalente a um programa cuja fórmula
contém no máximo os rótulos de gráfico BLOCK, IF-THEN-ELSE e DOUNTIL,
e funções adicionais TRUE, FALSE e POP, e função predicativa
TOP.
Prova:* Provamos o teorema por indução no número de linhas de
um programa próprio. A etapa de indução é construtiva e identifica, para
qualquer programa próprio de mais de um nó, um programa próprio equivalente
que é uma fórmula no máximo em rótulos de gráfico BLOCK, IF-THEN-ELSE,
* Agradecimentos a J. Misra pelas sugestões e assistência no desenvolvimento da seguinte
prova. Agradecimentos também a S. Cole pelas discussões sobre o teorema e métodos
para sua prova.

e DO-UNTIL e novos programas próprios, cada um com menos linhas do que
o programa inicial.
Para realizar a indução, primeiro definimos um processo de estruturação, S, em qualquer programa próprio, f, cujo resultado denotamos por S(f) ,
como segue. Por conveniência, abreviamos os rótulos de gráfico BLOCK,
IF-THEN-ELSE, DO-UNTIL para BLK, IF, DO, respectivamente, no restante
da prova.
Como f é um programa próprio, ele tem exatamente uma entrada e uma saída.
Identificamos vários casos que são possíveis.
Caso 1: Nenhum nó. Se f não tem nós, definimos
S(f) = A.
Caso 2: Um ou mais nós. Se f tem pelo menos um nó, examinamos o
nó único alcançado pela linha de entrada. Existem três casos possíveis:
Caso 2a: Nó predicado. Se o primeiro nó for um nó predicado, então f é
da forma na Figura 13-19. Como f é um programa próprio, a linha z pode
X
I : \ z -..... 0 / '
----;·~ p t,, _. ) ,.
y
FIGURA 13-19
ser alcançada tanto de x quanto de y,* e construímos dois programas constituintes
que consistem em todos os nós acessíveis em f de x e y, respectivamente, chamando-os
de g e h, respectivamente.
-......
/ ' I \ z
X I g ;
\ ' .... __ , I
.......-.....
/ ' y I \ z
\ h ) ,.
' ........ / .__,
FIGURA 13-20
* Nossa definição de programas próprios é necessária para esta afirmação. A prova de
Bohm e Jacopini [5] falha neste ponto.
Os constituintes podem conter nós idênticos de t, de modo que g e
h representam duplicações de partes de f. Se um nó coletor em g ou h é
alcançado por apenas uma linha de entrada (a outra linha em f estando no outro constituinte),
suprimimos esse nó coletor, isto é,
se torna
Observe que g e h são programas próprios; caso contrário, f não é um
programa próprio. Observe também que g e/ou h podem ser A., ​​um programa sem nós.
Como cada um de g e h contém pelo menos um nó predicado a menos do que
f, pelo menos um nó coletor é suprimido em cada constituinte. Em seguida,
consideramos o novo programa próprio, (IF, p, g, h), conforme mostrado na Figura
13-21, com o predicado original p e os constituintes g e hoff (e
um novo nó coletor, não de g ou h). Neste caso, definimos
S(f) =(IF, p, g, h) .
X
... -,
/ \
' z
\ g I
' --/I
FIGURA 13-21

Também, neste caso, observamos que
e(g) ~ cp(f) + 3(7r(f)- 1) + 1 = e(f) - 3
e(h) ~ cp'(f) + 3(7r(f) - 1) + 1 = e(f)- 3,
já que g e h pelo menos não contêm nota de predicado f. (Usamos e(f), cp(f),
e 1r(f) para denotar o número de linhas, nós de função e nós de predicado,
respectivamente, em f.)
Finalmente, fica claro pela construção que S(f) é equivalente a f.
Caso 2b: Nó de função. Se o primeiro nó for um nó de função, então f é da
forma mostrada na Figura 13-22, e h é um programa próprio, possível X.
Neste caso, definimos
.... - ..... Q / \h
----l)lo~ g ~ ...!I __, • .,..
\ , __ ..... I
FIGURA 13-22
S(f) = (BLK, g, h).
Além disso, neste caso é fácil contar o número de linhas em h, dado
que há e(f) linhas em f. O número é
e(h) = (cp(f) - 1) + 37r(f) + 1 = e(f) - 1.
Finalmente, fica claro pela construção que S(f) é equivalente a f.
Caso 2c: Nó de coleta. Se o primeiro nó for um nó coletor, então f
deve ser da forma mostrada na Figura 13-23, e examinamos o próximo
nó único alcançado a partir deste nó coletor. É claro que tal próximo
nó existe, porque um nó predicado, pelo menos, deve ser alcançado no programa impróprio restante para ter duas linhas de saída. Há
três subcasos a serem examinados.
2.c.(1). Nó Predicado. Se o próximo nó for um nó predicado, então f é da
forma mostrada na Figura 13-24.
Como antes, construímos dois programas que consistem em todos os nós que
podem ser alcançados de x e y, que terminam em z ou r. Suprimimos nós coletores
com apenas uma entrada, como antes. Esses programas não serão
programas próprios se r e z puderem ser alcançados de x ou y. No entanto,
como f é um programa próprio, sabemos que cada programa construído deve
atingir pelo menos z ou r e que cada z e r deve ser alcançado por pelo menos um
programa construído. Esses programas construídos têm a forma mostrada na
Figura 13-25, onde a linha de saída sólida é necessária e a linha de saída pontilhada
pode ou não existir. Usamos nós de função TRUE e FALSE
(para definir sinalizadores) e possivelmente nós de coleta para construir novos programas próprios a partir destes mostrados, da forma na Figura 13-26, as formas na Figura
13-27 ou a forma na Figura 13-28, dependendo se as
linhas de saída pontilhadas r e z existem ou não.

Rotulamos esses programas próprios g e h (de modo que g tenha pelo menos
a linha de saída r e h tenha pelo menos !a linha de saída z). Agora consideramos
o novo programa mostrado na Figura 13-29, com g e tem programas constituintes.
Neste caso, definimos
S(f) = (BLK, TRUE, (BLK, (DO, TOP, (BLK, POP, (IF, p, g, h))),
POP)).
Observamos que g e h não têm o nó predicado p, e cada um tem
no máximo mais dois nós de função. Portanto,
e(g) ~ <f>(f) + 2 + 3(7T(/)- 1) + 1 = e(f)- 1
e(h) ~ </>(/) + 2 + 3-(7T(f)- 1) + 1 = e(f)- 1
Finalmente, pode ser verificado que S(f) é equivalente a f.
2.c.(2). Nó de função. Se o próximo nó for um nó de função, então f é da
forma mostrada na Figura 13-30, e consideramos o novo programa mostrado
na Figura 13-31, com o novo programa rotulado h. Neste caso, definimos
S(f) = (BLK, g, h).
Além disso, neste caso, observamos diretamente que
e(h) = e(f)
mas que também, o número de linhas, digamos, i(f), necessário para atingir o primeiro
predicado de f é reduzido em um, isto é,
i(h) = i(f) - 1
Finalmente, fica claro que S(f) é equivalente a f.
2.c.(3). Nó coletor. Se o próximo nó for um nó coletor, então f é da
forma mostrada na Figura 13-32, e consideramos o novo programa mostrado
na Figura 13-33, chamado g. Neste caso, definimos
S(f) = g
Além disso, neste caso, observamos diretamente que
e(g) = e(f)
i(g) = i(f) -1
Fica claro que S(f) é equivalente a f.
/ I I ' I '\
I
' .. . --/
..
Resumo. Isso conclui a análise de casos para a região de entrada de f
e a definição do processo de estruturação, S. Em resumo, em cada caso
definimos um novo programa, S(f), equivalente a f, tal que S(f) é uma
fórmula em, no máximo, rótulos de gráfico BLOCK, IF-THEN-ELSE e DO-UNTIL,
funções, predicados e programas constituintes próprios. Em vários
casos, o número de arestas dos constituintes de f é visto como menor que o número de arestas em f. Em dois casos, esse número de arestas não foi diminuído,
mas o número de arestas da entrada ao primeiro nó predicado foi
diminuído. É claro que o número de arestas da entrada ao primeiro nó predicado
é limitado pelo número de arestas de um programa. Quando
aplicamos essas informações àquelas geradas nas análises de caso acima, obtemos
Tabela 13-2.
Agora estamos prontos para resumir nossa prova, como segue:

Primeiro, fica claro que o Teorema da Estrutura é verdadeiro para programas próprios
com uma linha, pois tal programa é simplesmente A..
Em seguida, suponha que o Teorema da Estrutura seja verdadeiro para programas próprios
de n linhas ou menos para n > 1. Seja f um programa próprio com n + 1
linhas. Aplicamos S a f. Se o caso 2a, 2b ou 2c(1) se aplicar, temos um novo
programa equivalente, cujos programas constituintes são próprios e têm no
máximo n linhas; e cada um desses constituintes, por nossa hipótese de indução, satisfaz
o teorema. Além disso, o novo programa equivalente tem uma fórmula
em, no máximo, rótulos de gráfico BLOCK, IF-THEN-ELSE, DO-UNTIL, predicados
e seus constituintes. Portanto, o novo programa satisfaz o
teorema. Se nenhum dos casos 2a, 2b ou 2c(l) se aplicar, então i(f) :::; n, e
o caso 2c(2) ou 2c(3) deve ser aplicado. Em cada caso, resta apenas um
constituinte, digamos, g, e
e(g) = e(f), i(g) = i(f) - 1
Portanto, após, no máximo, n dessas aplicações, o caso 2c( 1) deve ser aplicado, e
o programa equivalente final satisfaz o teorema.
Isso completa a prova do Teorema da Estrutura.
Corolário de cima para baixo
Qualquer programa próprio é equivalente a um programa de uma das formas
(BLOCK, g, h)
(IF-THEN-ELSE, p, g, h)
(DO-UNTIL, p, g)
onde p é um predicado do programa original ou TOP, e g, hare proper
programs, funções do programa original, TRUE, FALSE ou POP.
Programas Estruturados em S
O Teorema da Estrutura motiva a definição de um programa estruturado
da seguinte forma:
Seja S qualquer conjunto finito de rótulos associados a gráficos de controle de
programas próprios. Então, qualquer programa cuja fórmula contenha apenas
rótulos de gráfico de S é dito ser um programa estruturado em S.
Quando o prefixo "S" não é crítico ou compreendido, ele será suprimido.
Representações de Programas
O resultado do Teorema da Estrutura é semelhante aos teoremas de representação
em outros ramos da matemática, nos quais é mostrado que todos os elementos
de um conjunto, ou "espaço", podem ser representados por combinações de um subconjunto de
"elementos básicos" do espaço. Por exemplo, três vetores não planares abrangem
um espaço euclidiano tridimensional, o conjunto {sin nx, cos nx I n = 0, 1,
... } abrange um conjunto de funções reais no intervalo [0, 2?T ]- isto é, um "espaço de
funções". Os exemplos anteriores referem-se à combinação linear para representação.
No Teorema da Estrutura é mostrado que três tipos simples de
programas, definidos pelos gráficos de controle BLOCK, IF-THEN-ELSE e DO-UNTIL,
abrangem o conjunto de todos os programas apropriados, usando a substituição de
programas apropriados para nós de processo como a única regra de combinação. Tal teorema de representação
permite a resolução de questões de adequação de uma
linguagem de programação de forma simples e eficaz. Por exemplo, tudo o que se precisa
para mostrar que um novo conjunto de programas base abrangerá o conjunto de todos os
programas apropriados é que se possa representar programas BLOCK, IF-THEN-ELSE e
DO-UNTIL neste novo conjunto.
Uma ilustração simples de uma nova base é representar DO-UNTIL em
termos de BLOCK e DO-WHILE, como mostrado na Figura 13-34, ou
(DO-UNTIL, p, f) = (BLOCK, f, (DO-WHILE, p, f)).
Portanto, BLOCK, IF-THEN-ELSE e DO-WHILE fornecem uma
estrutura de controle suficiente para representar todos os programas adequados, bem como BLOCK,
IF-THEN-ELSE e DO-UNTIL.
· Árvores de Programa
A fórmula de um programa estruturado pode ser exibida em uma árvore de programa
de forma natural, com os rótulos de gráfico, funções e predicados atribuídos
aos nós da árvore. Por exemplo, a fórmula
(IF-THEN-ELSE, p, g, h)
define a árvore de programa na Figura 13-35; e a fórmula
(FAÇA-ENQUANTO, p, (SE-ENTÃO-SENÃO, q, g, (BLOCO, h, k)))
define a árvore do programa na Figura 13-36
160 PRODUTIVIDADE DO SOFTWARE
FAÇA-ENQUANTO
/~
p SE-ENTÃO-SENÃO
/~
q g BLOCO
/~ h k
FIGURA 13-36
Por outro lado, dada qualquer árvore de programa de rótulos de gráfico, funções e
predicados, o programa original pode ser recuperado. Em particular, qualquer sutr
árvore definida por um nó mais todos os seus sucessores na árvore define um subprograma
do programa original.
A árvore do programa fornece uma maneira conveniente de visualizar a estrutura do programa
na forma de subprogramas. Ao rotular subprogramas e se referir
às suas funções de programa em níveis mais altos no programa, um
programa original de qualquer tamanho pode ser organizado como um conjunto de subprogramas.
cada um de um tamanho máximo prescrito.
É claro que cada subprograma assim definido é um programa apropriado.
Ou seja, cada um mapeia um conjunto de dados de entrada em um conjunto de dados de saída, sem efeitos colaterais de
controle.
Correção do Programa
Já notamos que a correção do programa é uma questão de previsibilidade.
Mais precisamente, dado um programa, f, e uma função, g, estamos
interessados ​​em saber se g é o mesmo que a função do programa [fl. Se soubermos
tanto g quanto [f), podemos resolver a questão por comparação. Realizar
tal comparação de dois conjuntos é um problema matemático geral cuja
solução dependerá de como os conjuntos são definidos. Em alguns casos, eles
serão enumerados. Então seus elementos podem ser ordenados e correspondidos, um par
de cada vez. Na maioria dos casos, esses conjuntos serão definidos por condições ou regras em algum contexto mais amplo (menos formal) do que a teoria dos conjuntos em si. Pode haver
números naturais envolvidos, caso em que definições e comparações indutivas
podem ser possíveis. Em qualquer caso, as técnicas de comparação estão
além do nosso interesse atual e devem ser formuladas em quaisquer termos
disponíveis.
No caso de programas estruturados, a árvore do programa permite a
decomposição do problema de correção em uma série de problemas aninhados,
cada um de um tipo simples que pode ser prescrito com antecedência.
Teorema da Correção
Teorema: Se a fórmula de um programa 'contém no máximo rótulos de gráfico BLOCK,
IF-THEN, IF-THEN-ELSE, DO-WHILE e DO-UNTIL e satisfaz uma
qualificação de loop, então pode ser provado correto por um tour de sua árvore de programa,
na qual, em cada nó, o relevante de cinco casos deve ser provado
(conjuntos de dados suprimidos; veja abaixo as versões dos conjuntos de dados):
1. Iff= (BLOCK, g, h), prove
£n = { (r, t) I 3: s( (r, s) E [g] A (s, t) E [h])}
2. Iff= (IF-THEN, p, g), prove
[f] = {(r, s) I ((r, True) EpA (r, s) E [g]) V
((r, False) E pi\ (r,s) E pi\ r=s)}
3. Se= (SE-ENTÃO-SENÃO, p, g, h), prove
(f] = { (r, s) I ((r, Verdadeiro) A p A (r, s) A [g]) V
((r,Falso) (pl\(r,s) E[h])}
4. Se= (FAÇA-ENQUANTO, p, g), prove
£n =[(SE-ENTÃO, p, (BLOCO, [g), [f)))]
5. Se= (FAÇA-ATÉ, p, g), prove
[/]=[(BLOCO, (g], (SE-ENTÃO, p, [f)))]
Prova: Por hipótese, cada nó na árvore do programa é um dos cinco
tipos listados. Começando na raiz da árvore, a função do programa [f)
do programa f é determinada por possivelmente um predicado, e funções do programa
{g], [h] dos subprogramas constituintes g, h, e assim por diante, até que as funções sejam alcançadas nos pontos finais da árvore. Se a função do programa em cada nó
é conhecida em relação às funções do programa de seus nós sucessores, então
por indução finita a função do programa na raiz da árvore é conhecida
em relação às funções no programa.
Resta validar a afirmação detalhada caso a caso.

pela definição das funções do programa [g), [h]. Então a função do programa [f]
pode ser formulada diretamente como
[f] = {(r, t) j r E R 3: s( (r, s) E [g] A s E SA (s, t) E [h)) A t E T}.
Isso concorda com a declaração do teorema com os conjuntos de dados suprimidos.
Caso f = (IF-mEN, p, g)
Em forma de fluxograma,
Notas de correção. À primeira vista, as condições de verificação para DOWHILE
e DO-UNTIL parecem envolver uma relação recursiva na função do programa
(f]. Mas esse não é o caso; as condições de verificação envolvem
[f] como uma entrada, não como uma incógnita a ser resolvida.
Também é digno de nota que a abordagem de cima para baixo para correção
evita o problema de regras incompletas (ou em outras formulações, funções incompletas
para as quais não temos contrapartes) e término. Em uma
equação de programa como
/=WHILE p DOg,
as funções p e [g] são geralmente consideradas as "variáveis ​​independentes"
e a função [f) a "variável dependente", um ponto de vista "de baixo para cima".
É claro que, embora p e [g] possam ser dados por regras completas,
a nova regra "WHILE p DO g" pode acabar sendo parcial devido à
não término. No entanto, no ponto de vista de cima para baixo, a função (f] é
a "variável independente", e a equação do programa define "variáveis
dependentes" p e [g] implicitamente (e significativamente). Agora, como [f] é uma
função, p e [g] devem ser definidos de forma que a regra "WHILE p DO g"
termine para qualquer entrada no domínio de [fl.
A qualificação de loop necessária no Teorema da Correção é uma
restrição séria com relação à alocação e liberação de espaço de
armazenamento. Se o corpo de um loop DO aloca ou libera espaço, então a qualificação de loop
não é satisfeita, e a redução de uma verificação de loop para
a forma do teorema não é válida.
Expansões de Programa de Cima para Baixo
Até agora, consideramos os programas primeiro e depois seus significados como
funções de programa. Na programação de cima para baixo, queremos reverter essa
ordem de concepção; isto é, dada uma função (uma especificação de programa),
queremos encontrar algum programa (uma regra) que tenha essa função de programa.
Essa reversão de concepção nos permite evitar questões de "regras parciais",
"correção parcial" e o problema geral de término, porque elas
nunca surgem. Na maneira usual de olhar para equações de programa, como
f =(DO-WHILE, p, g),
o rótulo do gráfico DO-WHILE, predicado p e função ou subprograma g
geralmente tomados como "variáveis ​​independentes", e o programa f é tomado

para ser a "variável dependente". Neste caso, embora p e g sejam
dados por regras definidas em todos os lugares em seus domínios, o novo programa
(DO-WHILE, p, g) pode não terminar e, portanto, ser chamado de regra parcial.
Pode-se provar propriedades que relacionam p e g a f em caso de término para
obter correção parcial, mas também é preciso estabelecer a terminação separadamente!
para obter correção total.
Observamos que se tomarmos f como a variável independente na
equação anterior, então esses problemas de regra parcial e correção parcial
desaparecem. Se f denota uma regra completa, então p e g devem denotar
regras completas para satisfazer a equação como variáveis ​​dependentes.
Essa é a essência da programação de cima para baixo, considerando os subprogramas e predicados constituintes de uma expansão como variáveis ​​dependentes que
satisfazem uma equação prescrita que é herdada de cima para baixo.
Quando essa abordagem é adotada, talvez o resultado mais surpreendente seja
a quantidade de liberdade disponível para um programador ao escrever um
programa correto. Na abordagem bottom up, a programação parece ser uma
atividade com liberdade quase ilimitada para improvisar ou resolver problemas de
várias maneiras. Mas ao desenvolver um programa top down fica claro que essa
liberdade é altamente restrita. À primeira vista pode parecer que há menos
liberdade na programação top down do que bottom up, mas um segundo
pensamento mostra que não é o caso. Eles devem levar a resultados equivalentes,
e de fato o que realmente é exibido na abordagem bottom up é uma falsa
liberdade que é posteriormente paga em um doloroso processo de eliminação de erros,
seguindo um original "jato de originalidade".
Para exibir o grau de liberdade disponível na programação
nós fomu\amos o Teorema da Expansão abaixo em uma versão verba\ e uma versão
teórica de conjuntos. O Teorema da Estrutura exibe características de um
programa completo, enquanto o Teorema da Expansão mostra como os programas podem
olhar para cada estágio intermediário de sua construção. Em cada um desses estágios intermediários, um programa desenvolvido em uma disciplina de cima para baixo pode ser garantido como correto, na medida em que é desenvolvido, sem a necessidade de alterar partes do programa já feitas para acomodar as partes restantes do programa ainda a serem desenvolvidas. É uma experiência familiar no desenvolvimento de grandes programas obter "90% concluído" e permanecer nesse nível de 90% por um longo período. Esse fenômeno não ocorre
'u~\:.C.\\<:,~ \\\~\c.<:,\ \<'00fc \<:, ~\~\:.\\\\ \1\) ~t\\~, 'u\\\ 'u~<.:.'O.~"-~ \~ 1\)t\.\~t \1\) ~t\.\~
os últimos 10%, seções críticas dos primeiros 90% precisam ser alteradas. O
Teorema da Expansão e a programação de cima para baixo podem garantir que os
primeiros 90% podem permanecer intactos enquanto os últimos 10% são concluídos conforme o cronograma.

Teorema de Expansão (Versão Verbal)
Teorema: Em uma expansão de função de programa da forma (conjuntos de dados suprimidos;
veja abaixo para mais detalhes):
1. f =[(BLOCK, g, h)]
Qualquer par (g, h) cuja composição é f pode ser escolhido.
2. f =[(IF-THEN-ELSE, p, g, h)]
Qualquer predicado p com o mesmo domínio que f pode ser escolhido; então g
e h são totalmente determinados, como os membros da partição de f definida
por p.
3. f =[(DO-WHILE, p, g)]
A função de programa f deve ser a identidade na interseção de seu
domínio e intervalo; qualquer função g pode ser escolhida cuja conclusão
é a parte variável de f; e p é totalmente determinado por f e g.
Em suma, a invenção de um programa IF-THEN-ELSE é equivalente
a uma partição de uma função de programa prescrita, enquanto a invenção
de um programa DO-WHILE é equivalente à determinação de uma função
cuja conclusão é uma função de programa prescrita. Ou seja, a única
liberdade em um programa IF-THEN-ELSE é seu predicado, e a única
liberdade em um programa DO-WHILE é seu processo iterativo - todas as outras liberdades,
nas cláusulas THEN ou ELSE, ou no predicado WHILE, são
ilusões. As cláusulas THEN e ELSE são frequentemente usadas para elaborar
especificações funcionais não totalmente declaradas; mas essas não são liberdades de
escolha, mas interpretações de intenções em níveis mais detalhados. O ponto
é que se as especificações funcionais são suficientemente bem definidas para decidir
se um programa as satisfaz, então não há liberdade além da
escolha do predicado em um programa IF-THEN-ELSE. No caso do
DO-WHILE a questão é mais sutil e se relaciona ao caráter
das questões de término na programação de cima para baixo, em contraste com a de baixo
para cima. O predicado WHILE é completamente determinado no domínio
e intervalo da função (especificação). O programa DO-WHILE deve
terminar ao atingir qualquer elemento do intervalo e deve continuar caso contrário,
porque se não, ele não pode satisfazer a especificação de função pré-estabelecida (de cima para baixo
herdada).
Para formular uma versão mais concisa e teórica do Teorema da Expansão, introduzimos uma reinterpretação da constante lógica
"Verdadeiro". Normalmente, um predicado é considerado uma função, p, tal que
range(p) = {Verdadeiro, Falso}.
Reinterpretamos a constante Verdadeiro pela declaração para uma
função associada
p= {(x,y) I (x, Verdadeiro) E p};
isto é, se p(x) for verdadeiro, então para qualquer elemento y, (x, y) E p.
Também introduzimos a ideia de um refinamento de uma função, correspondendo
à ideia comum do refinamento de uma partição. (Um refinamento
de uma partição é simplesmente uma nova partição, cada um dos quais membros é
um subconjunto de algum membro da partição original.) Formamos uma partição
do domínio de uma função, chamada partição de conjuntos de níveis, ou o contorno
da função, agrupando argumentos que têm valores idênticos em subconjuntos
do domínio. Então dizemos que uma função é um refinamento de
outra se seu contorno é um refinamento das outras.
Finalmente, definimos os pontos fixos de uma função f, denotados como o
subconjunto fixed(/):
fixed(f) = { (x, y) I (x, y) E fAx = y}.
Teorema da Expansão (Versão Teórica de Conjuntos)
Teorema: Em uma expansão de programa da forma (conjuntos de dados suprimidos; veja abaixo
para mais detalhes):
I= [(BLOCK, g, h)]
1. Escolha a função g como qualquer refinamento da função de programa / .
2. Então h é determinado exclusivamente pela relação
f = g *h.
j =[(IF-THEN-ELSE, p, g, h)]
1. Escolha o predicado p tal que domain(p) = domain(!).
2. Então g e h são determinados exclusivamente pelas relações
c='Pnt
h = f-g.
Considere (s, v) E /, isto é, v E range (f). Notamos que necessariamente
p(v) =False. Caso contrário, o caminho de controle tog é tomado, e o programa
não pode terminar com o valor v, o que contradiz a correção da
expansão.
Em seguida, considere (r, v) E f tal que r E domínio(!) n range(!); então
p(v) =False pela observação anterior, e a função g é ignorada, então
que necessariamente v = r ou r E domínio(fixo(f)). Por outro lado, se r E domínio
(fixo (f)), então r E range(!) e p(r) =False; portanto r E domínio(!)
n range(!). Isto é, domínio(fixo(f)) =domínio(!) n range(!), como
precisava ser mostrado.
Em seguida, choose_junction g tal que * g * = f- fixed (f). Pelo menos uma
dessa escolha é possível, a saber, para g = f- fixo (f), uma vez que o domínio e
o intervalo fora de - fixo (f) são disjuntos.
Finalmente, já vimos que necessariamente p(x) = Falso quando x E
intervalo(!). Mas claramente, devemos ter p(x) = Verdadeiro quando x E domínio(g),
para que o caminho de controle correto seja tomado para finalmente atingir uma saída
v E intervalo (f); além disso, uma vez que * g * :J f, então necessariamente domínio (g)
:J domínio (*g*) :J domínio(!), de modo que x E domínio(g) implica x E domínio
(f). Assim, em resumo,
p(x) = . Verdadeiro se x E domínio(g) - intervalo(!)
p(x) = Falso se x E intervalo(!),
como seria mostrado.
Os conjuntos de dados necessários são os seguintes:
Defina R = domínio(!) .
Defina V = intervalo (f).
Defina T = domínio(g).
Defina U = intervalo(g).
ConjuntoS = R U U.
Esta discussão é concluída com uma caracterização combinatória de
g, o processo iterativo de um programa DO-WHILE.
Para a função j, considere qualquer superfunção h tal que intervalo(h) =
intervalo(/). Para cada conjunto de níveis, ou contorno, de h, defina qualquer conjunto arbitrário
de árvores enraizadas em seus elementos. Se x do domínio (h) for uma raiz de tal árvore.
então definimos
y(x) = h(x).
Se x E domínio(h) não for uma raiz de tal árvore, deixe y denotar o pai de
x naquela árvore, e defina
g(x) = y.
É facilmente verificado que qualquer função g assim definida, e nenhuma outra, satisfará
a relação * g * = f.
Com isso fica claro que em todos os três casos toda a liberdade de escolha
é combinatória. Em um programa BLOCK é a escolha de uma função;
em um programa IF-THEN-ELSE a escolha é uma partição de uma função:
em um programa DO-WHILE a escolha é uma estrutura de árvore dentro dos níveis
conjuntos de uma função.
Programas Indeterminados
Em certas aplicações, particularmente aquelas de inteligência artificial (veja Nilsson
[33]), é conveniente generalizar a ideia de um programa para uma construção
que permite ambiguidade na execução, em vez de exclusividade. Por
exemplo, um algoritmo pode especificar uma seleção de um membro de algum conjunto
para processamento, sem nomear um membro específico. Neste caso, resultados intermediários
e/ou finais podem ser indeterminados. Tais "algoritmos indeterminados"
são frequentemente úteis para descrever os fundamentos de um processo sem
se envolver indevidamente com suas especificidades. Algoritmos indeterminados são
também úteis para tratar um sistema de computação pessoa-máquina, no qual as
ações de pessoas - digamos, em terminais - são indeterminadas. Então, um sistema inteiro
pode ser definido para ser governado por um algoritmo indeterminado.
Nosso desenvolvimento de programas, que chamamos de "programas determinados",
quando necessário, pode ser generalizado para incluir "programas
indeterminados" por uma extensão muito simples - ou seja, estendendo a ideia de
função para a ideia de relação. Uma relação é definida para ser uma

conjunto de pares ordenados, sem a qualificação adicional necessária de uma
função para fornecer valores únicos para argumentos dados. Assim como com funções,
relações herdam propriedades de conjunto. Na verdade, não apenas a interseção e a diferença
de duas relações são novas relações (como no caso de funções), mas
a união de duas relações também é uma relação (geralmente não para funções).
Domínios e intervalos de relações são definidos como para funções.
Em seguida, definimos um programa indeterminado como um conjunto finito de
relações, chamadas instruções indeterminadas, cada um dos domínios está incluído
em um espaço de dados, e cada um dos intervalos está incluído no produto cartesiano
do espaço de dados e do programa indeterminado, novamente chamado
de espaço de estado. Uma execução de programa indeterminado é, novamente, uma sequência
de valores de estado
s = (d;, ri), i = 0, 1, ...
tal que
que termina, se alguma vez, quando di ~ domain(ri) . Exatamente como antes, todas as
execuções que terminam definem um conjunto de pares ordenados, agora uma relação
em vez de uma função, que chamamos de relação de programa indeterminado; isto
é, em retrospecto, um programa indeterminado é uma regra (não única) para calcular
os membros de sua relação, usando outras relações ao fazê-lo.
Neste ponto, deixamos para o leitor observar que toda construção
e teorema passa por programas indeterminados e suas
relações, assim como para programas determinados e suas funções.

Ler programas como uma
Atividade gerencial

É uma prática comercial padrão para gerentes medir a quantidade e
qualidade da produção de suas organizações. Mas, em grande medida,
houve uma exceção na programação, onde o trabalho foi
de origem misteriosa e especializada. Essa exceção foi necessária no
passado porque produzir programação de computador era um processo ad hoc
cujos resultados eram mais visíveis em sua execução do que em si mesmos.
Mas, à medida que as bases técnicas surgem e a programação se torna um
processo mais gerenciável, essa condição mudará.
No que diz respeito aos esforços humanos, a programação é uma atividade muito jovem.
Ela viu uma sucessão de máquinas, começando há cerca de 25 anos. No
início, as máquinas tinham operações muito simples, necessariamente feitas sequencialmente
e relacionadas a apenas um único conjunto de elementos de armazenamento de dados. Mas até o
presente, passamos por três grandes gerações de hardware, cada uma
com sofisticação crescente. Há novas complexidades em operações de processamento de dados simultâneas, que envolvem não apenas vários processadores, mas,
para cada processador, muitos canais (que são eles próprios processadores especiais),
operando nas mesmas memórias que as principais unidades de processamento
central. Técnicas extensivas de armazenamento e endereçamento de dados foram desenvolvidas,
em termos de endereçamento baseado e indexado no armazenamento principal, endereçamento de
registro múltiplo para processamento de alta velocidade múltiplo e uma variedade de
unidades de armazenamento em massa e entrada/saída, cada uma das quais tem um tipo peculiar de armazenamento de dados e ligação de transferência com o armazenamento principal. Essas mudanças
na arquitetura de hardware tiveram o efeito de manter o estado da arte da programação "desequilibrado", tornando obsoleto muito do conhecimento de
gerações de máquinas anteriores (por exemplo, IBSYS no 7094, no que diz respeito
ao 360) e mantendo a programação como a misteriosa arte negra que muitas vezes parece ser hoje.
Por mais doloroso que o desenvolvimento de hardware tenha sido em termos de software
adaptação e programação de ponta, esse desenvolvimento de hardware
produziu resultados espetaculares em termos de processamento e
capacidades de armazenamento. As máquinas agora podem processar e armazenar várias ordens de
magnitude a mais de dados pelo mesmo custo que poderia ser feito no início
da computação. O hardware proliferou a complexidade em software, mas essa
mesma economia também tornou certas simplificações no desenvolvimento de software
possíveis, ao permitir ineficiências no uso de hardware. Por exemplo,
linguagens de alto nível como Fortran ou PL/l são possíveis e práticas
nas máquinas de hoje, onde não seriam razoáveis ​​para
as eficiências exigidas das primeiras máquinas. As máquinas de hoje podem
ser usadas para ajudar a supervisionar suas próprias atividades e as atividades dos programadores,
onde eram um recurso muito escasso e caro para esse
propósito nos primeiros dias da computação.
Essas influências econômicas e técnicas estão convergindo para um novo
modo de operação no qual a linha de base para programação e desenvolvimento de software
é uma "máquina virtual" composta conjuntamente de hardware, software
e frequentemente algum firmware (isto é, microprogramação). Como resultado
o problema de gerenciamento de software está vendo uma plataforma mais estável
a partir da qual desenvolver. Essa plataforma mais estável inclui linguagens como
PL/I, Fortran e Jovial, nas quais é prático executar as principais
seções de grandes sistemas de programação e nas quais as idiossincrasias
desta ou daquela máquina são amplamente ocultadas pela tradução de alto nível
linguagem para linguagem de máquina automaticamente e de forma praticamente
sem erros. Essa plataforma estável introduz uma nova possibilidade para gerenciar
programação e para o desenvolvimento de grandes sistemas de programação
que não estava presente antes. Até agora não houve nenhuma boa
razão para os gerentes aprenderem a ler programas escritos em um código de máquina
ou outro, já que essa habilidade seria obsoleta no próximo projeto,
quando uma nova arquitetura de máquina fosse implementada. Mas a estabilidade da
plataforma de software atual em níveis de linguagem de programação acima de máquinas individuais
torna a leitura de programação uma habilidade e um recurso para
gerentes que vale a pena adquirir e, de fato, é necessária para o efetivo
desenvolvimento de grandes sistemas de programação ou a avaliação de programadores
em projetos de desenvolvimento.
Programas são declarações imperativas para máquinas para realizar
propósitos de algum conjunto de usuários. Essas declarações imperativas são formuladas
em linguagens de programação, e sua autoria é chamada de programação.
Mas como em qualquer linguagem escrita, geralmente é mais fácil aprender a ler a
linguagem do que escrevê-la, e de fato muito pode ser realizado
na aquisição de informações ou na revisão crítica de documentos na
linguagem com capacidade somente de leitura. Normalmente, ao ler uma linguagem,
alguém adquire automaticamente uma certa habilidade para escrevê-la, mas não
necessariamente a habilidade de atingir objetivos específicos em tal escrita.
Por essas razões, parece que chegou a hora de os gerentes
começarem a ler programas de forma sistemática, mesmo que a escrita
de tais programas não seja, e nunca será, parte de sua responsabilidade.
O advento da programação estruturada torna a leitura de programas
mais facilmente realizada do que nunca foi possível porque permite
ao leitor desfrutar de um privilégio especial na leitura, a saber, o
de ler de forma sequencial e sistemática, como em um texto inglês comum
para seguir os requisitos imperativos estabelecidos pelo
programa. Em programas que não são estruturados, a leitura do programa requer
muitos saltos para frente e para trás na sequência do texto
e manter o controle mental de muitas contingências nas quais ramificações
podem ser tomadas e condições especiais ou diferentes tratadas. A programação estruturada
força o escritor de programas a organizar as declarações de linguagem
para que possam ser lidas sequencialmente. Os principais beneficiários
desta disciplina são os próprios programadores, mas qualquer outra pessoa que tenha
uma ocasião para ler o código se beneficia de maneiras individuais ainda maiores
por causa do problema de familiaridade com o programa. Muitas vezes, um
programador que escreve um programa não estruturado terá em mente algum
padrão de operações que permite pular para frente e para trás de uma maneira
eficiente. Mas com a mesma frequência, o salto para frente e para trás acaba confundindo
o programador original, e o resultado é que os erros do programa podem
ir tão longe quanto a integração do sistema ou mesmo na operação do usuário antes de serem
detectados. Para alguém não familiarizado com o programa, a programação estruturada
tem um efeito ainda mais dramático porque essa pessoa não
tem o problema de determinar quais saltos olhar primeiro ou como
acompanhar os vários saltos em algum padrão de pensamento que deve
ser desenvolvido ad hoc durante o processo de leitura.
Com o tempo, espera-se que coloquemos o cavalo na frente da carroça
e ensinemos a leitura do programa a qualquer pessoa antes de escrevê-lo. Na verdade, nossos
cursos de programação atuais são padronizados ao longo daqueles de um "curso em
dicionário francês". Em tal curso, estudamos o dicionário e aprendemos
quais são os significados das palavras francesas em inglês (que corresponde a
aprender o que as instruções PL/I ou Fortran fazem com os dados). Na conclusão
de tal curso em dicionário francês, convidamos e exortamos os graduados
a seguir em frente e escrever poesia francesa. Claro, o resultado é que
algumas pessoas podem escrever poesia francesa e outras não, mas as habilidades críticas
em linguagens de programação, e sua autoria é chamada de programação.
Mas como em qualquer linguagem escrita, geralmente é mais fácil aprender a ler a
linguagem do que escrevê-la, e de fato muito pode ser realizado
na aquisição de informações ou na revisão crítica de documentos na
linguagem com capacidade somente de leitura. Normalmente, ao ler uma linguagem,
alguém adquire automaticamente uma certa habilidade para escrevê-la, mas não
necessariamente a habilidade de atingir objetivos específicos em tal escrita.
Por essas razões, parece que chegou a hora de os gerentes
começarem a ler programas de forma sistemática, mesmo que a escrita
de tais programas não seja, e nunca será, parte de sua responsabilidade.
O advento da programação estruturada torna a leitura de programas
mais facilmente realizada do que nunca foi possível porque permite
ao leitor desfrutar de um privilégio especial na leitura, a saber, o
de ler de forma sequencial e sistemática, como em um texto inglês comum
para seguir os requisitos imperativos estabelecidos pelo
programa. Em programas que não são estruturados, a leitura do programa requer
muitos saltos para frente e para trás na sequência do texto
e manter o controle mental de muitas contingências nas quais ramificações
podem ser tomadas e condições especiais ou diferentes tratadas. A programação estruturada
força o escritor de programas a organizar as declarações de linguagem
para que possam ser lidas sequencialmente. Os principais beneficiários
desta disciplina são os próprios programadores, mas qualquer outra pessoa que tenha
uma ocasião para ler o código se beneficia de maneiras individuais ainda maiores
por causa do problema de familiaridade com o programa. Muitas vezes, um
programador que escreve um programa não estruturado terá em mente algum
padrão de operações que permite pular para frente e para trás de uma maneira
eficiente. Mas com a mesma frequência, o salto para frente e para trás acaba confundindo
o programador original, e o resultado é que os erros do programa podem
ir tão longe quanto a integração do sistema ou mesmo na operação do usuário antes de serem
detectados. Para alguém não familiarizado com o programa, a programação estruturada
tem um efeito ainda mais dramático porque essa pessoa não
tem o problema de determinar quais saltos olhar primeiro ou como
acompanhar os vários saltos em algum padrão de pensamento que deve
ser desenvolvido ad hoc durante o processo de leitura.
Com o tempo, espera-se que coloquemos o cavalo na frente da carroça
e ensinemos a leitura do programa a qualquer pessoa antes de escrevê-lo. Na verdade, nossos
cursos de programação atuais são padronizados ao longo daqueles de um "curso de
dicionário francês". Em tal curso, estudamos o dicionário e aprendemos
quais são os significados das palavras francesas em inglês (que corresponde a
aprender o que as instruções PL/I ou Fortran fazem com os dados). Na conclusão
de tal curso de dicionário francês, convidamos e exortamos os formandos
a seguir em frente e escrever poesia francesa. Claro, o resultado é que
algumas pessoas podem escrever poesia francesa e outras não, mas as habilidades críticas para escrever poesia não foram aprendidas no curso que acabaram de fazer no dicionário francês. Por exemplo, aqueles que poderiam escrever poesia em inglês
provavelmente acabarão como os melhores escritores de poesia francesa. Isso corresponde em
programação ao fato de que as pessoas que fazem o curso de programação
que acabam fazendo a melhor programação são aquelas que entraram no
curso com certas habilidades algorítmicas e analíticas, bastante independentes
de qualquer coisa que aprenderam no curso em si.
Mas é um fato que alguém pode ler programas por razões bem diferentes
das que alguém poderia ter para escrevê-los, e que habilidades de verificação
ou de tradução podem ser bem diferentes das habilidades algorítmicas e analíticas
necessárias para escrever programas.
Com a leitura em massa de programas por gerentes, outras
anomalias de programação podem ser esperadas para acontecer. É curioso
que em programação, o programador típico nunca espera ver alguém
mais lendo o programa. O programador será julgado pela execução e
julgado de maneiras altamente superficiais. Quando as máquinas fazem um milhão
multiplica por segundo, um fator de dez na ineficiência não é nem detectável
a menos que o programa seja um conjunto bem usado de problemas que muitas outras pessoas
fizeram para comparação. Da mesma forma, o uso do núcleo é difícil de julgar
a menos que existam padrões bem usados ​​de comparação por aí. Sabemos
por experiência e amostragem pontual que os programas podem ser muito ineficientes
tanto em rendimento quanto em núcleo, e também sabemos que a lógica do programa pode ser
muito torturada, difícil de manter e praticamente impossível de construir oe
ou estender; ainda assim, programas com deficiências tão grosseiras passam "pela inspeção
de execução" com sucesso todos os dias. Não é de se admirar que os programadores
tenham problemas psicológicos às vezes porque são privados de uma necessidade muito
humana em seu trabalho - a necessidade de serem apreciados ou a necessidade de serem
elogiados por um trabalho bem feito. Enquanto ninguém ler seu código e
enquanto todos se conc
Às vezes é surpreendente pensar em quão rápido uma sociedade pode se tornar
inflexível. A programação tem menos de 20 anos; como uma atividade de gestão.
tem menos de 10 anos. Ela já desenvolveu algumas vacas sagradas.
como ver a leitura de código como um sinal de desconfiança ou os julgamentos
de código por qualquer coisa que não seja a inspeção grosseira pela execução uma impertinência
de gestão. Essas vacas sagradas nasceram facilmente e serão mortas
facilmente também. Qualquer experiência com gerentes que leem código de forma inteligente
mostra que os programadores estão mais motivados e orgulhosos de seu
trabalho de uma forma que não seria possível de outra forma.
A leitura de programas por gerentes também introduzirá um novo
nível de precisão na programação que é possível, mas não tornado
inevitável, por novos desenvolvimentos técnicos em programação. A programação estruturada e os resultados na correção do programa dão aos programadores uma base técnica
para escrever código quase sem erros, mas esse potencial não será
realizado sem uma transformação psicológica também. Voltamos ao
problema de uma atividade de 20 anos tateando seu caminho para um processo
sistemático, passando de uma atividade frustrante de tentativa e erro, altamente "criativa"
na qual inteligência e ofuscação são virtudes para um processo sistemático de engenharia
na qual a ênfase está na precisão, lógica e repetibilidade.
Essa transformação psicológica não é um processo reservado para
pouquíssimos indivíduos talentosos. É um processo que vimos começar a
acontecer em larga escala, de pessoal júnior a sênior. Simplesmente
se resume a isso. Quando um programador sabe que o que está em sua
cabeça está correto, torna-se mais importante de repente colocar isso no
papel exatamente naquela forma correta, consultar definições de dados anteriores para
ter certeza de que são precisamente compatíveis e examinar cada caso
especial com mais cuidado para garantir que eles tratem o assunto
exatamente da maneira correta. Essa psicologia da precisão parte desse entendimento
da capacidade lógica do próprio programador para o
desenvolvimento de material legível por máquina, seja qual for a forma como ele é realizado.
Por outro lado, se um programador pensa que o que está em sua mente
está correto, mas está subconscientemente contando com execuções de depuração para resolver
pequenos erros na lógica, então a concentração é perdida aqui e em todo o
processo, e pequenos erros são cometidos que mais tarde atormentam o programador
e outros no processo de depuração. A questão crítica não é simplesmente para
um programador ser capaz de programar corretamente. O programador deve saber
que ele ou ela é capaz de programar corretamente. Pois é esse último conhecimento da
habilidade de programar corretamente que afeta a transformação psicológica
e torna possível a concentração necessária para escrever os
programas corretos. Essa diferença entre ser capaz de programar corretamente
e saber disso é uma distinção que está disponível para um programador somente após
educação considerável em questões de matemática e lógica que permitem
a uma pessoa considerar a programação como uma atividade lógica semelhante em forma a um
jogo como jogo da velha, e diferindo do jogo apenas no grau
de complexidade, mas não em qualquer requisito inerente que transcenda as
capacidades humanas do programador.
Programadores com esse tipo de transformação psicológica ficarão
decepcionados de fato se seu código não for lido e se o raciocínio que
eles formulam para seu código não for apreciado.
A questão da documentação tem atormentado o gerenciamento de programação
por muito tempo. Na teoria matemática por trás da programação estruturada,
a documentação acaba tendo um lar natural. A documentação
de um programa e a prova de que ele está correto são sinônimos.
Na verdade, qualquer coisa além disso é supérflua. Essa prova de correção pode
estar em vários níveis: no nível do usuário, no nível de manutenção do programa ou mesmo em alguns casos no nível da máquina. Mas o problema da correção fornece
a justificativa e uma base para julgamento da relevância e qualidade da
documentação que não tínhamos antes.
Nas provas de correção do programa, a documentação aparece como
um complemento do próprio programa. É fácil apontar para a documentação que
tenta substituir o código. Quando isso ocorre, há um perigo frequente
de que o código seja alterado sem que a documentação seja alterada; o
resultado é que a documentação perde sua atualidade. Quando os programas são mantidos
em uma forma visivelmente correta, os padrões de correção são eles próprios
padrões para manter a documentação em uma forma atual e relevante.

Como comprar software de qualidade
Algumas lições aprendidas — e outras não!
ARTIGO
15
A aquisição de software tem muitas semelhanças e analogias com a aquisição de hardware,
mas uma transferência cega de conceitos e procedimentos tem
levado a desastres monumentais. E uma coisa estranha sobre esses desastres é
que eles geralmente são escondidos tanto pelo comprador quanto pelo vendedor. O comprador não
quer parecer idiota ou enganado, então a reação ao desastre geralmente toma
a forma "Veja o quanto aprendemos na fase 0; estamos em boas condições para
começar o desenvolvimento da fase 1" — quando na verdade o termo "fase 0" surgiu
há apenas seis meses, quando algo parecia errado; três
anos atrás o projeto não tinha fases — era a coisa real! O vendedor também
não quer parecer idiota, ou que o desastre seja conhecido e afete
a reputação do vendedor. Então, os desastres geralmente são escondidos, e as chances de aprender
lições importantes são perdidas.
Admitindo que há semelhanças com a aquisição de hardware, nós
também notamos diferenças cruciais na aquisição de software [4].
1. Mais flexibilidade para mudanças de engenharia é necessária. "Todo mundo sabe
que o hardware tem que ser consertado para fabricação, mas o software tem
um processo de fabricação trivial - duplicar uma fita, e esse tipo de
coisa, então por que o software não consegue responder?"
2. Deficiências de hardware precisam ser compensadas no software. "Então o
pacote de memória não funcionou e apenas metade da memória planejada
está disponível, mas alguns programadores inteligentes devem ser capazes de
contornar isso."
3. A complexidade absoluta tem que ser levada em conta. A função de hardware
é normalmente fornecida em um conjunto de instruções de pequenas operações independentes,
cada uma das quais pode ser projetada e testada em relativo isolamento.
A função de software é normalmente fornecida na interface do usuário que chama
conjuntos complexos e interdependentes de operações que são difíceis de projetar
e testar.
Uma conclusão pragmática
Não é possível aceitar adequadamente um sistema de software "lançado
sobre o muro" sem despesas exorbitantes. Por quê? Porque o que precisa ser
testado é o design do software em si. Em hardware, o design é relativamente
simples, mas a fabricação é crítica, então os testes de função de hardware
confirmam a fabricação para um design relativamente simples. Em software, o
design é relativamente complexo, e a fabricação é trivial, então os testes de
função de software dependem criticamente do design.
Ainda mais crucial, a coisa mais importante sobre um sistema de software
é a integridade de seu design - mas essa integridade não pode ser especificada
exceto em termos qualitativos. No entanto, é justamente essa integridade que torna o
sistema de software fácil ou difícil de manter e modificar, impossível ou não
de usar como uma plataforma para uma capacidade de acompanhamento. Um sistema de software pode
passar em seus testes de aceitação de desempenho e capacidade e ainda ser um
pesadelo interno de designs ad hoc reunidos como um tour de force nas memórias de curto prazo
de uma equipe de programadores que é dissolvida e dispersa
assim que os testes são concluídos.
O problema básico na compra de software é que a complexidade ainda desafia a
medição em termos pragmáticos [7]. Podemos medir se um sistema de software
requer muita memória ou muito tempo e reagir de acordo.
Mas não temos maneiras práticas e objetivas de diferenciar um sistema bem projetado
de profundas simplicidades de uma tigela de espaguete de força bruta. A programação estruturada
deu um salto quântico ao abordar o problema de design
[5, 6, 9], mas ainda há necessidade de medição prática da complexidade
dentro de sistemas estruturados.
Uma maneira de contornar isso é não comprar sistemas de software, mas
alugá-los. Nesse caso, há incentivos significativos para o fornecedor
fornecer um sistema que funcione após o teste de aceitação, bem como por meio do teste de aceitação, e o ônus de manter uma tigela de espaguete recai
sobre o fornecedor. Para sistemas únicos, o aluguel pode não ser viável,
mas fornecer incentivos para o desempenho e manutenção pós-aceitação
ainda pode ser possível.
Uma Proposta Pragmática
Pare de aceitar sistemas de software "jogados por cima do muro". Em vez disso, exija
duas condições para o desenvolvimento de sistemas, que são observáveis ​​durante o
processo de desenvolvimento: (1) programação estruturada de cima para baixo [6] para fornecer
melhor visibilidade da integridade do sistema durante sua construção e (2) contabilidade
de desenvolvimento [8] para avaliar melhor a qualidade do próprio
processo de desenvolvimento.
Na programação estruturada de cima para baixo, uma disciplina sistemática permite
uma revisão contínua e ordenada do progresso do desenvolvimento, à medida que as especificações
de sistemas são traduzidas em design e software funcional. Isso está em
forte contraste com o desenvolvimento tradicional de baixo para cima, no qual pouca
revisão efetiva é possível até a fase de integração no final do desenvolvimento.
A programação estruturada de cima para baixo requer mais habilidade de design e
pensamento no início de um desenvolvimento, mas compensa na visibilidade
de gerenciamento durante o desenvolvimento [1]. O desenvolvimento de cima para baixo também torna a contabilidade
de desenvolvimento viável, o que não é viável no desenvolvimento de baixo para cima
por causa da grande quantidade de retrabalho e acusações no momento da integração.
A ideia da contabilidade de desenvolvimento é registrar dados suficientes sobre
o histórico de desenvolvimento, incluindo o destino de cada linha de código criada, para que
estatísticas de gerenciamento significativas possam ser geradas e estudadas. Pode haver
resistência em registrar o destino de cada linha de código — cada erro do programador — em alguns projetos, mas isso já foi feito [1, 3]
e representa pequenas dores de crescimento em uma profissão adolescente. Haverá
custos associados a esse registro, mas no máximo 5% em projetos
onde estouros de 20% são a regra e estouros de 100% ocorrem com mais frequência
do que qualquer um gostaria de admitir.
É de se esperar que muitas novas ideias e usos para esses dados
surjam quando eles se tornarem disponíveis para estudo e uso. Assim como na
contabilidade financeira, os padrões de gerenciamento de integridade, objetividade e julgamento
precisam ser desenvolvidos. Mas com tanto em jogo e tão pouco a arriscar, a
contabilidade de desenvolvimento parece um negócio de primeira ordem para o gerenciamento de sistemas
em aprender melhor "como comprar software de qualidade".

Contabilidade de Desenvolvimento
O desenvolvimento de software é uma nova atividade para a raça humana, lidando com
complexidade e precisão lógica nunca antes exigidas dos humanos. Então
frustrações e melhorias subsequentes podem ser esperadas. Como consequência
de sua infância e adolescência, o desenvolvimento de software tem sido
praticado como uma arte negra - não maliciosamente, mas porque nunca pareceu
possível ou necessário fazer disso uma prática pública. Mas a tecnologia de desenvolvimento de software está amadurecendo e passando de uma arte privada para uma
prática pública [1, 3].
Os jovens (pessoas ou indústrias) nunca se interessam muito por
história, mas aprendem. Teoricamente, um sistema de software existe a qualquer
momento independente de seu desenvolvimento histórico, e qualquer outra história
que chegue ao mesmo sistema produzirá o mesmo histórico de uso subsequente.
Mas a chance prática de duas histórias de desenvolvimento diferentes produzirem
um sistema de software idêntico é quase zero. Os sistemas podem parecer semelhantes
ao usuário, cada um pode ter "nenhum erro conhecido" e assim por diante, mas seus internos
serão diferentes, e sua integridade de design e propriedades de erro futuras
serão diferentes. Suponha que dois desses sistemas, chamados A e B e desenvolvidos
para as mesmas especificações, produzissem as estatísticas na Tabela 15-1. Após
a aceitação, cada sistema não tem "nenhum erro conhecido". Na verdade, o sistema A pode
ter mais erros restantes do que o sistema B. Mas as evidências apontam para
o sistema B, que foi difícil de montar, com erros de interface aparentemente sutis
que levaram um tempo considerável para serem encontrados e, portanto, tem a probabilidade
de mais erros ainda não descobertos. De um ponto de vista prático, esses
não são os mesmos sistemas e, geralmente, A acabará sendo melhor projetado
(menos erros antigos) e mais confiável.
As estatísticas anteriores não são mantidas, é claro, no processo típico de desenvolvimento de software de arte negra, por causa da noção de que é uma questão privada como um sistema chega a um estado de "nenhum erro conhecido". Mas realmente importa como um sistema chega a tal estado porque prevê como o sistema se sairá no futuro. Estatísticas de desenvolvimento
Um sistema bem projetado de simplicidades profundas tem um histórico de desenvolvimento que é nitidamente distinto da tigela de espaguete de força bruta. A diferença mais notável é o histórico de depuração. Um sistema bem projetado pode ser montado com poucos erros durante suas fases de código e integração [1, 2]. Uma tigela de espaguete terá um histórico de muita descoberta de erros e consertos. Portanto, um parâmetro crítico de contabilidade é o número de erros encontrados e corrigidos - todos os erros do bloco de codificação ou terminal em diante. É um procedimento de última geração
hoje rastrear erros de testes unitários em diante, mas não um procedimento de última geração
rastrear erros de linhas de código em diante.
Outra diferença está na idade dos erros encontrados. Em um
desenvolvimento de programação estruturada de cima para baixo bem projetado [6], o teste sob
condições reais do sistema começa cedo, com erros do sistema encontrados em
normalmente um dia ou mais. Na abordagem de força bruta, o código é frequentemente testado em unidades
com drivers, e erros do sistema são frequentemente encontrados mais tarde em semanas de integração ou
meses depois.
O número e a idade dos erros levam à ideia de dias de erro como
provavelmente a melhor estatística única que poderíamos medir para estimar a
qualidade de um sistema aceito de outra forma. Ele indica prováveis ​​incidentes de erro
futuros, mas também indica indiretamente a eficácia do design e
processo de teste. Dias de erro altos indicam muitos erros (provavelmente
devido a produtos de design intermediários ruins) ou erros de longa duração (provavelmente
devido a procedimentos de integração e teste ruins).
Com experiência, outras estatísticas serão úteis na avaliação
da qualidade do desenvolvimento do sistema. Classificações razoavelmente objetivas de todas
as adições, exclusões e modificações do programa em várias categorias são
possíveis, como as seguintes.
Por exemplo, erros de sintaxe são encontrados durante a montagem/compilação,
erros de lógica são encontrados na execução do teste e erros de design são encontrados na
codificação e assim por diante. Tais proporções como
Erros de design
Erros de lógica '
Erros de lógica
Erros de sintaxe'
Erros de design
Produção normal
descreverão diferentes aspectos do processo de desenvolvimento e fornecerão
indicadores e padrões de qualidade com gerenciamento de programação e aquisição
experiência.

Como escrever programas corretos e saber disso
Não há uma maneira infalível de saber que você encontrou o último
erro em um programa. Portanto, a melhor maneira de adquirir confiança de que um programa
não tem erros é nunca encontrar o primeiro, não importa o quanto
ele seja testado e usado. É um mito antigo que a programação deve ser um
processo de tentativa e frustração propenso a erros, de cortar e tentar, de ansiedade. A nova
realidade é que você pode aprender a escrever consistentemente programas que são
sem erros em sua depuração e uso subsequente. Essa nova realidade é
fundada nas ideias de programação estruturada e correção de programa,
que não apenas fornecem uma abordagem sistemática à programação
mas também motivam um alto grau de concentração e precisão no
subprocesso de codificação.
Palavras-chave e frases
programação estruturada
correção do programa
Introdução
práticas de programação
Um velho mito e uma nova realidade
É um velho mito que a programação deve ser um processo propenso a erros, de cortar e tentar
de frustração e ansiedade. A nova realidade é que você pode aprender a escrever consistentemente programas que são corretos ab initio e provam ser
sem erros em sua depuração e uso subsequente.
Ao praticar os princípios da programação estruturada e sua matemática
você deve ser capaz de escrever programas corretos e convencer a si mesmo
e aos outros de que eles estão corretos. Seus programas devem normalmente compilar
e executar corretamente na primeira vez que você os tenta, e daí em diante. Se você
é um programador profissional, erros de sintaxe ou lógica devem ser
extremamente raros porque você pode evitá-los com ações positivas de sua
parte. Programas não adquirem bugs como as pessoas adquirem germes - apenas por ficar
perto de outros programas com bugs. Eles adquirem bugs apenas de seus autores.
Há uma razão simples pela qual você deve esperar que seus próprios programas
estejam completamente livres de erros desde o início, para sua própria paz
de espírito. É que você nunca será capaz de provar que tal programa
não tem erros de forma infalível. Isso não é porque os programas são tão
complexos que não valem o esforço; é porque simplesmente não há uma maneira humana - lógica ou matemática - de provar isso, não importa quanto esforço
você possa colocar nele.
A fé máxima que você pode ter em um programa está no processo de pensamento
que o criou. Com cada erro que você encontra em testes e uso, essa
fé é minada. Mesmo que você tenha encontrado o último erro deixado em seu
programa, você não pode provar que é o último, e você não pode saber que é o
último.

A fé máxima que você pode ter em um programa está no processo de pensamento
que o criou. Com cada erro que você encontra em testes e uso, essa
fé é minada. Mesmo que você tenha encontrado o último erro deixado em seu
programa, você não pode provar que é o último, e você não pode saber que é o
último. Então sua verdadeira oportunidade de saber que você escreveu um programa correto
é nunca encontrar o primeiro erro nele, não importa o quanto ele seja inspecionado,
testado e usado.
Agora a nova realidade é que programadores profissionais, com profissional
cuidado, podem aprender a escrever consistentemente programas que são livres de erros
desde o início - programas de 20, 50, 200, 500 linhas e mais. Apenas
saber que é possível é metade da batalha. Aprender a escrever tais
programas é a outra metade. E ganhar experiência em escrever tais programas,
pequenos no início, depois maiores, fornece uma nova base psicológica
para concentração sustentada em programação que é difícil de imaginar
sem experiência pessoal direta. Os programadores profissionais de hoje estão
produzindo código na taxa de um erro por ano em seu trabalho finalizado;
esse desempenho não é possível por programação de cortar e tentar. O programador profissional
de amanhã se lembrará, mais ou menos vividamente,
de cada erro em sua carreira.

O que é um programa correto?
A programação cut-and-try enfrenta três tipos de dificuldades:
1. Mudanças de especificação
2. Erros de programação
3. Discrepâncias do processador

Um programa correto define um procedimento para um processador declarado satisfazer
uma especificação declarada. Se você não sabe o que um programa deve
fazer, ou não sabe como o processador deve funcionar, você não pode
escrever um programa correto. Então presumimos uma especificação conhecida e um processador
conhecido por completo. Mesmo assim, um programador praticante deve estar preparado
para lidar com especificações incompletas e mutáveis ​​e com processadores
que se comportam de forma diferente do que seus manuais dizem. Para essas dificuldades,
não temos remédio sistemático, exceto por reduções radicais de erros de
programação que podem ajudar a isolar dificuldades nessas outras áreas. No entanto,
a experiência usual em programação frequentemente falha em separar essas três
fontes de dificuldade, de modo que erros de programação — agrupados com todo
o resto — parecem muito mais inevitáveis ​​do que realmente são.
Escrever programas corretos não significa que você pode escrever programas
de uma vez por todas. Significa que você pode escrever programas para fazer exatamente
o que você pretende que eles façam. Mas, à medida que as intenções mudam, as mudanças de
programa também são necessárias. As mesmas oportunidades e princípios se aplicam a essas
mudanças de programa. Você deve ser capaz de modificar programas corretamente, se
eles forem bem projetados e explicados, bem como escrevê-los corretamente
para começar.
Essa distinção entre correção e capacidade é crítica para
entender essa nova realidade. Determinar o que um programa deve fazer é
geralmente um problema muito mais profundo do que escrever um programa para fazer um
processo predeterminado. É a última tarefa que você pode fazer corretamente. Por exemplo,
você pode querer programar um jogador de xadrez campeão mundial; isso é uma questão
de capacidade e um problema que você pode ou não ser capaz de resolver. Ou você
pode querer programar um jogador de xadrez cujo movimento foi determinado
para cada situação que possa surgir. Você pode escrever tal programa corretamente,
mas se ele se torna ou não um campeão mundial é outra questão.
A dificuldade com provas de correção
Começamos com uma dificuldade fundamental, que pode parecer fatal para nosso objetivo
mas que paradoxalmente nos diz o que fazer. Não há uma maneira
infalível de provar que um programa está correto. Essa dificuldade fundamental não está
na programação, mas na matemática — porque a ideia escolar de matemática
(ou lógica) como um corpo de verdades sobrenaturais e procedimentos infalíveis
simplesmente não é assim. A matemática é uma atividade humana sujeita à
falibilidade humana. Ela não tem segredos básicos de verdade ou razão. Um exemplo simples
está no que chamamos de "números naturais", que não são naturais de forma alguma.
Todo mundo aprende a contar nos "números naturais" com outra pessoa,
que aprendeu a contar com outra pessoa. Mas voltando o suficiente,
ninguém sabia contar! Os números naturais são invenções humanas conscientes,
assim como rádios, Hamlet e aviões. Eles sobreviveram
porque funcionam. E assim é com o que as crianças em idade escolar aprendem sobre frações,
equações quadráticas, cálculo e assim por diante, como se fossem "a
verdade, toda a verdade e nada além da verdade", quando nada poderia estar
mais longe da verdade.
Mesmo assim, a matemática é muito útil, e acreditamos que ela esteja amplamente
correta na maior parte de seu desenvolvimento. É correto o suficiente para conduzir negócios,
projetar computadores que funcionam e enviar homens à lua e de volta. E isso
é muito bom. Só não é infalível. Na verdade, você deve usar toda a matemática
que puder para ajudar a se convencer de que seus programas estão corretos.
Mas você deve fazer isso conhecendo as limitações da matemática,
e não procurando por alguma mágica para substituir sua própria responsabilidade.
O que é uma Prova Matemática?
Se não há um caminho infalível para uma prova matemática, o que é, e por que
se preocupar de qualquer maneira?
Uma prova matemática é um experimento repetível, assim como um experimento
em um laboratório de física ou química. Mas o sujeito principal em cada
experimento é outra pessoa. O resultado pretendido do experimento é uma
convicção subjetiva por parte dessa outra pessoa de que uma determinada hipótese
leva a uma determinada conclusão. O experimento pode ser realizado em uma
conversa, coletivamente em uma palestra ou por escrito. Em uma palestra ou por
escrito, muitas pessoas podem estar envolvidas. Um experimento bem-sucedido termina em uma
convicção subjetiva por um ouvinte ou leitor. A convicção pode estar incorreta.
A convicção pode estar correta, mas baseada em uma conversa falha.
Qualquer falibilidade humana pode estar presente, porque é uma atividade humana.
A conversa lida com uma prova de que a hipótese leva à
conclusão. A prova pode consistir em uma única afirmação, "É óbvio",
ou uma sequência de tais afirmações para uma sucessão de conclusões intermediárias,
cada uma das quais serve como uma hipótese para a próxima conclusão. Em cada
afirmação o sujeito concorda ou discorda; no primeiro caso, o experimento continua,
e no segundo caso, o experimento termina. Se a conclusão final
for alcançada, o experimento termina em sucesso; caso contrário, termina
em fracasso.
O que é uma Prova Matemática?
Se não há um caminho infalível para uma prova matemática, o que é, e por que
se incomodar de qualquer maneira?
Uma prova matemática é um experimento repetível, assim como um experimento
em um laboratório de física ou química. Mas o sujeito principal em cada
experimento é outra pessoa. O resultado pretendido do experimento é uma
convicção subjetiva por parte dessa outra pessoa de que uma dada hipótese
leva a uma dada conclusão. O experimento pode ser realizado em uma
conversa, coletivamente em uma palestra ou por escrito. Em uma palestra ou por
escrito, muitas pessoas podem estar envolvidas. Um experimento bem-sucedido termina em uma
convicção subjetiva por um ouvinte ou leitor. A convicção pode estar incorreta.
A convicção pode estar correta, mas baseada em uma conversa falha.
Qualquer falibilidade humana pode estar presente, porque é uma atividade humana.
A conversa lida com uma prova de que a hipótese leva à
conclusão. A prova pode consistir em uma única afirmação, "É óbvio",
ou uma sequência de tais afirmações para uma sucessão de conclusões intermediárias,
cada uma das quais serve como uma hipótese para a próxima conclusão. Em cada
afirmação o sujeito concorda ou discorda; no primeiro caso, o experimento continua,
e no segundo caso, o experimento termina. Se a conclusão final
for alcançada, o experimento termina em sucesso; caso contrário, ele termina
em fracasso.
A notação matemática não desempenha nenhum papel na prova, exceto em seu
efeito sobre o sujeito experimental. O que a notação matemática faz é
facilitar a comunicação e a memória humanas. Ela permite que uma sucessão de
afirmações sejam declaradas e acordadas rapidamente, para que mais terreno possa ser
coberto pelo mesmo esforço humano. Ela permite, com lápis e papel, que uma
pessoa estenda a memória para detalhes (por exemplo, fazendo uma divisão longa ou simplificando uma expressão algébrica). Ela até permite que os humanos concordem com
regras para concordar sobre afirmações de prova (lógica matemática).
O que é uma prova convincente? Claramente, isso depende do sujeito experimental. Mas para um determinado sujeito, há muitas conversas possíveis
sobre a mesma hipótese e conclusão. Se houver poucos passos,
o salto na intuição pode ser muito grande. Se houver muitos passos, a exaustão humana ou a falta de interesse podem se instalar. Portanto, é necessário um equilíbrio,
que depende do sujeito. Mas é um problema tipicamente humano, cuja
resolução requer experiência e julgamento humanos.
Por que se preocupar com matemática, se ela só leva a convicções subjetivas? Porque esse é o único tipo de convicção fundamentada possível,
e porque o principal sujeito experimental da sua conversa é
você mesmo! A matemática fornece linguagem e procedimento para sua própria
segurança mental. Adquirindo confiança em programas
Como observamos, nossa confiança máxima em um programa é subjetiva,
quer percebamos ou não. Se acreditamos que um programa está correto por causa de
uma prova formal de sua correção, nossa confiança subjetiva está na metodologia de prova
e na crença adicional de que essa metodologia se aplica ao
escopo total do programa.
Mais frequentemente, nossa confiança subjetiva em um programa é baseada em uma
combinação de experiência de sua inspeção (incluindo provas formais de
correção), teste e uso.
Se a programação for praticada como uma atividade de cortar e tentar, um certo
número de erros é esperado na sintaxe e lógica, e a fase de compilação, teste
e depuração é esperada para descobrir a maioria desses
erros. Mas mesmo em uma atividade de cortar e tentar, se o número de erros encontrados em
teste e depuração for excessivo, um programador pensativo fica desconfortável.
Em vez de ser grato por encontrar tantos erros, o programador
começa a duvidar dos processos de pensamento que os produziram. Muitos programadores
recomendam começar tudo de novo quando isso ocorre.
Por outro lado, como acontece ocasionalmente mesmo em uma atividade de cortar e tentar,
se um programa estiver livre de erros em todos os seus testes e uso - sem
nenhuma depuração necessária - a confiança subjetiva do programador é
notavelmente afetada. Nunca será possível provar que tal programa
não tem erros. Mas cada novo obstáculo que ele passa em mais testes e uso
melhora a plausibilidade de que isso seja assim e que os processos de pensamento que
produziram o programa estão se mantendo.
Então, quando você pensa sobre isso, o objetivo real na programação

deveria ser escrever programas corretos desde o início, não apenas emergir
da depuração sem erros. A nova realidade é que escrever tais
programas corretos desde o início é uma atividade humana muito possível. E é assim que
a própria impossibilidade de provas infalíveis da correção dos programas
nos diz o que devemos fazer. Se nenhum erro ocorre em um programa, então uma prova
de correção não pode nos dizer mais nada.
A descoberta pessoal dessa nova realidade muda a vida de um
programador ao introduzir uma consciência psicológica inteiramente nova do
poder e dos benefícios da concentração no design e codificação de programas. Há
pouca motivação para se concentrar em uma atividade de cortar e tentar; mais um erro
para descobrir entre muitos é de pouca consequência. Mas em uma atividade mental de precisão
a diferença entre nenhum erro e um é profunda. Quando um
programador descobre o poder de suas próprias capacidades mentais,
o que entra no programa como um reflexo do pensamento do programador
se torna muito mais importante.
Se uma criança sabe jogar um jogo da velha perfeito, mas não sabe o que sabe, ela ainda perde jogos ocasionalmente por falta de concentração, mas não reconhece seus lapsos. Se for solicitada a jogar um jogo importante (digamos, por uma barra de chocolate), sua atitude é "Espero ganhar", mas se perder, ela diz "Que azar". Se essa mesma criança descobrir que sabe jogar jogo da velha perfeitamente, toda a sua atitude muda. Em vez de dizer "Espero ganhar", ela diz. "Depende de mim!" Ela pode perder, mas em vez de dizer "Que azar", ela diz "Eu errei!", e descobriu sua própria falta de concentração. E se ela gosta de barras de chocolate, ela logo aprende a se concentrar durante jogos importantes e a relaxar depois. É o mesmo com o programador que descobre que é importante saber "como escrever programas corretos e conhecê-los".

Fundamentos de programação
Funções como expressões da lógica essencial do programa
Um programa opera em dados, alguns deles intencionais, alguns deles frequentemente um
subproduto de fazer outra coisa. Por exemplo, um programa pode operar
em uma matriz para recalcular seus elementos, mas ao mesmo tempo calculará
subscritos para identificar elementos específicos da matriz durante a execução.
Em particular, os últimos valores para subscritos serão deixados
na memória. Normalmente, alguém estará interessado nos elementos da matriz e
se eles foram computados corretamente, e não nos últimos valores que vários
subscritos tiveram. Mas em alguns casos, dados computados não centrais para a intenção do programa podem encontrar um uso em outro programa se sua
condição for conhecida.
Essa imagem de programas que operam em dados, sejam de interesse
central ou não, surge naturalmente da visualização de dados conforme ocorrem no armazenamento
da máquina. É bem sabido que esse uso de dados é uma das principais
armadilhas para fazer sistemas cada vez maiores de programas funcionarem. É a
questão dos efeitos colaterais, onde alguns dados não imediatamente visíveis em uma
interface de programa são alterados ou usados.
A ideia de uma função matemática permite que se seja preciso sobre
o efeito intencional de programas em dados. Por exemplo, no caso de array
seus elementos podem ser mapeados em novos elementos usando uma descrição funcional.
Nada é dito sobre subscritos ou mesmo se subscritos são usados ​​no
computação de seus elementos. Nesta forma, qualquer outra pessoa é avisada de que
quaisquer suposições sobre subscritos são feitas por sua própria conta e risco e são
provavelmente falsas.
Um primeiro encontro típico com a ideia de uma função é aquele que
relaciona duas variáveis, digamos, uma função f que relaciona y a x na forma
y=f(x),
onde

Para nossos propósitos em lidar com objetos combinatórios finitos, mas complexos
outra definição de uma função, como um conjunto de pares ordenados, é mais útil.
Por exemplo, podemos escrever (x, y) E f em vez de y = f(x) para enfatizar
o aspecto do conjunto. Como uma função é um conjunto, as operações comuns de conjunto se aplicam
a funções. A expressão x2 + 3x + 2 é parte de uma regra que define
quais pares ordenados pertencem a f; na verdade, é apenas uma das muitas
regras possíveis. Na programação, a especificação funcional corresponde à função,
e o programa corresponde à regra.
Para o exemplo acima, podemos usar a notação de conjunto para descrever f como
f= {(x,y) I y=x2 + 3x+2}.
As variáveis ​​x e y são variáveis ​​fictícias, pois
g = { (u, v) I v = u2 + 3u + 2}
ou
h={(u,v) I v=(u+l) (u+2)}
são ambos conjuntos idênticos a f. Neste contexto, vemos que as três regras correspondem
a três programas diferentes (operações diferentes e variáveis ​​diferentes)
que realizam a mesma especificação funcional.

Você pode escrever programas com lógica de função correta usando princípios de
programação estruturada e correção de programa que são aplicados em sua
construção de programa linha por linha. A tarefa do programador começa com
uma especificação funcional que descreve o que o programa a ser deve fazer.
No processo tradicional, o programador de alguma forma converte essa especificação
em instruções de programa e então verifica se as instruções criadas
de fato fazem o que o programa foi criado para fazer. Na programação estruturada
há uma descrição precisa dos resultados dessa atividade mental. Ela começa
com a especificação funcional e a divide repetidamente, um passo de cada vez,
em novas subespecificações funcionais, conectadas por instruções de programa,
até que o programa esteja completo. Ela não consiste em um grande salto de fé
e esperança de uma especificação funcional para uma coleção solta de instruções de
programa que são encaixadas peça por peça em um programa. O processo de
programação estruturada analisa especificações funcionais em vez de sintetizar
instruções de programa. Uma breve maneira de entender a programação estruturada
e como provar a correção de programas escritos
desta forma é a seguinte.
a. Qualquer especificação funcional pode ser definida em termos de uma função matemática
que mapeia entradas em saídas sem considerar sua construção
interna. Mostramos tal função (especificação funcional) como
-----i•~l função I •
b. Qualquer programa de fluxograma realiza uma função que pode ser
expressa pelo uso repetido de apenas três figuras básicas de programa
mostradas na Figura 16-1.
Cada IF-THEN-ELSE, SEQUENCE e DO-WHILE no lado esquerdo
é uma função realizada de uma nova maneira no lado direito. Cada
parte THEN, ..., parte DO no lado direito é apenas uma nova função
e pode ser substituída por outra figura IF-THEN-ELSE, SEQUENCE ou DOWHILE
em uma etapa de expansão subsequente.
O processo de programação estruturada procede de uma especificação funcional
original como uma série de decisões de design que especificam qual
figura e quais novos testes e funções resultantes são necessários para expandir
a função original e quaisquer funções intermediárias necessárias. Quando as funções
necessárias podem ser escritas diretamente como instruções de programa, o processo de expansão
está concluído.
Em uma linguagem como PL/I, essas expressões podem ser escritas diretamente em instruções correspondentes, sem rótulos ou GO TO's para resultar finalmente
em um programa GO TO-free. Esse programa GO TO-free pode ser lido sequencialmente,
sem pular de um lado para o outro. A relação entre o texto do programa
e a execução, portanto, se torna especialmente clara.
c. Em cada etapa de expansão, a correção dessa etapa pode ser
decidida respondendo a uma pergunta padrão que acompanha esse tipo de expansão.
Se a resposta for sim, a etapa está correta e a expansão do programa
pode prosseguir. Se a resposta for não, a etapa não está correta e uma nova
deve ser definida imediatamente. As perguntas são:
1. IF-THEN-ELSE: Sempre que o teste IF for verdadeiro, a parte THEN
faz o IF-THEN-ELSE e, sempre que o teste IF for falso, a parte
ELSE faz o IF-THEN-ELSE?
2. SEQUÊNCIA: A primeira parte seguida pela segunda parte faz a
sequência?
3. DO-WHILE: (a) A terminação é garantida? (b) Sempre que o teste
WHILE for verdadeiro, a parte DO seguida pelo DO-WHILE
faz o DO-WHILE, e sempre que o teste WHILE for falso,
a função de identidade (programa sem operação) faz o DO-WHILE?
As perguntas para as expansões IF-THEN-ELSE e SEQUENCE
são autoevidentes. A pergunta para o DO-WHILE se torna autoevidente
observando esta sequência de expansões equivalentes: Expanda a execução
do DO-WHILE em um IF-THEN (sem parte ELSE) e então
observe que o DO-WHILE reaparece como a segunda parte da sequência
compondo a parte THEN (veja a Figura 16-2).
d. Quando as etapas b e c são realizadas até o ponto em que nenhuma
subespecificação permanece, o resultado é um programa completo, e a prova
de sua correção também foi concluída.
Algumas ilustrações de etapas individuais com suas questões de correção são:
1. IF-THEN-ELSE: z = max(x, y)
x,y

Sempre que x 2 y faz z = x faz z = max(x, y) e sempre que x < y
faz z = y faz z = max(x, y)?
2. SEQUÊNCIA: z = max(x, abs(y))
x,y •I' -__w _=_ab_s_(Y _) _ __, X, w ·,.I..L . . _z =_ m_ax(_x, _w) _. ..t. ----l'-~ z
Faz w = abs(y) seguido por z = max(x, w), faz z = max(x,
abs(y) )?
3. DO-WHILE: remove zeros à esquerda (de um inteiro decimal positivo)
(a) A terminação é garantida? (b) Sempre que houver um zero à esquerda,
remover dígito à esquerda seguido por remover zeros à esquerda remove
zeros à esquerda; e sempre que não houver zero à esquerda,
não fazer nada remove zeros à esquerda?
A doença dos erros de sintaxe
O problema de escrever lógica de programa correta é mais difícil do que
escrever sintaxe correta, e a maior parte deste artigo é sobre o último problema.
Nossa preocupação com a sintaxe correta é identificar uma atitude de precisão
que será transferida com bom efeito para o problema da lógica
do programa. Na verdade, essa ênfase na sintaxe é baseada na experiência reversa
de que quando os programadores acertam a lógica do programa desde o início, a atitude
de precisão é transferida de volta para a codificação, e eles começam a obter a sintaxe do programa
desde o início, sem nenhum esforço especial.
Com o advento dos compiladores e outros recursos de depuração, tem sido
fácil adotar uma atitude de "deixe o compilador fazer" ao encontrar erros de
sintaxe. Mas a longo prazo, essa é uma atitude devastadora porque fomenta
ignorância e descuido que deslizam para a lógica do programa que o compilador
não consegue descobrir.
Se sua programação é uma vocação e não uma vocação, não
há razão para você encarar erros de sintaxe levianamente ao escrever um programa.
Erros de sintaxe são erros de ignorância ou descuido. Se forem
erros de ignorância, você precisa fazer mais lição de casa sobre a sintaxe de
suas linguagens de programação. Se forem erros de descuido, você precisa
aprender a se concentrar e levar o que está fazendo mais a sério.
Escrever sintaxe correta é como jogar um jogo da velha perfeito,
não como serrar um tabuleiro exatamente ao meio, o que requer precisão perfeita.
É um processo combinatório que requer apenas um grau fixo e humanamente possível
de precisão para correção. Por exemplo, uma expressão complicada
pode terminar com cinco (ou seis) parênteses; mas nunca terminará
com 5,37521 . . . parênteses. A diferença entre cinco e seis é distinguível
na escrita e na leitura, e se deve ser cinco ou seis
depende apenas de caracteres anteriores de tipos discretos e localizações na
expressão.
Escrevendo algumas pesquisas

Para ver esses princípios em ação, considere o problema de procurar
por um item chamado KEY em uma lista chamada TABLE, com um total de N elementos, denotados TABLE (1), ..., T ABLE(N), respectivamente; devemos
exibir os resultados da pesquisa em um item chamado I, que deve satisfazer
a relação
TABLE(I) =KEY, se possível
I = 0, caso contrário.
Observe que definimos uma função em palavras. O argumento é N + 2
itens, a saber N, TABLE(l), ..., TABLE(N), KEY, e o valor é I,
conforme diagramado
N, TABLE(l), ..., T ABLE(I) = KEY,
------l~ se possível 1----_..
TABLE(N), KEY I = 0, caso contrário
É fácil inventar um programa, digamos em PL/I, para esta função.
SEARCHl :PROCEDURE;
I= 0;
DO 1 = 1 TON;
IF TABLE(J) =KEY THEN
I= J;
END;
END SEARCH!;
Não é um programa eficiente, com certeza, mas parece estar correto. Por quê?
Primeiro, é uma sequência de dois subprogramas cujas funções são
1. primeira parte: definir I como zero.
2. segunda parte: encontrar, se possível, um valor para I para o qual T ABLE(I) =
KEY; caso contrário, deixar I inalterado.
A questão da sequência acima pergunta se a primeira parte seguida pela segunda
parte faz a sequência. Acredita-se que sim. Em seguida, a segunda parte acima é
em si um loop, mas não uma figura DO-WHILE. Em vez disso, é o conhecido
loop indexado, que chamaremos de loop DO para abreviar. Vale a pena nossa atenção
como uma conveniência extra além das três figuras básicas fornecidas acima,
sob um ponto extra de disciplina. Essa disciplina extra é que o índice
do loop DO não é alterado de forma alguma pela parte DO do loop DO.
Então o loop DO se torna uma sequência estendida, com uma primeira parte, uma segunda
parte, ..., enésima parte. A questão de correção correspondente é uma extensão simples
da questão de sequência também. A parte DO neste caso é
parte DO: se TABLE(J) =KEY então defina I para J;
caso contrário, deixe I inalterado
e é fácil ver que a sequência de tais partes DO, para J = 1, ..., N
realmente faz o loop DO (segunda parte acima). Finalmente, a parte DO é
em si uma figura IF-THEN (IF-THEN-ELSE com ELSE nulo), e é fácil
ver que ela satisfaz seu requisito funcional.
Em resumo, articulamos uma análise que um programador faz
de relance para ilustrar os blocos de construção de um observador habilidoso. Neste
caso, eles são estruturados em uma árvore do formato mostrado na Figura 16-3.
Cada nó define uma subfunção e um subprograma simultaneamente. Um
pianista habilidoso aprendeu a tocar escalas e arpejos com pouca atenção
às notas individuais, e um programador habilidoso também aprende a juntar pequenas
combinações de declarações quase da mesma maneira. Mesmo assim,
as perguntas básicas são válidas e precisam ser consideradas explicitamente. Se as
respostas forem óbvias, não levarão muito tempo para serem verificadas; se não forem óbvias,
elas valem a pena serem investigadas.

É fácil ver como melhorar SEARCHl para SEARCH2 da seguinte forma:
SEARCH2: PROCEDURE;
I = 0;
DO J = 1 TON WHILE(I = 0);
IF TABLE(J) = KEY THEN
I = J;
END;
END SEARCH2;
Enquanto SEARCHl olhou para cada item em TABLE, seja bem-sucedido
ou não no meio do caminho, SEARCH2 tem senso suficiente para parar de olhar para
o primeiro sucesso em TABLE. A única mudança em SEARCH2 é a cláusula WHILE. O efeito é um loop DO com uma terminação condicional, que pode
ser reescrito como:
J = 1;
DO WHILE(J <= N & I = 0);
END;
IF TABLE(J) = KEY THEN
I = J;
J = J + 1;
Isto é, o loop DO WHILE se torna uma sequência de uma primeira parte para inicialização
e segunda parte de DO-WHILE, cuja parte DO inclui incrementar
o índice. Nesta forma, a questão DO-WHILE se aplica; ela pergunta:
sempre que J s N e I = 0, a parte DO
seguida por DO-WHILE (com J = J + 1
agora) faz o DO-WHILE; e sempre que J > N
ou I 7':- 0, não fazer nada faz o DO-WHILE?
Podemos ver que sim. Se KEY ainda não foi encontrado em TABLE,
e não olhamos para cada item, então podemos olhar para o próximo item
e definir I, J adequadamente e ainda concluir a tarefa necessária do DOWHILE.
Olhando de volta para a ideia funcional em programação discutida
anteriormente, observe também que o SEARCH2 aprimorado deixa um valor imprevisível
para J, enquanto SEARCH! deixou J = N + 1 sempre. Se um programador
tomasse o programa, em vez da especificação funcional, como definitivo,
poderia haver problemas dependendo de um valor para J.

Se os elementos de TABLE forem classificados (digamos, em ordem crescente), então uma
pesquisa possivelmente mais eficiente pode ser definida como uma pesquisa binária. Ao examinar
um elemento próximo ao meio da tabela, encontramos KEY ou
sabemos então que KEY deve ser encontrada apenas em uma metade ou na outra
da tabela restante. Essa etapa básica pode ser repetida na metade indicada
e continuada até que uma tabela de apenas um elemento seja alcançada. Se KEY não for
encontrada por essa etapa, ela não existe na tabela. Colocamos o precedente
em um programa, como segue, introduzindo as variáveis ​​LO e HI, que
definem o subscrito inferior e superior da tabela que está sendo pesquisada em cada
etapa.
SEARCH3: PROCEDURE;
I= 0;
LO= 1;
HI=N;
DO WHILE(LO <=HI & I= 0);
J = (LO + HI)/2;
IF TABLE (J) = KEY THEN
I= J;
ELSE
END;
FIM DA PESQUISA3;
SE TABELA (J) < CHAVE ENTÃO
LO = J + 1;
SENÃO
HI=J-1;
A árvore de perguntas sobre PESQUISA3 é dada pela Figura 16-4. Há
cinco nós não terminais nesta árvore, correspondendo a duas sequências,
um DO-WHILE e dois IF-THEN-ELSE's. (Observe que consideramos uma
sequência de atribuições como simplesmente uma atribuição generalizada para nossos
propósitos aqui.) Cada nó define uma função que, por sua vez, serve como um
componente na próxima função.
A função para PESQUISA3 é a mesma que a já declarada,
ou seja, dado N, TABELA (I), ..., TABELA(N), CHAVE, encontre I que satisfaça
a relação
TABELA(I) =CHAVE, se possível, I= 0, caso contrário.


Para ver que o DO-WHILE é realizado por este
teste WHILE e esta parte DO, duas considerações principais são necessárias.
Primeiro, fazer a parte DO uma vez sem encontrar KEY não pode impedir o
DO-WHILE encontrar KEY se for possível; segundo, fazer a parte DO
suficientemente muitas vezes (finitamente) garante a falha final do
teste WHILE. Para a primeira consideração, a suposição de uma
TABLE ordenada deve ser invocada, com a verificação de que cada falha em encontrar
KEY na TABLE garante que KEY não será encontrada acima ou abaixo
desse ponto, conforme o caso. Para a segunda consideração, é suficiente
considerar a diferença algébrica HI ​​- LO e observar que quando I
permanece 0 (caso contrário, o teste WHILE é falso), então LO ou HI
é alterado para que
(HI- LO)arter < (HI- LOherore -1,
de modo que eventualmente,
HI- LO < 0,
e o teste WHILE falhará.
Não elaboraremos os argumentos para os dois IF-THEN-ELSE's.
Mas observe que suas funções são definidas pelos argumentos precedentes para
o DO-WHILE. Observe também a diferença essencial no argumento para um
DO-WHILE e para um loop DO indexado.

Para se aprofundar
Em programação estruturada
O primeiro nome em programação estruturada é Edsger W. Dijkstra, que cedo
reconheceu o problema da complexidade no processo de programação e
identificou a necessidade de disciplina mental em abstrações funcionais e
lógica de controle. Em uma carta famosa, "Declaração GOTO considerada prejudicial"
[7], Dijkstra desencadeou uma controvérsia que abalou a ciência da computação. No
capítulo "Notas sobre programação estruturada" de Programação estruturada
[5], ele deu a motivação e o método para programação estruturada
como um processo sistemático de dividir e conquistar por abstração e refinamento.
A primeira prova de que programas estruturados eram suficientemente poderosos
para representar qualquer lógica de programa de fluxograma foi devida a Giuseppe Jacopini
no artigo "Diagramas de fluxo, máquinas de Turing e linguagens com apenas duas regras de formação" [4], em coautoria com Corrado Bohm. Como Dijkstra aponta [7], a conversão irracional de fluxogramas gerais em programas estruturados não é recomendada, mas Jacopini mostra que você pode projetar programas estruturados para quaisquer requisitos lógicos para começar.

A correção de programas estruturados recebe um tratamento elegante
por C. A. R. Hoare em "An Axiomatic Approach to Computer Programming"
[12], que introduziu uma nova abordagem sistemática para provar
programas estruturados corretos. Esta abordagem é ilustrada por N. Wirth em
Systematic Programming: An Introduction [22] e por J. R. Kelley e
C. L. McGowan em Top-Down Structured Programming [14]. A abordagem
de Hoare et al. é um pouco diferente para loops do que a abordagem que
demos acima. Ela deriva de ideias de Naur [19] e Floyd [11], que abordam
a iteração do loop diretamente por meio da descoberta de uma condição invariante, que é satisfeita em cada iteração e pode ser usada para deduzir
a condição de saída do loop. Em contraste, a abordagem que demos acima ~converte
uma iteração em uma recursão, após ideias que remontam a McCarthy em "A
Basis for a Mathematical Theory of Computation" [16].
A expansão gradual de especificações em programas estruturados
foi discutida anteriormente por Dijkstra em "A Constructive Approach to the Problem
of Program Correctness" [8], por Wirth em "Program Development by
Stepwise Refinement" [21], e por Mills em "Top Down Programming in
Large Systems" [17].
Em Programming Practices
Uma aplicação importante da programação estruturada (em conjunto com certas
técnicas organizacionais) é descrita por F. T. Baker em "Chief
Programmer Team Management of Production Programming" [2] e em
"System Quality Through Structured Programming" [3]. Baker relata um
aumento substancial na produtividade e uma diminuição ainda mais notável
na incidência de erros sobre as normas da indústria no desenvolvimento de um grande sistema de informação
conversacional.
Em uma edição especial sobre programação do ACM Computing Surveys
[11, editado por P. J. Denning, os autores P. J. Brown, J. M. Yohe, N.
Wirth, D. E. Knuth e B. W. Kernihan e P. J. Plouger discutem vários
aspectos da prática de programação. Dijkstra dá insights especiais sobre
boas práticas mentais em programação em um artigo anterior, "Programming
Considered as a Human Activity" [6], e um posterior, "The Humble
Programmer" [9].
A abordagem de refinamento gradual para o desenvolvimento de programas pode
ser identificada como uma metodologia de design de sistema também, conforme discutido em um
artigo anterior de F. Zurcher e B. Randell, "Iterative Multi-Level Modelling
- A Methodology for Computer System Design" [23]. Em "Uma Metodologia de Design para Sistemas de Software Confiáveis" [15], B. H. Liskov combina princípios de programação estruturada e correção de programa em uma abordagem sistemática ao desenvolvimento de software.

Em Matemática
Dizem que a guerra é importante demais para ser deixada para os generais, e por isso
o pensamento claro na programação é importante demais para ser deixado para os matemáticos.
Dijkstra, em "Programação como Disciplina de Natureza Matemática" [10], expressa muito bem as necessidades e oportunidades para incorporar
pensamento matemático na programação. Mills, em "A Nova
Matemática da Programação de Computadores" [18], discute programação estruturada
e por que ela funciona em termos algébricos. W. Huggins observou [13] que
"a álgebra é a ferramenta natural para estudar coisas feitas pelo homem, e a análise é
a ferramenta natural para estudar coisas feitas por Deus". Essa observação apropriada parece
se aplicar a programas feitos pelo homem, de fato.
R. L. Wilder, em Evolution of Mathematical Concepts-An Elementary
Study [20], aponta (pp. 196f) que "parece ser um fenômeno universal
na evolução da cultura, que quando uma cultura evoluiu
suficientemente para atingir um certo grau de maturidade, surge então uma necessidade
entre seus participantes de uma 'explicação' de sua origem ... a subcultura matemática da cultura ocidental moderna não forneceu nenhuma exceção ...
a fé na 'verdade' das teorias matemáticas que foi sustentada na cultura geral é compartilhada em grande medida pela subcultura matemática". O professor Wilder então conclui que a matemática
continuará a evoluir assim como qualquer outra atividade humana - com base em
seu valor para a condição humana.
Agradecimento
É um prazer reconhecer as discussões estimulantes em "Como escrever
programas corretos e conhecê-los" na teoria e na prática com R. C. Linger.

A nova matemática da programação de computadores

Resumo
A programação estruturada provou ser uma metodologia importante
para o design e desenvolvimento sistemático de programas. Programas estruturados
são identificados como expressões de funções compostas na álgebra de funções.
As propriedades algébricas dessas expressões de funções permitem
a reformulação (expansão e redução) de uma subexpressão aninhada
independentemente de seu ambiente, modelando assim o que é
conhecido como refinamento de programa passo a passo, bem como execução de programa.
Finalmente, a programação estruturada é caracterizada em termos da seleção
e solução de certas equações elementares definidas na álgebra
de funções. Essas soluções podem ser dadas em fórmulas gerais, cada uma envolvendo
um único parâmetro, que exibem toda a liberdade disponível
na criação de programas estruturados corretos.
Palavras-chave e frases
programação estruturada
álgebra de funções
refinamento gradual
correção do programa
CR (ACM Computing Reviews) Categorias: 4.6, 5.21, 5.24
Em homenagem a Alston S. Householder

A programação de computadores como uma atividade humana prática tem cerca de 25 anos
de idade, um curto período para o desenvolvimento intelectual. No entanto, a programação de computadores
já apresentou o maior desafio intelectual que a humanidade
enfrentou em lógica pura e complexidade. Nunca antes o homem teve os
serviços de tais servos lógicos, tão notáveis ​​em poder, mas tão desprovidos
de senso comum que as instruções dadas a eles devem ser perfeitas e
devem cobrir todas as contingências, pois são realizadas mais rápido do que a
mente pode acompanhar.
O computador eletrônico prático foi a invenção de algumas das
nossas melhores mentes em matemática e engenharia [7], por exemplo, von Neumann,
Goldstine, Burks, Bigelow, Williams, Eckert, Mauchly, Atanasoff, Pomerene.
Muitas pessoas das melhores universidades e laboratórios do mundo
entraram em seu desenvolvimento cedo, tanto em design de hardware quanto em programação,
por exemplo, Wilkes [17], Forrester, Alexander, Forsythe, Rutishauser,
Hopper. No início, a ênfase estava na computação numérica,
e uma nova matemática para análise numérica surgiu, liderada pelos
estudos clássicos de von Neumann e Goldstine [16], Householder [10],
Wilkinson [18], Henrici [8], et a!. Mais tarde, uma ênfase adicional se desenvolveu
na computação simbólica, e outra nova matemática para análise simbólica
surgiu, liderada por McCarthy [13], Newell e Simon [15],
Minsky [14], et a!. A marca registrada da computação numérica é a iteração
e a análise real, e o principal problema conceitual é a aproximação
de algoritmos iterativos para os reais em números de ponto flutuante. A marca registrada
da computação simbólica é a recursão e a análise combinatória,
e o principal problema conceitual é a representação de objetos complexos
em estruturas de dados recursivas flexíveis.
O exposto acima exigiu programação computacional de processos matemáticos. Mas é apenas recentemente que uma nova matemática da própria programação de computadores começou a emergir, nos trabalhos de Dijkstra [6], Hoare
[9], Wirth [19], et al. Neste caso, a matemática modela os processos mentais
de programação - de inventar algoritmos adequados para um determinado
computador para atender às especificações lógicas prescritas. Bauer [2], Dijkstra [5],
e Knuth [11] resumiram muito deste desenvolvimento e suas características únicas sob o termo programação estruturada.

Uma Perspectiva Matemática
Discutimos a programação estruturada em forma matemática para ilustrar a
relevância e o poder dos conceitos matemáticos clássicos para simplificar e descrever objetos e processos de programação. É matemática aplicada
na tradição clássica, fornecendo maior capacidade humana por meio de abstração,
análise e interpretação em aplicação à programação de computadores.
Nosso principal objetivo é modelar o processo mental da
programação estruturada com a seleção e solução de certas equações de função
que surgem como uma abstração natural de processos de programação concretos.
Antes que essas equações de função possam ser abstraídas, no entanto, precisamos
desenvolver a ideia de programação estruturada e o corolário de que programas estruturados
podem ser vistos como expressões de função composta na
álgebra de funções. São as propriedades algébricas da programação estruturada
que fornecem seu poder prático - no aninhamento natural de expressões algébricas - e a capacidade de considerar uma expressão aninhada independentemente
de seu ambiente em uma expressão composta.
A título de ilustração, todos nós podemos lembrar das aulas de matemática elementar
que o problema não era simplesmente obter a resposta certa, mas encontrar
o processo certo para obter a resposta. Frequentemente, recebíamos apenas parte do crédito
por uma resposta correta porque não mostrávamos como a obtivemos. Havia
uma razão. Se resolvermos problemas matemáticos simples adivinhando as respostas,
então quando chegarmos aos problemas mais difíceis não seremos capazes de adivinhar as
respostas. Esse é exatamente o papel da nova matemática na programação de computadores -
ir da programação como um processo instintivo e intuitivo para um
processo mais sistemático e construtivo que pode ser ensinado e compartilhado por
pessoas inteligentes em uma atividade profissional.

Programação Estruturada
Teoremas de Fluxograma
Fluxogramas são regras gráficas para definir funções de estado complexas1 em
termos de funções de estado mais simples conhecidas por um dispositivo de computação. Mais precisamente,
seja X um conjunto finito de estados possíveis de uma computação; um fluxograma
é um gráfico orientado e direcionado com três tipos de nós (veja a Figura 17-1).
Um nó de função é rotulado com uma função de estado finito, digamos,
f c X x X. Um nó de predicado é rotulado com um predicado de estado finito, digamos,
p c X x {T, F}, e direciona o controle para uma das duas linhas externas do nó. Um nó de coleta não é rotulado e apenas passa o controle das
duas linhas internas para a linha externa.
Diferentes fluxogramas podem definir os mesmos cálculos e as mesmas
funções; por exemplo, os formulários na Figura 17-2 definem cálculos idênticos.
Diferentes fluxogramas podem definir cálculos diferentes, mas a mesma
função (veja, por exemplo, a Figura 17-3).
Assim, vários níveis de equivalência de fluxograma podem ser definidos, que
preservam cálculos, funções, etc. Em particular, Bohm e Jacopini [3],
Cooper [4] e outros estudaram o poder expressivo de várias classes
de fluxogramas na definição de cálculos e funções. O principal resultado
desses estudos é que classes relativamente pequenas e econômicas de fluxogramas
podem definir os cálculos e funções da classe de todos os fluxogramas,
possivelmente às custas de cálculos extras fora da descrição original
do conjunto de estados.

O exposto acima motiva um tratamento mais formal, como segue. Defina
uma classe de D-gráficos (D para Dijkstra [5]) sobre um conjunto de funções de estado
F = {fb ... , f,,} e um conjunto de predicados de estado P = {p1, ... , Pn} como segue:

Um Teorema de Estrutura. Considere qualquer fluxograma cujas funções formam um se! F
e predicados formam um conjunto P. Aumente os conjuntos F e P com funções e
predicados que definem e testam variáveis ​​fora do conjunto de estados do
fluxograma fornecido. Então existe um D-ehart nos conjuntos aumentados que simula
os cálculos do fluxograma fornecido.
Na ilustração, seguindo Cooper [4], considere qualquer fluxograma dado,
e rotule cada uma de suas linhas de forma única. Então o fluxograma na Figura 17-4,
usando uma nova variável L (para rótulo), simulará os cálculos do
fluxograma original.

A operação dentro do loop pode ser expandida em um D-ehart sem loop de testes em L, levando aos vários nós do fluxograma original,
como um conjunto de alternâncias aninhadas. Em resumo, este fluxograma mostra que,
às custas de definir e testar uma única variável L (fora do
conjunto de estados original), os cálculos de qualquer fluxograma podem ser
simulados como uma subsequência dos cálculos de um D-ehart com um único
loop.
Bohm e Jacopini [3], Ashcroft e Manna [1 ], e Kosaraju
[12] têm resultados mais nítidos, que preservam mais da estrutura do
fluxograma original. Bohm e Jacopini preservam os loops do fluxograma original
com uma simulação mais eficiente de seus cálculos. Kosaraju
encontrou uma hierarquia de capacidades expressivas entre várias classes de
fluxogramas. Em particular, Kosaraju descobriu as condições precisas
sob as quais um D-ehart pode simular um fluxograma dado sem aumentar
suas funções e predicados.
Teorema (Kosaraju [12]). Considere qualquer fluxograma A cujas funções formam
o conjunto F, e cujos predicados formam o conjunto P. Então, existe um D-ehart sobre
F e P que preserva os cálculos do fluxograma A dado se e
somente se cada loop de A tem uma única linha de saída.

A operação dentro do loop pode ser expandida em um D-ehart sem loop de testes em L, levando aos vários nós do fluxograma original,
como um conjunto de alternâncias aninhadas. Em resumo, este fluxograma mostra que,
às custas de definir e testar uma única variável L (fora do
conjunto de estados original), os cálculos de qualquer fluxograma podem ser
simulados como uma subsequência dos cálculos de um D-ehart com um único
loop.
Bohm e Jacopini [3], Ashcroft e Manna [1 ], e Kosaraju
[12] têm resultados mais nítidos, que preservam mais da estrutura do
fluxograma original. Bohm e Jacopini preservam os loops do fluxograma original
com uma simulação mais eficiente de seus cálculos. Kosaraju
encontrou uma hierarquia de capacidades expressivas entre várias classes de
fluxogramas. Em particular, Kosaraju descobriu as condições precisas
sob as quais um D-ehart pode simular um fluxograma dado sem aumentar
suas funções e predicados.
Teorema (Kosaraju [12]). Considere qualquer fluxograma A cujas funções formam
conjunto F, e cujos predicados formam o conjunto P. Então, existe um D-ehart sobre
F e P que preserva os cálculos do fluxograma dado A se e
somente se cada loop de A tem uma única linha de saída.

Expressões de função
A álgebra de funções herda expressões de função da álgebra de
conjuntos, por exemplo, se g, h são funções, então também o são g n h (intersecção de conjuntos) e
g - h (diferença de conjuntos); é claro que g U h pode ou não ser uma função, mas
será uma relação em qualquer caso.
Programas básicos de fluxograma de uso comum, como os definidos para
D-charts, são convenientemente representados como expressões de função adicionais,
por exemplo, onde
(1)
escreva
----~·~l ___ g_;_h _ ~~--~·~
g ;h= {(x,z) J (3:y)(y=g(x) A z=h(y))}
(observe que o operador ; inverte os operandos do operador de composição de função comum *, por exemplo, g ; h = h * g).
A expressão de iteração é definida por recursão em termos de semi-alternação
e composição.
Como consequência dessas definições, qualquer D-ehart pode ser representado
como uma expressão de função composta, e os cálculos de qualquer
fluxograma podem ser simulados por tal expressão.
Tipos de expressão adicionais podem ser úteis e eficientes para certos
processadores, por exemplo, defina
( 5) DO g UNTIL p OD = g ; WHILE - p DO g OD,
(6) CASE k OF g1, g~, . . . , gn FO = IF k = 1 THEN gl ELSE
IF k = 2 THEN g2 ELSE
IF k = n THEN gn FI ... FI Fl.
Definimos um programa estruturado para ser uma expressão de função composta em
qualquer conjunto prescrito de tipos de expressão. Os D-charts são programas estruturados
no conjunto de tipos {composição, alternância, iteração} conforme definido
acima.
Refinamento de função passo a passo
As propriedades poderosas da programação estruturada estão enraizadas, finalmente, em
propriedades algébricas de expressões de função; por exemplo, expressões aritméticas,2
expressões lógicas, etc., permitem sua avaliação, manipulação, etc., um passo
de cada vez em subexpressões mais internas, independentemente de seu ambiente externo.
Adicionamos 2 + 4 da mesma forma, quer depois multipliquemos o resultado por
9 ou o dividamos por 3, em 9 * (2+ 4) ou (2 + 4)/3. Alternativamente, um número
como 6 pode ser expandido como ( 2 + 4), se útil, ou ( 2 * 3), independentemente
das operações sendo realizadas nele. Da mesma forma, expressões de função podem
ser formuladas e contempladas independentemente de seus ambientes em
expressões de função composta mais complexas.
Conforme observado por Dijkstra [6], Wirth [19], et al., o processo mental criativo e iterativo da programação estruturada é o refinamento gradual de uma
função em uma expressão em funções intermediárias, até que as funções disponíveis no computador em questão sejam alcançadas. Assim, não apenas a expressão final
está envolvida, mas também as etapas mentais intermediárias para alcançá-la
são registradas. Por exemplo, a sequência de fluxogramas rotulados como 1 e 2 em

A diferença é crítica, porque a sequência 2 contém uma
descontinuidade mental (duas, na verdade), que requer processamento mental adicional
fora da sequência. Na sequência 1, cada um dos três membros são expressões compostas
equivalentes, ou seja,
f= (g;h) = (g;WHILEpDOkOD)
Mas na sequência 2, o primeiro e o terceiro membros são equivalentes, como acima,
mas o membro do meio é diferente de qualquer um dos outros. Assim, de
f na sequência 2, por algum insight não registrado, a função chamada h na sequência
1 é definida como uma iteração. Esta expressão não é igual a nenhum outro objeto
na sequência 2 e requer esse insight não registrado para validação. Então,
por fim, esta expressão é corrigida colocando g na frente dela, ainda precisando
desse insight não registrado para acertar g. Quando tais funções se tornam complexas,

e muitos desses insights não registrados precisam existir ao longo de dias, semanas e
meses, não é de se admirar que a programação possa ser complexa e frustrante.
A Correção das Expressões de Função
A verificação da correção das expressões de função pode prosseguir com
refinamento gradual. Na verdade, elas são melhor praticadas em conjunto do que separadamente
e sequencialmente. Cada estágio no refinamento gradual identifica uma
expressão composta em funções intermediárias, cada uma das quais pode ser expressa posteriormente
em outras funções. Essas funções intermediárias são críticas na validação
da correção. Elas desempenham dois papéis - primeiro, como funções em expressões sendo
validadas e, segundo, como funções pelas quais suas expressões de substituição
são validadas.
Durante o refinamento gradual, um procedimento de validação padrão pode
ser definido para cada tipo de expressão. Esses procedimentos declaram o que deve ser
provado - a descrição da função determina como tal prova deve ser
realizada em detalhes.
Teorema (Correção). A Correção de uma Expressão de Alternância. Para
provar f = IF p THEN g ELSE h FI é necessário e suficiente
mostrar, para todo (x, y) E f, que p(x) = T andy= g(x) ou p(x)
=Fandy=h(x).
A Correção de uma Expressão de Composição. Para provar f =
g ; h é necessário e suficiente mostrar, para todo (x, y) E f, que y
=h(g(x)).
A Correção de uma Expressão de Iteração. Para provar f =
WHILE p DO g OD é necessário e suficiente mostrar, para todo
(x, y) E f, que a iteração termina e que p(x) = T andy=
f(g(x)) ou p(x) = F andy= x.
A prova deste teorema segue diretamente das definições de
(1 ) , ( 2) , ( 3 ) e ( 4) .
Equações de Função e Suas Soluções
O Problema de Computação e o Problema de Programação
No refinamento gradual, membros de um conjunto finito de equações de função prescritas
surgem, um para cada tipo de expressão, das formas
(7) f =IF p THEN g ELSE h FI (alternância)
226 PRODUTIVIDADE DE SOFTWARE
(8) f = g;h
(9) f=WHILEpDOgOD
etc.
(composição)
(iteração)
Quando p, g, h são tomados como funções independentes, e f como a
função dependente (desconhecida), essas equações representam o
problema de computação; ou seja, dada uma expressão de função composta, o problema é
avaliá-la por avaliações passo a passo de expressões mais internas.
No entanto, o problema de programação começa com uma função a ser
expressa, com f como a função independente, e p, g e h como as funções dependentes
(desconhecidas). Isso motiva o estudo dessas equações de função prescritas, com f dado, para caracterizar as soluções em p, g, h.
Com uma pequena análise, podemos escrever as soluções diretamente e exibir,
assim, toda a liberdade de um programador em um refinamento passo a passo correto.
A equação de alternância
A solução geral mínima para a equação de alternância pode ser dada em
termos de um único parâmetro, qualquer subfunção (subconjunto) de f, digamos u. Então
(p, g, h) resolve a equação de alternância (7), onde3
(10) g = u,
h = f- u,
p = (D(u) X {T}) U (D(f - u) X {F}).
Observe que {g, h} é uma partição de f.
A equação de composição
A solução geral mínima para a equação de composição pode ser dada
em termos de um único parâmetro, qualquer função, digamos, u, com domínio D(f)

cujos conjuntos de nível4 refinam os conjuntos de nível; ou seja, cada conjunto de nível de u é um subconjunto
de algum conjunto de nível de f. Então (g, h) resolve a equação de composição (8), onde5
(11)
g = u,
h=u- 1 ;/onde (u - 1 = {(x,y) I (y,x) E u})
Assim, enquanto o conjunto de solução da equação de alternância tem precisamente
a liberdade de uma partição binária da função f, o conjunto de solução da
equação de composição tem a liberdade de qualquer sistema de partições nos
conjuntos de nível de f, uma escolha muito mais rica.
A equação de iteração
A equação de iteração é mais complexa e interessante do que as equações de alternância
e composição. Primeiro, enquanto qualquer função pode ser expressa
em uma alternância ou composição, isso não é verdade para uma expressão de iteração; acontece que uma condição de existência é necessária para uma solução.
Segundo, enquanto todas as funções p, g, h variam sobre o conjunto de soluções nas
equações de alternância e composição, verifica-se que apenas a função
g varia sobre o conjunto de soluções na equação de iteração; isto é, o predicado
p é fixado inteiramente por f sozinho. Em outras palavras, p é uma derivada de f, assim como
a inclinação de uma função diferenciável é uma derivada dessa função. Chamamos
p de derivada de iteração de f.
Considere a equação de iteração, dado f, para encontrar (p, g) tal que
(eq. (9)) f =WHILE p DO g OD. Por enquanto, suponha que g seja restrito
a funções para as quais D (g) C D (f); mostramos abaixo que isso não envolve
nenhuma perda de generalidade.
Então veremos que se a condição de existência (x E D(f) n
R(f)) ::l f(x) = x for mantida (caso contrário, não há solução), a solução mínima geral para a equação de iteração pode ser dada em termos de um único parâmetro, uma função u que define qualquer sistema de árvores nos conjuntos de níveis
off em D(f) - R(f), ou seja, 6
u = { (x, y) I y é o pai de x}.
4 Um conjunto de níveis Dy(f) = {xI (x, y) E f}, ou seja, todos os argumentos com o mesmo valor de f.
Mais diretamente, u deve satisfazer o predicado D(u) = D(f) A (f(x) =I= f(y) :::> u(x) =I=
u (y)).
5 Em geral, u-1 será uma relação, não uma função, mas a composição u - 1 ; f será
uma função devido à restrição em u.
6 Mais diretamente, a condição em u é
u c (D(f) - R(f)) V (y = u(x) :::> f(y) = f(x)) V u acíclico.
Então (p, g) resolve a equação de iteração. (9), onde
(12)
p= ((D(f) -R(f)) X {T} U (R(f) X {F}),
g=u U (f-D(u) XR(f)).
Para ver o exposto acima, é mais fácil obter a fórmula para p primeiro,
então a condição de existência e então a fórmula para g.
Primeiro, para qualquer solução (p, g), p deve ter valor F em cada ponto
em R (f), pois caso contrário o programa de iteração não pode terminar naquele
valor; inversamente, p deve ter valor T em cada ponto em D(f) - R(f),
pois caso contrário o programa de iteração não atingirá um valor em R(f). Isso
dá a fórmula acima para o domínio do pino D(f) U R(f).
Em seguida, considere qualquer ponto em D(f) n R(f). Pelo exposto acima, p tem
valor F em tal ponto, e o programa de iteração nunca invoca g, mas
simplesmente existe sem alterar o estado. Isso fornece a condição de existência
acima, ou seja, que f deve ser a função identidade em D (f) n R (f).
Finalmente, considere o gráfico da função de estado g em D (f) n R (f).
É evidente que o gráfico do subconjunto de gin D(f) - R(f) não pode ter
nenhum ciclo - deve ser uma árvore - pois, caso contrário, o programa de iteração
não terminaria em tal ciclo. Também é evidente que todos os pontos de uma
subárvore conectada no gráfico de g devem estar no mesmo conjunto de nível de t, pois
o programa de iteração terminará no mesmo valor em R (f) . Assim, o
gráfico do subconjunto de g contido em D(f) - R (f) deve ser um sistema de
árvores nos conjuntos de nível de f. Agora considere os arcos do gráfico de g que
se originam em D(f) -:- R(f) e terminam em R(f) . Os pontos de origem
são raízes das árvores em D(f) - R (f). Como p é F em R (f), o programa de iteração
termina com cada arco. Assim, para cada ponto de origem, digamos x, devemos ter g(x) = f(x). Isso fornece a fórmula para g,
acima, com parâmetro u, uma função que define um sistema de árvores no nível
começa em D(f) - R (f).
Agora removemos a restrição de que D(g) c D(f) como segue.
Suponha D(g) ¢ D(f); então escolha qualquer (x, y) tal que x E D(g) - D(f),
y = g(x). Se para nenhum z E D(f) e inteiro k, gk(z) = x, então (x, y) é
supérfluo para g e g- { (x, y)} também é uma solução; caso contrário, deixe gk(z)
= x, e junte (x, f(z)) a f, e g continua sendo uma solução. Em ambos os casos, o
número de elementos em D(g) - D(f) é reduzido em um; isso pode ser continuado
até D(g) c D(f).
Equações em Expressões de Função Composta
É direto, mas possivelmente tedioso, estender soluções para equações de função
em expressões elementares para equações em expressões compostas arbitrárias
expressões da forma f = expressão de função composta, onde nenhuma
variável de função ocorre mais de uma vez. Para cada nível de aninhamento, um
parâmetro adicional está envolvido e é efetivo somente dentro do escopo desse
aninhamento. Assim, os parâmetros da solução podem ser associados à
árvore de aninhamento da expressão composta.
Em particular, as soluções acima fornecem predicados de existência sobre
os parâmetros para cada tipo de equação de função e as fórmulas para
as soluções refinadas passo a passo. Esses predicados e fórmulas podem ser invocados
iterativamente para descrever o conjunto de todas as soluções para uma equação de função
composta de qualquer complexidade. Como há apenas um número finito de
equações de função composta em um número fixo de funções, essas fórmulas
permitem a formulação explícita de todos os programas D-ehart corretos de
qualquer tamanho.

Desenvolvimento de software
Resumo
O desenvolvimento de software surgiu como um gargalo crítico no
uso humano do processamento automático de dados. Começando com métodos heurísticos ad hoc
de design e implementação de sistemas de software, problemas
de manutenção e mudanças de software se tornaram inesperadamente
grandes. Afirma-se que a melhoria só é possível com mais rigor
na metodologia de design e desenvolvimento de software. O design rigoroso
de software deve sobreviver à sua implementação e ser a base para uma maior
evolução. O desenvolvimento de software deve ser feito incrementalmente, em
estágios com participação e replanejamento contínuos do usuário, e com programação de design-
para-custo dentro de cada estágio.
Palavras-chave e frases
programação de design-para-custo
design de software
desenvolvimento de software
manutenção de software
desenvolvimento de cima para baixo
Vinte e cinco anos de processamento de dados
A explosão do processamento de dados
Nos últimos vinte e cinco anos, uma nova indústria de processamento de dados
explodiu em um papel crítico nos negócios e no governo. Cada empresa ou agência na nação de qualquer tamanho, sem exceção, agora depende de hardware e software de processamento de dados de forma indispensável. Em uma única geração humana, várias gerações de hardware surgiram, cada uma com melhorias notáveis ​​em função, tamanho e velocidade. Mas há dores de crescimento significativas no software que conecta esse maravilhoso hardware com as operações de processamento de dados de empresas e governo. Se esse desenvolvimento de hardware tivesse sido espaçado ao longo de 125 anos, em vez de apenas 25 anos, uma história diferente teria resultado. Por exemplo, imagine a oportunidade para o desenvolvimento industrial ordenado com cinco gerações humanas de desenvolvimento de currículo universitário, educação, feedback para a expansão de metodologias úteis e poda de tópicos menos úteis, etc. Do jeito que está, vemos uma grande indústria com raízes técnicas mínimas, porque quase ninguém em uma posição de responsabilidade tem uma educação universitária original no assunto, e as universidades não têm experiência nem mesmo em saber o que ensinar. Em comparação, vale a pena
observar quantos anos e quanto dar e receber foram investidos
no desenvolvimento do currículo atual de matemática para dar suporte à engenharia
e às ciências físicas — pelo menos os 125 anos imaginados antes.
Mesmo assim, do zero, o progresso técnico e industrial
da sociedade em 25 anos de processamento de dados é impressionante. Mas as necessidades e
frustrações são tão grandes que alguma perspectiva é necessária para entender melhor
como chegamos aqui e para onde podemos estar indo.

Processamento de dados antes
Antes dos últimos 25 anos, essas mesmas empresas e agências conduziam
suas operações sem processamento automático de dados, enquanto ainda processavam
dados em quantidades suficientes para gerenciar seus negócios. Mas o processamento de dados
era feito por pessoas. Mesmo que calculadoras de mesa ou tabuladores fossem usados
aqui e ali, as pessoas ainda inspecionavam resultados intermediários e aplicavam
seu bom senso, quando necessário, para corrigir erros óbvios. Se as instruções de processamento de dados estivessem com defeito ou faltando, as pessoas usavam o bom senso,
novamente, para fazer as operações funcionarem. Em outras palavras, os sistemas de processamento de dados
eram sistemas indulgentes, por causa da inteligência usada em sua execução.
Tais sistemas indulgentes permitem a evolução e a seleção natural
de melhorias no processamento de dados de forma ordenada. Se uma melhoria
é proposta, ela é facilmente adotada com pouco risco, porque efeitos colaterais
imprevistos geralmente serão notados e suprimidos pelas pessoas. Como resultado, o processamento de dados é feito, em grande parte com pouca autoconsciência, como partes implícitas
de outras atividades, como faturamento, controle de estoque, etc.

Alexander, em Notes on the Synthesis of Form [1] discute a
noção de "adequação do ajuste" na arquitetura entre o design e um contexto problemático.
Em culturas primitivas, o design arquitetônico é frequentemente "inconsciente de si mesmo"
e os princípios do design são transmitidos na forma de tradição
e costume. A variação no design é desencorajada pela própria natureza de seu
registro em termos culturais. Mas pequenas mudanças em resposta ao ajuste inadequado, por exemplo,
ao formato do terreno, etc., são fáceis e naturais. Há uma correspondência impressionante
aqui com o processamento de dados em gerações anteriores. Era
inconsciente de si mesmo exatamente neste sentido discutido por Alexander.
Em retrospecto, também está claro que nossos empreendimentos e
agências anteriores sobreviveram com menos processamento de dados do que é feito agora. Com a industrialização
acelerada, as operações físicas são controladas mais de perto do que
antes (por exemplo, compare a gestão logística de alimentos por meio de
cadeias de supermercados atuais em comparação com sistemas de supermercados anteriores) e
atividades administrativas se multiplicaram (por exemplo, compare os requisitos de relatórios fiscais
de negócios hoje e 50 anos atrás). Não está claro qual
é pai e qual é filho - as necessidades de processamento de dados ou a capacidade
de fazer processamento de dados. Mas, em qualquer caso, uma era inteiramente nova de processamento automático
de dados substituiu aqueles · dias em que as pessoas faziam tudo (ou, pelo
menos, a maior parte).

Processamento de Dados Agora
O processamento automático de dados de hoje é feito por computadores sem
nenhum senso comum. Como resultado, instruções defeituosas ou ausentes causam
tal estrago em massa que uma ênfase inteiramente nova na correção
e integridade das instruções de processamento é necessária. Em instituição
após instituição, a transição do processamento manual para o automático de dados
tem sido de benefício misto; embora novas capacidades notáveis ​​tenham sido
forjadas, elas também foram traumáticas e perturbadoras.
Este novo processamento automático de dados é o começo do design
autoconsciente. Alexander [1) continua discutindo o surgimento do design
autoconsciente na arquitetura em Samoa, onde "... o costume exige
que as casas de hóspedes sejam construídas exclusivamente por carpinteiros. Como esses carpinteiros
precisam encontrar clientes, eles estão no negócio como artistas; e eles começam a
fazer inovações e mudanças pessoais sem nenhuma razão, exceto que os clientes em potencial
julgarão seu trabalho por sua inventividade," [1, p. 57]. Novamente,
a correspondência com programadores e designers desses primeiros 25
anos em processamento de dados é muito reveladora.
Mas Alexander continua descrevendo na arquitetura um ponto geral
de relevância para o processamento de dados também [1, pp. 58-59].

No sistema inconsciente, o indivíduo não é mais do que um
agente... Tudo o que é necessário é que ele reconheça os desajustes e
responda a eles fazendo pequenas mudanças. Nem é necessário
que essas mudanças sejam para melhor. Como vimos, o sistema,
sendo autoajustável, encontra seu próprio equilíbrio... O processo autoconsciente
é diferente... Para alcançar em algumas horas na prancheta
o que antes levava séculos de adaptações e desenvolvimento, para inventar uma
forma repentinamente que se encaixe em seu contexto - a extensão das invenções necessárias
está além do designer médio.
Não é de se admirar que choque e frustração apareçam na conversão de operações de
processamento de dados de atividades informais manuais e autocorretivas para
formas formais, mecânicas e explícitas. Os novos designers de processamento de dados autoconscientes
têm hardware para controlar e explorar do qual nenhum de seus professores
nunca ouviu falar. Na arquitetura, é como se pregos, tijolos e argamassa
fossem repentinamente inventados, algo inédito antes. Pode-se esperar que algumas estruturas um tanto
estranhas surgissem!
E neste novo ambiente de frustração e medo, mesmo pequenas
melhorias e mudanças são vistas com suspeita e desconfiança. Na verdade,
os programas de computador que atendem às nossas instituições são incrivelmente
corretos e irremediavelmente incorretos. Eles são incrivelmente corretos em comparação
aos procedimentos manuais que substituíram. Eles representam um nível de
precisão e completude inédito há 25 anos. Mas eles são irremediavelmente
incorretos porque são o resultado de 25 anos de esforços amadores
de desenvolvimento de sistemas por pessoas que são totalmente novas nos problemas. Como
resultado, os programas que dão suporte às nossas instituições são frequentemente misteriosos,
incomunicativos com outros programas que lidam com assuntos e dados semelhantes, e além da compreensão e mudança racionais.

Falibilidade Humana - De Grande a Grandiosa
Nestes primeiros 25 anos, as principais invenções de software foram linguagens de programação
e sistemas operacionais. Estes são bons começos para permitir
o desenvolvimento de aplicativos de processamento de dados. Mas eles têm um
efeito colateral; já que os programadores são as únicas pessoas que conhecem as linguagens de programação
e sistemas operacionais, os programadores se tornam um
sacerdócio entre pessoas e computadores. A arrogância, o poder e a
impotência deste sacerdócio podem ser vistos na maneira como o desenvolvimento de sistemas
é realizado hoje, na maneira como grandes sistemas são concebidos e produzidos.
Um grande desenvolvimento de sistema pode envolver várias centenas de pessoas por vários
anos em uma sequência de estágios, chamados análise de requisitos, especificação,
design, implementação, teste, operação. É necessário e útil dividir tanto trabalho em partes como estas. Mas há perigos,
também, particularmente na condução desses estágios em sequência, e não em
iteração - ou seja, que o desenvolvimento seja feito em loop aberto, em vez de em um loop fechado
com feedback do usuário entre as iterações. O perigo na sequência é
que o projeto deixa de ser grandioso para ser grandioso e excede
nossas capacidades intelectuais humanas para gerenciamento e controle.
Para ilustrar, considere um sistema de software necessário para
controle de estoque em uma empresa, digamos, para ser desenvolvido ao longo de um período de três anos.
Logo de cara, há um conflito. As pessoas que sabem qual controle de estoque
é realmente necessário na empresa estão muito ocupadas fazendo isso para gastar
muito tempo na análise de requisitos, então especialistas substitutos com mais tempo
disponível (adivinhe por quê!) são encontrados. Depois de algum tempo (mas sem muita ajuda
das pessoas-chave), uma especificação de software é desenvolvida, provavelmente incompleta,
provavelmente inconsistente e quase certamente baseada em um conjunto de
opiniões amadoras sobre como fazer o controle de estoque. E neste
ponto a especificação de software começa uma vida própria - congelada, exceto por
controle estrito de mudanças. A especificação é um escudo maravilhoso para programadores
durante a implementação. Eles podem se esconder atrás dela, enquanto os futuros usuários se perguntam o que está acontecendo. Enquanto isso, o departamento de controle de inventário
tem que operar da melhor forma possível, com todas as novas ideias e
procedimentos que puder pensar. Mas, deixados sozinhos por três anos, os programadores
finalmente concluem a implementação e os testes, e o sistema está
pronto para a operação inicial. No entanto, ainda há algumas dificuldades. As
pessoas que fazem o controle de inventário são desconfiadas e céticas em relação ao novo
sistema, especialmente quando ele produz resultados idiotas de vez em quando, e
requer instruções idiotas para operar. Além disso, poucas das novas ideias
dos últimos três anos foram incorporadas ao novo sistema, de modo que
essas novas ideias devem ser abandonadas se o sistema for usado. Mas o mais
crítico de tudo é que o projeto de software foi concebido e gerenciado como um
projeto terminal de três anos, com todas as compensações e compromissos que isso
implica, enquanto a operação de controle de inventário continua indefinidamente.
Este exemplo pode parecer um pouco exagerado. Na verdade, comparado com a
realidade, pode ser malfeito. Mas se é assim, por que as empresas toleram
as frustrações e dificuldades de tal desenvolvimento? Duas razões são
a economia e a ignorância. A economia é que o processamento automático de dados
é barato, se for repetitivo o suficiente, e o processamento administrativo de dados
feito hoje no país não poderia ser feito manualmente - não há
pessoas suficientes. A ignorância se deve à nossa adolescência em uma indústria de 25 anos. Os próximos 25 anos verão um desenvolvimento de sistema muito mais eficaz,
e evolução do sistema além do desenvolvimento inicial, realizado em
unidades de pequenas equipes competentes, em vez de elencos de centenas ou milhares.
Mas isso é mais fácil dizer do que fazer, e para ver onde podemos
ir, precisamos entender melhor onde estamos.

Do desenvolvimento à manutenção
No início do desenvolvimento de aplicativos em processamento de dados, era
comumente suposto que o desenvolvimento era o principal problema. Mas em apenas
25 anos, cerca de 75% do pessoal de processamento de dados já está ocupado
com manutenção, não com desenvolvimento. E a menos que novos métodos radicais
sejam encontrados, a manutenção aumentará ainda mais suas demandas e irá
quase sufocar o desenvolvimento posterior. Por que isso?
Há duas razões, uma de logística simples, mas frequentemente esquecida,
uma de natureza técnica mais profunda. A razão logística é que um sistema de aplicativo
é mantido indefinidamente após um período definido de desenvolvimento,
e com cada desenvolvimento concluído, alguma fração da equipe de desenvolvimento
(ou seu equivalente) deve ser excluída do desenvolvimento e adicionada à
manutenção. Por exemplo, com uma força de trabalho constante, se uma fração x de
cada equipe de desenvolvimento deve ficar para trás para manutenção; então em um
período médio de desenvolvimento, a fração de todo o pessoal dedicado ao desenvolvimento
vai de D para D(l - x). No final de k períodos, começando
em D = 1 (todo o desenvolvimento), a fração de desenvolvimento é (1- x)", e
a fração de manutenção M é 1 - D ou
M = 1- (1- x)k.
Na ilustração, se x = 0,2, k = 6 (digamos uma dúzia de anos de projetos de 2 anos para
uma empresa), então
M = 1 - (0,8) 6 = 0,737856,
ou seja, quase os 75 por cento que são típicos hoje. Há apenas um
ponto estável nesta ecologia - 1 00 por cento de manutenção. Apenas a purga
ou substituição de aplicativos traz este ponto estável abaixo de 100 por cento.
A razão técnica para este alto nível de manutenção é que
tornou-se mais difícil desenvolver bons sistemas do que comumente
supõe. Por "bom" entende-se tanto correção quanto capacidade. Primeiro,
a dificuldade de integrar e depurar sistemas tem sido severamente subestimada
vez após vez. E uma grande força de trabalho é usada hoje em manutenção
corretiva, simplesmente para consertar software que "poderia ter" sido construído
corretamente para começar. Observe o uso incorreto das palavras "depuração" e
"manutenção". Depuração conota a remoção de erros que foram
inseridos por algum processo natural além do controle dos programadores
- mas foram os programadores que inseriram os bugs! Manutenção conota
restaurar um dispositivo ao seu estado original correto - mas o programa não estava
correto para começar! Em ambos os casos, esses são eufemismos gentis para
uma sociedade confusa de programadores. Segundo, tem havido uma subestimação consistente das incertezas e mudanças enfrentadas pelos aplicativos de processamento
de dados. Por exemplo, as leis tributárias mudam e diferem de estado para estado
- os usuários têm melhores ideias - as operações mudam. Portanto, uma força de trabalho considerável
é necessária na manutenção adaptativa, adicionando e modificando o sistema básico,
frequentemente até que o sistema básico não possa mais ser encontrado na confusão
causada pelo processo de modificação.
Da interação à integração

No início do processamento automático de dados, cada aplicativo era uma
operação isolada e autônoma. Tinha que ser. Um aplicativo único
englobaria entrada de dados, computação, geração de relatórios, etc., como um
sistema autossuficiente. No entanto, à medida que mais e mais aplicativos são desenvolvidos,
elementos comuns de dados, cálculos e relatórios surgem. As
mesmas informações de pessoal aparecem na folha de pagamento, estimativa de custos de engenharia
e perfis de pessoal. O mesmo tipo de operações é necessário para
todos os arquivos em relação aos quais as transações são atualizadas periodicamente. Os mesmos executivos
precisam de informações de diferentes aplicativos para fins de tomada de
decisão. Assim, dados e programas se tornam inter-relacionados, e um banco de dados
integrado surge para cada empresa ou agência, seja conscientemente
planejado ou não. A integração pode não ser física, ou mesmo lógica, mas
quanto mais cópias e formatos diferentes forem usados ​​para os mesmos dados, mais
trabalho extra e dificuldades ocorrerão para os usuários.
No início, os aplicativos de processamento de dados eram luxos
que substituíam custos. Mas hoje, muitos aplicativos de processamento de dados são incorporados
necessidades para permanecer no mercado. Sistemas de reserva de companhias aéreas, sistemas de controle de processos de fabricação, sistemas de subscrição e reivindicação de seguros
são exemplos de sistemas cujos custos em tempo de inatividade ou função limitada
não são encontrados na sala de máquinas, mas na folha de lucros e perdas do
negócio.
Metodologia de Design de Software
Integridade Conceitual
A principal lição dos primeiros 25 anos de processamento de dados é que o desenvolvimento de software
é mais difícil de gerenciar e controlar do que parecia
ser no início. Sem um design limpo e atraente, um grande
sistema de aplicativo logo se torna uma confusão e frustração. Detalhes locais podem ser facilmente compreendidos e verificados, mas o sistema vai além do
controle intelectual de qualquer maneira.
Fred Brooks, em The Mythical Man-Month, afirma que "integridade
conceitual é a consideração mais importante no design de sistemas" [4, p. 42]
e reforça isso com uma lembrança dramática de sua experiência em gerenciar
o desenvolvimento do OS/360, como segue [4, pp. 47-48].
É uma experiência muito humilhante cometer um erro multimilionário,
mas também é muito memorável. Lembro-me vividamente da noite em que decidimos como
organizar a escrita real das especificações externas para o OS/360.
O gerente de arquitetura, o gerente de implementação do programa de controle
e eu estávamos discutindo o plano, cronograma e divisão
de responsabilidades.
O gerente de arquitetura tinha 10 bons homens. Ele afirmou que
eles poderiam escrever as especificações e fazê-las corretamente. Levaria dez
meses, três a mais do que o cronograma permitia.
O gerente do programa de controle tinha 150 homens. Ele afirmou que
eles poderiam preparar as especificações, com a equipe de arquitetura coordenando;
seria bem-feito e prático, e ele poderia fazê-lo
no cronograma. Além disso, se a equipe de arquitetura fizesse isso, seus 150 homens
ficariam sentados de braços cruzados por dez meses.
A isso, o gerente de arquitetura respondeu que se eu desse à
equipe do programa de controle a responsabilidade, o resultado não seria de fato
no prazo, mas também estaria três meses atrasado e de qualidade muito inferior.
Eu fiz, e foi. Ele estava certo em ambas as contas. Além disso, a falta de
integridade conceitual tornou o sistema muito mais custoso para construir e
mudar, e eu estimaria que isso adicionou um ano ao tempo de depuração.

Heurística e Rigor
A base principal para manter a integridade conceitual no desenvolvimento de software
é o design rigoroso. Imaginava-se, para começar, que métodos de design
heurísticos eram suficientes. E, de fato, a possibilidade de métodos de design
rigorosos dificilmente era considerada. Afinal, parecia uma questão simples, mas
tediosa, para pessoas inteligentes pensarem em todas as peças de processamento de dados
que tinham que ser feitas e garantir que nada fosse deixado de fora. Como Brooks
aponta, agora sabemos melhor. Mas temos um legado de pensamento heurístico
no desenvolvimento de software que ainda será doloroso de curar.
A diferença entre heurística e rigor no design de sistemas de processamento de dados
está na integridade e estabilidade do design. Um design
heurístico quase sempre funciona - o problema está em "quase sempre". Quando
falha, o sistema deve ser -consertado e remendado. Após uma sucessão de tais
falhas e correções, o design se tornará altamente idiossincrático, com base no histórico de falhas específico que ocorreu. Essa dependência de históricos de falhas ocorre antes das operações reais do sistema em um processo de design heurístico
na imaginação dos designers. Se os designers testarem mentalmente e
consertarem um design heurístico pensando em casos e descobrindo deficiências,
então o design se torna idiossincrático com base no histórico imaginário de
falhas.
Um design rigoroso exigirá mais criatividade e pensamento do que um
heurístico, mas, uma vez criado, um design rigoroso é mais estável. Um design rigoroso
deve sobreviver à sua implementação, não ser inundado por ela e
fornecer uma estrutura para o controle intelectual de mudanças na implementação
conforme os requisitos mudam.
A diferença entre heurística e rigor no design pode ser ilustrada
na construção de um programa de jogo da velha, digamos, para começar
a jogar em qualquer situação viável (por exemplo, para participar em qualquer ponto de qualquer jogo).
Qualquer pessoa com um bloco e um lápis pode facilmente descobrir o que fazer a seguir em
qualquer situação desse tipo. Mas escrever todas essas possibilidades pode ser impraticável.
Então, o próximo passo pode ser uma abordagem heurística, baseada na introspecção
no processo de análise imaginado acima com bloco e lápis. O
início de tal processo (simplificado demais para ilustração) pode ser "jogar
em ordem de prioridade, se possível, centro, qualquer canto, qualquer lado." Isso contará
para alguns movimentos razoáveis, mas falhará em muitas situações, e
uma análise dessas situações sugerirá critérios adicionais de jogo. Mas
com cada adição, uma situação menos óbvia ainda pode levar a uma falha.
Depois de muitas dessas adições, o programa pode de fato ser capaz de
jogo da velha perfeito. Mas será difícil provar isso, exceto por uma exaustiva
análise, que por si só será difícil de provar completa, etc. Conforme observado antes,
tal design desenvolvido heuristicamente, embora possivelmente correto, será
altamente idiossincrático com base no histórico de falhas imaginadas (ou reais)
encontradas no jogo.
Em contraste com tal processo de design heurístico, um tratamento rigoroso
do jogo da velha é possível, usando uma função definida recursivamente, a saber,
uma função definida sobre tabuleiros de jogo da velha (jogos parciais) com valores
"ganhar, empatar, perder" (ou 1, 0, -1) chamado "melhor resultado que pode ser garantido
daqui em diante", digamos "melhor", para abreviar, por exemplo, melhor tem valores
melhor (tabuleiro) = melhor resultado garantido começando com "tabuleiro".
Então, usando a simetria do jogo para ambos os jogadores, a função
melhor pode ser definida recursivamente, como segue,
melhor (tabuleiro) = SE fim do tabuleiro ENTÃO resultado do tabuleiro
SENÃO movimento máximo ( - melhor (- (tabuleiro + movimento) ) )

onde "- board" inverte X's e O's em "board" e "move" é qualquer
escolha de um espaço em branco presente. Com um pouco de estudo, isso pode ser visto para
garantir a melhor jogada possível. Como esse design deve ser programado é
uma questão lógica bem diferente, mas bastante direta. A programação
deve levar em conta se funções recursivas estão disponíveis na linguagem de programação
a ser usada, estratégias de armazenamento e computação mais
adequadas para avaliar melhor a função, etc. Mas o design lógico para o
programa é expresso de forma concisa e completa para exame e
crítica no início, e como um requisito inequívoco para o que deve
ser programado.
Existem ferramentas poderosas em matemática para expressar e validar
design lógico em uma base rigorosa. Nos primeiros 25 anos, os programadores
as ignoraram amplamente, em parte porque as próprias ferramentas
não foram particularmente adaptadas ao design de software e em parte porque
os problemas resolvidos no design de software foram simples o suficiente (ou
pareceram simples o suficiente) para permitir abordagens ad hoc de mente aberta. Mas
há ideias-chave na teoria dos conjuntos, lógica matemática, sistemas axiomáticos,
teoria dos autômatos, linguística matemática, funções recursivas, etc., para
uso em expressão lógica rigorosa. Um problema hoje é que o tratamento usual
dessas ideias de expressão lógica é frequentemente incorporado em assuntos matemáticos maiores, que vão muito mais fundo do que os programadores precisam ou
têm tempo. Mas o uso de expressão lógica eficaz no design de software
está fadado a romper essas barreiras à medida que os benefícios de seu poder
se tornam mais conhecidos e à medida que uma melhor escrita expositiva os torna mais
disponíveis para os programadores. Liskov e Zilles ilustram várias técnicas
de expressão lógica para abstrações de dados em [12].

Design de Programa
Jackson começa seu livro Principles of Program Design com a seguinte
declaração [11, p. 1].
O começo da sabedoria para um programador é reconhecer a diferença
entre fazer seu programa funcionar e fazê-lo corretamente. Um programa
que não funciona está, sem dúvida, errado; mas um programa que
funciona não está necessariamente certo. Ele ainda pode estar errado porque é
difícil de entender; ou porque é difícil de manter conforme os requisitos do problema
mudam; ou porque sua estrutura é diferente da
estrutura do problema; ou porque não podemos ter certeza de que ele
realmente funciona.
A programação estruturada, conforme introduzida por Dijkstra [5], aborda
esse problema. Mas há muito exagero e confusão sobre programação estruturada, principalmente porque uma comunidade adolescente de processamento de dados
;; está ansiosa para encontrar respostas simples para problemas complexos. Embora
a programação estruturada tenha começado com uma famosa carta ao
ditor do CACM "Declarações GOTO consideradas prejudiciais" [7], a essência da programação estruturada é a presença de rigor e estrutura na programação,
:em vez da ausência de GOTOs em programas. Como no design lógico, a
ideia de um método de design de programa rigoroso em vez de heurístico é nova,
e ainda é amplamente desconhecida na programação como praticada hoje.
Como Jackson diz tão bem, fazer um programa funcionar não é suficiente, mas fazê-lo ser projetado corretamente é o mais importante, não apenas para
operar corretamente em todas as circunstâncias necessárias, mas para ser compreensível
e modificável. Há uma disciplina poderosa disponível para fazer com que os programas sejam projetados corretamente: a abordagem construtiva para a correção do programa,
defendida inicialmente por Dijkstra, dada em forma axiomática por Hoare [9],
e mais recentemente descrita e ilustrada em um livro marcante, A Discipline
of Programming, onde Dijkstra expõe seu caso da seguinte forma [6, p. 216].
A primeira mensagem é que não basta projetar um mecanismo
do qual esperamos que ele atenda aos seus requisitos, mas que devemos
projetá-lo de tal forma que possamos nos convencer - e a qualquer outra pessoa
de que ele realmente atenderá aos seus requisitos. E,
portanto, em vez de primeiro projetar o programa e então tentar
provar sua correção, desenvolvemos a prova de correção e o programa
de mãos dadas. (Na verdade, a prova de correção é desenvolvida um pouco
à frente do programa; depois de escolher a forma da prova de
correção, fazemos o programa de modo que ele satisfaça os requisitos da prova.)
Isso, quando realizado com sucesso, implica que o design
permanece "intelectualmente gerenciável". A segunda mensagem é que, se
essa abordagem construtiva para o problema da correção do programa for
ser nosso plano, é melhor garantirmos que o trabalho intelectual envolvido
não exceda nossos poderes limitados. ..
Onde essa disciplina é seguida, fazer os programas funcionarem é um
subproduto de fazê-los corretamente. Na verdade, como apontado no artigo
·'Como escrever programas corretos e conhecê-los" [13], programas bem projetados
podem ser esperados para rodar corretamente ab initio. Como é bem sabido
que não existem métodos infalíveis para saber que o último erro em um programa
foi encontrado, há muito mais confiança prática a ser adquirida
em nunca encontrar o primeiro erro em um programa, mesmo na depuração. Dez anos
atrás, tal objetivo teria sido descartado como irreal. Mas está acontecendo
regularmente entre bons programadores hoje.
A razão pela qual a correção do programa é a chave para um bom design de programa é
que uma disciplina de rigor é imposta no lugar das heurísticas
atualmente disseminadas. A programação estruturada é marcada por um refinamento gradual

processo de design, no qual os programas são derivados e validados como expansões de funções sucessivas em funções mais simples e primitivas. À primeira vista, o refinamento gradual pode parecer simplesmente uma sequência ordenada de cima para baixo
para inventar instruções de programa, mas há mais em jogo ao passar da invenção heurística para a derivação rigorosa. O que está em jogo é uma estrutura de design visível que sobrevive à codificação, para uso em manutenção e modificação, bem como implementação. Cada refinamento marca o topo de uma hierarquia que pode servir mais tarde como um novo ponto de partida intermediário para verificar a correção ou adicionar capacidade a um programa. O artigo "The New Math of Computer Programming" [14] desenvolve um tratamento rigoroso do refinamento gradual em termos matemáticos, no qual a correção é garantida por fórmulas fechadas para expansões corretas. Em outro livro marcante, Algorithms + Data Structures = Programs [18], Wirth dá muitos exemplos excelentes de refinamento gradual rigoroso. Jackson [11] desenvolve um sinergismo especial entre design lógico
e design de programa, com base na seguinte ideia. Um programa estruturado
baseado apenas na lógica de controle de composição (SEQUÊNCIA), alternância
(IF-THEN-ELSE) e iteração (DO-WHILE) produz sequências de execução
de instruções de processamento que são descritas por expressões regulares.
Por outro lado, estruturas de arquivo usadas no processamento de dados também podem ser frequentemente
descritas por expressões regulares. Dada tal estrutura de arquivo e
sua expressão regular, o que é mais natural do que uma estrutura de programa
que produz a mesma expressão regular? Por exemplo, com estrutura de arquivo
dada por
A(B I *(CD))
a estrutura de programa correspondente é
processo A
IFB THEN
processo B
ELSE
FI
WHILE COO
processo C
processo D
OD
Assim, no processamento de um único arquivo, há uma conexão rigorosa entre
arquivo e programa. A própria estrutura do programa garante que qualquer
a possível realização do arquivo será processada completamente. Uma ilustração mais extensa
das conexões entre design lógico e design de programa
é dada por Noonan [15].
A base para confiabilidade de software é design,
não teste
É bem sabido que você não pode testar confiabilidade em um sistema de software.
Se os programas forem bem projetados tanto na estrutura de dados quanto na estrutura de controle,
não há competição entre um programador e um computador para encontrar
erros; o programador vencerá de lavada (isso não é necessariamente verdade
para uma tigela de espaguete). Então a primeira defesa contra erros são programas bem projetados
e provas preventivas pelos próprios autores.
Mas o design eficaz pode fazer muito mais do que tornar erros fáceis de descobrir.
O design pode reduzir o tamanho de um sistema, reduzir suas interconexões,
reduzir a complexidade de suas especificações de programa. Em suma, um bom design
torna sistemas corretos possíveis a partir de programas corretos. Parnas ilustra
esse princípio em [16].
Um software ultraconfiável é possível? Dado o dobro do orçamento e
cronograma (para testar a sinceridade de um requisito de ultraconfiabilidade) não
gaste o extra em testes, gaste em design e inspeção. Comece com
uma competição de design e planeje manter o mais simples. Repita continuamente
subdesigns em estágios principais de refinamento gradual. Semeie "erros
secretos" no design para exercitar e calibrar o processo de inspeção.
Crie a "necessidade de ler" sempre que possível, digamos, exigindo documentação
independente e guias do usuário fora do processo de inspeção. Sistemas de
software com operação sem erros estão surgindo hoje e
serão mais comuns amanhã.
Metodologia de Desenvolvimento de Software
O Problema de Escalar
Logicamente, parece haver pouca diferença entre um programa pequeno e um grande
um. Ambos usam os mesmos conjuntos de instruções, os mesmos compiladores. Então, com
dez vezes o esforço, por que um programa de dez vezes o tamanho não pode ser construído?
A dificuldade é que escalar é mais rápido do que linearmente em esforço, como um
pouco pensamento comprova. O número de conexões possíveis entre n
itens é n(n - 1) /2, e parece razoável esperar que interações de programa244 PRODUTIVIDADE DE SOFTWARE
tenham a tal lei n2. Então, há mais design e
verificação lógica a fazer por unidade de programa desenvolvida. Além disso, conforme esse trabalho
aumenta, mais pessoas são necessárias para fazê-lo; e para coordenar seus esforços,
elas devem se comunicar umas com as outras. Isso significa a lei n2 novamente.
Então, conforme mais pessoas são adicionadas, cada uma gasta mais tempo se comunicando e
menos tempo produzindo.
Nesses problemas de escalonamento, as dificuldades aparecem no momento da integração do sistema. Raramente há dificuldade em fornecer um design adequado
de promessa notável, e raramente há dificuldade em programar as
peças, os módulos; a principal dificuldade é que os módulos raramente funcionam
juntos conforme projetado. Uma dificuldade adicional (como se a integração não fosse
suficiente!) é frequentemente que quando o sistema finalmente funciona todo junto
conforme projetado, ele não faz o que os usuários imaginaram que faria. Então, um
problema adicional de especificações e análise de requisitos que deveria
ter sido tratado no início, mas não foi, aparece.
Desenvolvimento de cima para baixo
A necessidade do desenvolvimento de cima para baixo em grandes sistemas de software nasce
de uma experiência amarga com design de cima para baixo e desenvolvimento de baixo para cima.
No desenvolvimento de cima para baixo, os programas de controle que integram módulos funcionais
são escritos e testados primeiro, e os módulos funcionais são adicionados
progressivamente. Na verdade, o desenvolvimento prossegue em uma base incremental,
nível por nível, com testes e integração realizados durante o processo de programação
, durante o refinamento gradual, em vez de depois, como
discutido por Baker [2] e Basili e Turner [3].
Em um sistema de software, o desenvolvimento de cima para baixo normalmente começa com
um design lógico para a cooperação harmoniosa de vários programas
por meio do acesso a vários conjuntos de dados compartilhados. Por exemplo, um sistema de informações
financeiras pode incluir um programa de manutenção de arquivos, vários programas de entrada de dados
que produzem arquivos de transação para o programa de manutenção de arquivos
e vários programas de recuperação/relatório de dados que acessam o arquivo
principal. Embora cada um desses programas possa ser desenvolvido de cima para baixo independentemente,
o teste de sistema de cima para baixo requer coordenação entre eles, por exemplo,
programas de entrada de dados fornecendo entrada para o programa de manutenção de arquivos,
que por sua vez cria arquivos para programas de recuperação de dados, etc.
No desenvolvimento de cima para baixo, o desempenho do design é crucial. Ele representa
pensar e resolver problemas antes da integração, em vez de depois.
Por outro lado, o desenvolvimento de cima para baixo força a avaliação do design pelo
processo de integração em andamento. No desenvolvimento de baixo para cima, o design ruim é
frequentemente escondido até o final da integração, depois que muito código funcional foi
escrito e testado, apenas para ser descartado.

Em retrospecto, é fácil ver que a vantagem do desenvolvimento de cima para baixo
sobre o desenvolvimento de baixo para cima é a vantagem de um processo de feedback de gerenciamento de
loop fechado sobre um processo de loop aberto. Em um desenvolvimento de baixo para cima
, os módulos não são testados como parte do sistema final até
o fim do desenvolvimento; no desenvolvimento de cima para baixo, eles são testados em
seu ambiente de sistema no dia seguinte. Se houver erros de programa de
efeito em todo o sistema, o desenvolvimento de cima para baixo os descobre cedo, quando
recém-programado (e o programador original está disponível). Se houver
erros de design, o desenvolvimento de cima para baixo força sua descoberta e correção
durante o refinamento gradual, enquanto o desenvolvimento de baixo para cima frequentemente
os deixa sem ser descobertos até o momento da integração, quando os programadores originais
geralmente já partiram.
O desenvolvimento de cima para baixo é mais difícil de projetar do que o desenvolvimento de baixo para cima, mas o esforço extra no design é compensado na integração
e no teste. O problema do design no desenvolvimento de cima para baixo não é apenas
como o sistema final ficará, mas também como o sistema em desenvolvimento
será em cada estágio de sua construção. Construir uma ponte ilustra
essa ideia. Ao desenhar uma ponte no papel, uma viga de extensão pode ser
desenhada primeiro, para ficar pendurada no ar até que outros membros sejam desenhados depois para
suportá-la. Mas para realmente construir essa mesma ponte, um plano de construção
é necessário, o que permite que as vigas sejam colocadas e fixadas uma a uma,
em apoio uma à outra, até que a ponte esteja concluída.
Construir um sistema de software de baixo para cima é como construir uma
ponte de papel: nenhum plano de construção é necessário, apenas o design final, e todos
esperam que tudo saia como planejado. Se as pessoas fossem infalíveis, especialmente
os designers, nenhum plano de construção seria necessário, mas as pessoas são falíveis.
Construir um sistema de software de cima para baixo é como construir uma ponte real.
Encontrar um topo adequado é uma tarefa técnica significativa. Um topo adequado é aquele
que executa como um sistema parcial no início do desenvolvimento e que
fornece a base para adicionar módulos intermediários e finais em um processo contínuo de iteração
de código/integração/teste.
Ferramentas de desenvolvimento
À primeira vista, alguém desejaria o conjunto mais poderoso de ferramentas de desenvolvimento
possível. Isso é verdade, mas não é toda a verdade. É ainda mais
importante que as ferramentas de desenvolvimento sejam confiáveis. Uma linguagem simples com
um bom compilador é melhor do que uma poderosa com um compilador ruim.
Um retorno confiável de duas horas é melhor do que um retorno médio de uma hora
com alta variabilidade. Bons hábitos de trabalho podem acomodar ferramentas
confiáveis ​​em qualquer nível disponível. Mas ferramentas não confiáveis ​​promovem hábitos de trabalho
desordenados.

Uma forma de confiabilidade em ferramentas é o rigor de suas especificações
e implementações. Uma linguagem de programação criada aleatoriamente
como uma coleção de ideias brilhantes é uma ameaça à boa metodologia
de programação. Também é mais difícil de implementar, então as probabilidades favorecem um
compilador não confiável, cujas partes não confiáveis ​​os programadores aprendem a evitar
por meio de experiências amargas, e então, é claro, algumas dessas ideias brilhantes
são efetivamente extirpadas. Quase todas as linguagens de programação criadas
nestes primeiros 25 anos se enquadram nesta categoria; muito poucas se beneficiaram de
uma análise sintática e semântica rigorosa em seu início. Pascal é uma
exceção, como axiomatizado por Hoare e Wirth [1 0]. Um designer
de linguagem de programação enfrenta uma terrível tentação em todas as ideias aparentemente boas
ao redor. Neste caso, o conselho de Wirth é especialmente valioso sobre a
necessidade de rigor e simplicidade, a saber [17, p. 29], "A linguagem [de programação]
deve repousar sobre uma fundação de recursos simples, flexíveis e nitidamente axiomatizados
que compreendem as técnicas básicas de estruturação de dados e
programa." Gannon e Horning [8] também discutem a necessidade de boas construções de linguagem
em termos de fatores humanos.
Um bom número de ferramentas de depuração foi criado para tomar o
lugar de uma boa programação, mas elas não podem. Os programas devem ser escritos
corretamente para começar. Depurar sistemas de software mal projetados e codificados
é medicina veterinária para dinossauros. A solução real é se livrar
dos dinossauros, mesmo que eles realmente apresentem questões
interessantes para veterinários. A melhor ferramenta de depuração, dada uma linguagem de programação
especificada e implementada corretamente, é a mente humana. Compiladores que perdoam
ajudam e encorajam programadores desleixados. Se os programadores podem ser precisos
e exigentes, os compiladores também devem.
Os sistemas de biblioteca podem parecer ferramentas mundanas, em comparação com compiladores,
analisadores, etc., mas são críticos e importantes, conforme discutido por
Baker [2]. Os sistemas de biblioteca devem, antes de tudo, ser ferramentas de gerenciamento de projetos;
como um subproduto, serão ferramentas para programadores. Mas se eles começarem
como ferramentas para programadores, será muito mais difícil garantir que eles
atendam às necessidades de gerenciamento de projetos. Os sistemas de biblioteca devem registrar
e arquivar todo o processo de desenvolvimento de software, desde o bloco de codificação,
ou pressionamento de tecla, em diante.

O Dia do Erro
Teoricamente, um sistema de software existe a qualquer momento, independentemente de seu
desenvolvimento histórico, e qualquer outro histórico que chegue ao mesmo sistema
produzirá o mesmo histórico de uso subsequente. Mas a chance prática
de dois históricos de desenvolvimento diferentes produzirem um sistema de software
idêntico é quase zero. Os sistemas podem parecer semelhantes para o usuário, cada
Desenvolvimento de Software 247
não tem "nenhum erro conhecido", etc., mas seus internos serão diferentes, e
sua integridade de design e propriedades de erro futuras serão diferentes. Um sistema bem projetado
de simplicidades profundas tem um histórico de desenvolvimento que é
bastante distinto de uma tigela de espaguete de força bruta. A diferença mais notável
é o histórico de depuração. Um sistema bem projetado pode
ser montado com poucos erros durante sua implementação. Uma tigela de
espaguete terá um histórico de muita descoberta e correção de erros. Então, uma
diferença é o número de erros encontrados e corrigidos, todos os erros do
pad de codificação ou pressionamento de tecla em diante. (É comum hoje rastrear erros a partir do lançamento do módulo
em diante, mas incomum rastrear erros a partir das linhas de código.) Outra
diferença está na idade dos erros encontrados. Em um desenvolvimento de cima para baixo
bem projetado, os testes sob condições reais do sistema começam cedo, com
erros do sistema encontrados em tipicamente um dia ou mais. Na abordagem de força bruta,
o código é frequentemente testado em unidade com drivers, e os erros do sistema são frequentemente
encontrados mais tarde na integração, semanas, meses ou anos depois.
O número e a idade dos erros levam ao dia do erro (ou seja, para cada
erro removido, a soma dos dias desde sua criação até sua detecção) para
estimar a qualidade de um sistema aceitável de outra forma. Ele indica prováveis
incidentes de erro futuros, mas também indica indiretamente a eficácia
do processo de design e teste. Dias com muitos erros indicam muitos
erros (provavelmente devido a um design ruim) ou erros de longa duração (provavelmente devido
ao desenvolvimento ruim).
Na ilustração, imagine que dois desses sistemas, chamados A e B,
desenvolvidos com as mesmas especificações e condições de aceitação, produziram
as estatísticas na Tabela 18-1. Após a aceitação, cada sistema não tem "nenhum
erro conhecido". Mas o sistema B foi mais difícil de montar, com erros de interface mais sutis
que levaram um tempo considerável para serem encontrados e, portanto, há uma forte probabilidade de mais erros desse tipo ainda não terem aparecido. As estatísticas na Tabela
18-1 não são mantidas, é claro, no processo típico de desenvolvimento de software,
sob a noção de que é uma questão privada como um sistema chega a um estado de
"nenhum erro conhecido". Mas, de fato, importa como um sistema chega a tal
estado porque prevê como o sistema se sairá no futuro. De um
ponto de vista prático, esses não são os mesmos sistemas, embora cada um
não tenha erros conhecidos no momento. O dia do erro dá uma maneira de distingui-los
por como chegaram aqui.

Programação Design-to-Cost
Um dos problemas mais incômodos do desenvolvimento de software é atender aos compromissos de custo
e cronograma. Excessos de tempo e dinheiro são comuns. Na
verdade, os underruns são altamente incomuns. Superficialmente, esses problemas surgem
dos problemas de especificação e estimativa. Especificações frouxas e instáveis
certamente impedem o desenvolvimento oportuno. Mas o problema de
estimativa de programação é difícil, mesmo com boas especificações para uma nova
capacidade ou um novo ambiente de desenvolvimento.
Uma maneira de contornar esse problema de especificação e estimativa de programação
é reinterpretar as estimativas de custo desejadas como requisitos de design-to-cost
e aplicar uma metodologia de design-to-cost no desenvolvimento de software.
Se o custo deve ser fixo, uma nova visão das especificações é necessária.
O software, para praticamente qualquer função necessária, pode ser definido em uma ampla
variedade de custos. As funções básicas de um item de software são geralmente uma
pequena fração do software total finalmente construído. O restante do
software lida com ser amigável aos usuários, lidar com erros automaticamente,
etc., todas as quais são coisas importantes a serem feitas, mas todas as quais podem ser
priorizadas com relação aos fundos e tempo disponíveis para fazê-las. Uma
divisão típica de código básico para exceção em software é de 20-80, por exemplo, 20 por cento
do código lida com 80 por cento das funções necessárias. Se o código básico
for mal estimado mesmo em 100 por cento, esses 20 por cento se tornam 40
por cento, e uma divisão de 40-60 resulta. Provavelmente é uma divisão tolerável (pelo menos
temporariamente) porque ainda lida com 75 por cento (60/80) das exceções
necessárias. Mas o trabalho crítico de gerenciamento de programação é certificar-se
de que os 20 por cento básicos (ou 40 por cento) estejam funcionando dentro
do cronograma e do custo, às custas, se necessário, dos 80 por cento (ou
60 por cento).
Design-to-cost não é uma ideia nova. A sociedade pratica isso na indústria
e no governo de muitas maneiras. Uma metodologia básica vem de um simples
orçamento multinível. Por exemplo, um governo municipal começa com um orçamento
de um certo tamanho e aloca esse orçamento em várias partes; uma para
controle executivo geral, o restante em funções como polícia, bombeiros,

Programação Design-to-Cost
Um dos problemas mais incômodos do desenvolvimento de software é atender aos compromissos de custo
e cronograma. Excessos de tempo e dinheiro são comuns. Na
verdade, os underruns são altamente incomuns. Superficialmente, esses problemas surgem
dos problemas de especificação e estimativa. Especificações frouxas e instáveis
certamente impedem o desenvolvimento oportuno. Mas o problema de
estimativa de programação é difícil, mesmo com boas especificações para uma nova
capacidade ou um novo ambiente de desenvolvimento.
Uma maneira de contornar esse problema de especificação e estimativa de programação
é reinterpretar as estimativas de custo desejadas como requisitos de design-to-cost
e aplicar uma metodologia de design-to-cost no desenvolvimento de software.
Se o custo deve ser fixo, uma nova visão das especificações é necessária.
O software, para praticamente qualquer função necessária, pode ser definido em uma ampla
variedade de custos. As funções básicas de um item de software são geralmente uma
pequena fração do software total finalmente construído. O restante do
software lida com ser amigável aos usuários, lidar com erros automaticamente,
etc., todas as quais são coisas importantes a serem feitas, mas todas as quais podem ser
priorizadas com relação aos fundos e tempo disponíveis para fazê-las. Uma
divisão típica de código básico para exceção em software é de 20-80, por exemplo, 20 por cento
do código lida com 80 por cento das funções necessárias. Se o código básico
for mal estimado mesmo em 100 por cento, esses 20 por cento se tornam 40
por cento, e uma divisão de 40-60 resulta. Provavelmente é uma divisão tolerável (pelo menos
temporariamente) porque ainda lida com 75 por cento (60/80) das exceções
necessárias. Mas o trabalho crítico de gerenciamento de programação é certificar-se
de que os 20 por cento básicos (ou 40 por cento) estejam funcionando dentro
do cronograma e do custo, às custas, se necessário, dos 80 por cento (ou
60 por cento).
Design-to-cost não é uma ideia nova. A sociedade a pratica na indústria
e no governo de muitas maneiras. Uma metodologia básica vem de um simples
orçamento multinível. Por exemplo, um governo municipal começa com um orçamento
de um certo tamanho e aloca esse orçamento em várias partes; uma para
controle executivo geral, o restante em funções como polícia, bombeiros, saneamento, etc. Cada função é, por sua vez, reorçamentada de forma semelhante: o
departamento de polícia alocará uma parte para seu controle geral, o restante para
subfunções, como operações de delegacia, operações de viaturas,
investigações especiais, etc. Este processo de orçamento finalmente atinge o desempenho individual
onde nenhuma outra subunidade é criada.
Por mais simples e antigo que esse tipo de metodologia de design-to-cost
pareça, podemos aplicá-la praticamente em pleno efeito ao problema de desenvolvimento de
software. O desenvolvimento de cima para baixo pode prosseguir como um exercício de orçamento
em uma atividade de design-to-cost. Dado um orçamento para um item de software,
uma fração apropriada pode ser alocada para seu design geral. Uma parte crítica
deste design geral é a alocação dos fundos restantes para o
software ainda a ser feito. Outra parte crítica é a construção do
programa de controle que executará e controlará o software ainda a ser
desenvolvido. Assim, a metodologia de design-to-cost força os custos reais
da construção do programa de controle no topo do software a serem
retirados dos fundos antes que o restante seja alocado para o resto do
software; ou seja, o problema dos designers e arquitetos de sistemas inclui
o problema de alocação entre controle e função subsequente.
A incorporação de uma metodologia de design-to-cost nas operações de planejamento
e orçamento de uma organização usuária também pode trazer
benefícios importantes na conversão do desenvolvimento de software para projetos
orientados à terminação para atividades contínuas mais normais da organização.
A evolução de grandes sistemas em pequenos estágios, com feedback do usuário e
participação em refinamentos de metas em cada etapa é uma maneira de ir do
grandioso para o grande desenvolvimento de sistemas de software. Ainda há muito a
aprender sobre como realizar tal programação de design-to-cost em um
conjunto maior de desenvolvimento incremental de software. Mas estamos 25 anos mais sábios
e mais perto de realizar o sonho de benefícios ainda mais notáveis ​​do
processamento automático de dados para a sociedade.

Software Engineering Education
Em um campo de rápido crescimento como engenharia de software, o problema
educacional se divide em duas partes principais: educação universitária e educação
industrial (algumas das quais são dadas em locais universitários, como
cursos curtos, mas aqui considerados educação industrial). Ambas as partes
se baseiam nas mesmas disciplinas e metodologias subjacentes. Mas as
pessoas envolvidas — tanto professores quanto alunos — têm objetivos
e características diferentes. No nível universitário, os alunos são jovens,
inexperientes e relativamente homogêneos em formação e habilidades.
No nível industrial, os alunos são mais velhos, mais experientes e variam
consideravelmente em formação e habilidades.
Neste artigo, discutimos as semelhanças subjacentes e as
diferenças sobrepostas da educação universitária e industrial em engenharia de
software. As semelhanças em disciplinas e metodologias envolvem
o estudo e a compreensão do processo de software, conforme discutido na
Seção 2 desta edição especial, e das "ferramentas" e "know-how" discutidos
na Seção 3. As diferenças são devidas às características e
objetivos dos alunos, e aparecem no conteúdo e na estrutura dos currículos
e na definição do curso.

Educação em Engenharia de Software em Fluxo
Educação Universitária e Educação Industrial
Em um campo que cresce tão rapidamente quanto a engenharia de software, o problema da educação
se divide em duas partes principais: educação universitária e educação
industrial. (Cursos curtos oferecidos em locais universitários sem créditos de graduação
são considerados educação industrial aqui.) Ambas as partes se baseiam nas
mesmas disciplinas e metodologias subjacentes. Mas as pessoas envolvidas
- professores e alunos - têm objetivos e características diferentes.
Estudantes universitários são jovens, inexperientes e relativamente homogêneos
em formação e habilidades. Estudantes industriais são mais velhos, mais
experientes e variam consideravelmente em formação e habilidades. Professores
universitários são orientados para uma população estudantil transitória (em 2-4 anos
eles se vão) e para suas próprias publicações. Professores industriais são
orientados para uma população estudantil mais estável e para um melhor desempenho industrial
dos alunos devido à sua educação. Em resumo, estudantes universitários
"devem estar aprendendo", enquanto estudantes industriais "devem
estar trabalhando".
Em um campo mais estável do que a engenharia de software, a educação universitária
desempenha um papel dominante na formação dos princípios e valores do
campo, enquanto a educação industrial consiste em cursos de atualização e reciclagem
em áreas marginais e de fronteira. Mas a educação universitária em engenharia de software
não estava disponível para a maioria das pessoas que a praticam e gerenciam
hoje. Portanto, os princípios e valores da engenharia de software estão
sendo moldados em conjunto por influências universitárias e industriais.

Um Problema Sério
Os Estados Unidos se encontram muito à frente em hardware de computador, mas também
caminhando para um problema sério em software. Em uma lição de objeto recente, nossa
indústria eletrônica foi fortalecida significativamente pela escassez de nossos
propulsores de mísseis em comparação com os da União Soviética há 20 anos. Como
resultado parcial da severa disciplina de limitações de potência, espaço e peso
em nossos propulsores, nossa eletrônica foi miniaturizada e melhorada de
maneiras dramáticas. E lideramos em eletrônica hoje por causa dessa história.
Ao contrário, vimos um crescimento surpreendente em potência e disponibilidade de computadores. E nossa indústria de software sofreu com a falta de
disciplina imposta, mesmo ao desenvolver os maiores sistemas de software
conhecidos hoje. Simplificando, estamos acostumados a desperdiçar
potência de computador. Esse mau hábito permeia a indústria, o governo e a própria sociologia e psicologia da maior parte da programação de computadores hoje.
Como o processamento de informações se tornou uma parte essencial da maneira como a sociedade administra suas indústrias e, portanto, uma chave para o poder industrial, a inércia de várias centenas de milhares de programadores indisciplinados nos Estados Unidos é um motivo real para preocupações futuras. Também podemos ter certeza de que essa causalidade funcionará ao contrário. A falta de escassez de computação fornece tentações todos os dias, de todas as maneiras, para desculpar e tolerar o baixo desempenho no setor de software. De fato, a indústria de software já se atrapalhou em uma parcela predominante dos custos de processamento de dados. A menos que abordemos esse problema com medidas excepcionais, estamos a caminho de uma "lacuna de software" muito mais séria e persistente do que a famosa "lacuna de mísseis" que ajudou a alimentar o próprio crescimento de nossa indústria eletrônica. O problema perpetuado Como resultado dessa história, a formação educacional e a disciplina da vasta maioria dos programadores de computador são seriamente baixas. Mas, como uma característica humana natural, a maioria desses programadores prefere ser confortada do que educada. "Afinal, se eu for tão bom quanto a próxima pessoa, eu sou
bom o suficiente."
Felizmente para esses programadores, há uma série de cursos industriais
curtos que confortam, em vez de educar. Eles são
"práticos", "fáceis de entender", "as últimas técnicas". Ao comparecer,
programadores descobrem vários nomes novos para o senso comum, ideias superficiais
e, portanto, concluem, com muito conforto e alívio, que eles
estão atualizados o tempo todo. Mas, infelizmente para o país, esses
programadores não apenas aprenderam muito pouco, mas foram reforçados
na própria atitude de que eles têm pouco a aprender!
Para piorar as coisas, muitos desses cursos
curtos confortáveis ​​e reconfortantes fazem uso liberal do termo "engenharia de software" como uma
palavra da moda. Uma "educação" tão típica em engenharia de software consiste em
três dias de audição, sem exames, mas um sentimento considerável de euforia.
Esse acidente da história também apresenta problemas críticos para as universidades.
A grande demanda por engenharia de software fornece muitas tentações
para padrões acadêmicos mais baixos. As bases matemáticas sólidas para
análise e design de software estão apenas surgindo e não são fáceis de empacotar
para uso em sala de aula neste estágio. Mas, como o software aborda tantos
problemas amplos, não há problema em preencher um curso semestral, ou mesmo um
currículo, com todas as últimas palavras da moda e propostas do campo.

O que é engenharia de software?
Ciência da computação, programação de computadores e
Engenharia de software
Está na moda renomear toda programação de computadores como engenharia de software
hoje, mas não faremos isso aqui. Nossa definição de engenharia de software
requer software e engenharia como componentes essenciais.
Por software, queremos dizer não apenas programas de computador, mas todas as outras
documentações relacionadas, incluindo procedimentos de usuário, requisitos, especificações e
design de software. E por engenharia, queremos dizer um corpo de conhecimento e
disciplina comparável a outros currículos de engenharia em universidades hoje,
por exemplo, engenharia elétrica ou engenharia química.
Nós distinguimos engenharia de software de ciência da computação pelos
diferentes objetivos de engenharia e ciência em qualquer campo - construção prática
e descoberta. Nós distinguimos engenharia de software de programação de computador pela presença ou não de disciplina de nível de engenharia. A engenharia de software é baseada em ciência da computação e programação de computadores, mas
é diferente de qualquer uma delas.
A disciplina completa de engenharia de software não é economicamente viável
em todas as situações. Escrever programas de alto nível em grandes e bem estruturados
sistemas de aplicativos é um exemplo. Essa programação pode muito bem se beneficiar
dos princípios da engenharia de software, mas seus desafios são mais administrativos
do que técnicos, mais no assunto do que no software.
No entanto, quando um pacote de software pode ser escrito por US$ 50.000,
mas custa cinco milhões para consertar um único erro devido a um recall necessário de
um produto de consumo perigoso, o produto pode muito bem exigir um sério
trabalho de engenharia de software, em vez de um simples trabalho de programação de qualidade imprevisível. Fundamentos matemáticos da engenharia de software
É característico de uma disciplina de engenharia ter fundamentos técnicos
explícitos, e a engenharia de software não é exceção. Como o conteúdo
do software é essencialmente lógico, os fundamentos da engenharia de software
são principalmente matemáticos — não a matemática contínua subjacente
à física ou química, é claro, mas a matemática finita mais discreta e
algébrica do que analítica em caráter. Foi observado1 que "a álgebra
é a ferramenta natural para estudar coisas feitas pelo homem, e a análise a ferramenta para estudar coisas feitas por Deus". O software é feito pelo homem, e a álgebra é de fato
a ferramenta matemática natural para seu estudo, embora a álgebra apareça
em muitas formas e disfarces em tópicos de ciência da computação. Por exemplo,
teoria dos autômatos, teorias de sintaxe e semântica de linguagens formais,
estruturação de dados e abstrações e correção de programa são todos algébricos
em caráter, apesar de notações amplamente diferentes devido às suas origens históricas.
Em contraste, a engenharia elétrica combina design físico e lógico
e, portanto, baseia-se em matemática contínua e discreta.
A engenharia de software usa matemática contínua apenas para aproximação conveniente, por exemplo, na teoria de probabilidade ou otimização. A diferença
entre o design lógico da engenharia elétrica e o design lógico
da engenharia de software é de escala. A complexidade lógica de um grande
sistema de software é ordens de magnitude acima da complexidade lógica de um
processador fisicamente realizável. Na verdade, essa capacidade de realizar e implementar
complexidade lógica de alta ordem é a razão do software.
Observe que a matemática discreta não implica necessariamente matemática finita. A análise de algoritmos, por exemplo, leva a questões lógicas profundas
quanto a se um processo computacional é finito ou não, mesmo
embora todas as operações sejam discretas. A teoria das máquinas de Turing fornece
outro exemplo [8].
Estrutura e organização na engenharia de software
A principal dificuldade na engenharia de software é a complexidade lógica [4].
E a principal técnica para lidar com a complexidade é a estrutura. Devido
ao grande volume de trabalho a ser feito, o desenvolvimento de software requer
dois tipos de estruturação, algébrica e organizacional. A estruturação
algébrica, aplicada de diferentes maneiras, permite técnicas mentais de dividir
e conquistar, com os mesmos princípios subjacentes, nas várias fases
de especificação, design, implementação, operação e evolução do software.
O resultado da estruturação adequada é o controle intelectual, ou seja, a
capacidade de manter a perspectiva ao lidar com detalhes e de aumentar
e diminuir o zoom na análise e design de software.
A principal técnica organizacional é a estruturação do trabalho - entre
trabalhadores e máquinas e, além disso, entre trabalhadores. Ferramentas de software,
na forma de compiladores de linguagem, sistemas operacionais, entrada de dados e recursos de biblioteca,
etc., representam técnicas de estruturação do trabalho entre
trabalhadores e máquinas. Uma dimensão importante da estruturação do trabalho entre
pessoas está ao longo do eixo conceitual-clerical, que permite isolamento efetivo
e delegação do trabalho clerical. Outras dimensões são baseadas no assunto
em software e aplicativos. Uma equipe cirúrgica representa um bom exemplo de estruturação do trabalho, com diferentes papéis predefinidos pela profissão
e educação anterior. Cirurgia, anestesiologia, radiologia, enfermagem,
etc., são dimensões da estruturação do trabalho em uma equipe cirúrgica. A comunicação
entre esses papéis é nítida e limpa - com uma baixa largura de banda em
sua interface, por exemplo, no nível de "esponja e bisturi", não toda a largura de banda
do conhecimento médico. Um time de futebol de escola primária representa um
mau exemplo de estruturação do trabalho - o primeiro garoto que alcança a bola consegue
chutá-la. Mas a primeira pessoa que alcança o paciente não consegue operar,
e os enfermeiros do hospital não se tornam cirurgiões por meio de treinamento no trabalho.

Estruturas de Carreira em Engenharia de Software
Além das habilidades de engenharia de nível de graduação em software, identificamos a
necessidade de vários graus de habilidades técnicas e também de habilidades de ciências
e administração de nível de graduação. Dentro das habilidades de engenharia, podemos
diferenciar por assunto e ainda mais por nível de habilidade por meio de níveis de graduação
de graduação.
Assim como em qualquer outra profissão, como direito, medicina, etc., muitas
categorias de habilidade e níveis de habilidade entram em uma equipe de engenharia de software
bem formada. No desenvolvimento de software, o peso absoluto da lógica precisa domina,
e a necessidade de procedimentos de precisão para design e controle é
crítica. Por exemplo, em direito, três juízes podem subdividir uma opinião para
um projeto de redação conjunta e atender aos requisitos de precisão legal com
pequenas variações em seus vocabulários individuais. Mas um desenvolvimento de software
conjunto por três programadores não tolerará a menor variação
no vocabulário por causa do tratamento literal do texto de design por um
computador.
O engenheiro de software está no centro do desenvolvimento de software
e operações de computador nas quais algoritmos básicos e processamento de dados
podem exigir outras habilidades avançadas para sua definição, análise e validação.
Por isso, as habilidades administrativas e de ciências de pós-graduação são parceiras frequentes
no desenvolvimento de software, e o engenheiro de software precisa
estar em casa com uma abordagem interdisciplinar.
Dentro da engenharia de software, podemos identificar várias áreas de concentração
que têm a profundidade e a substância que podem ocupar uma pessoa
por uma carreira ao longo da vida. Essas áreas incluem tópicos como compiladores,
sistemas operacionais, sistemas de banco de dados, sistemas de controle em tempo real e sistemas de
processamento distribuído. Essas especialidades em engenharia de software geralmente
exigem educação de nível de pós-graduação para liderança de equipe eficaz e
contribuições técnicas avançadas.
Práticas de engenharia de software
Elementos da engenharia de software
A prática eficaz da engenharia de software deve ser baseada em seus fundamentos técnicos, assim como qualquer outra atividade de engenharia, combinando necessidades do mundo real e possibilidades técnicas em projetos e sistemas práticos.
Para nossos propósitos, é conveniente classificar as disciplinas e procedimentos
da engenharia de software em três categorias.
1. Design (segundo Platão, Fedro). "Primeiro, a absorção de
particulares dispersos sob uma Ideia, para que todos entendam o que
está sendo falado... Segundo, a separação da Ideia em partes,
dividindo-a nas juntas, como a natureza orienta, não quebrando nenhum membro ao meio
como um mau entalhador faria."
2. Desenvolvimento. A organização das atividades de design em desenvolvimento de
software sustentado, incluindo a seleção e o uso de ferramentas e
procedimentos operacionais para estruturação de trabalho entre diferentes categorias de
pessoal.
3. Gestão. Análise de requisitos, definição de projeto, identificação
do pessoal certo e estimativa, programação, medição
e controle do design e desenvolvimento de software.
Design de Engenharia de Software
A disponibilidade de princípios úteis, testados e bem documentados de especificação e design de software
explodiu na última década, em três
áreas distintas, a saber,
1. Controle de processo sequencial: caracterizado por programação estruturada
e ideias de correção de programa de Dijkstra [7], Hoare [14], Linger,
Mills e Witt [17] e Wirth [26, 27].
2. Estruturação de sistema e dados: caracterizada por ideias de decomposição modular
de Dijkstra [9], Dahl [7], Ferrentino e Mills [II, 19]
e Parnas [22].
3. Controle de processamento multidistribuído e em tempo real: caracterizado por
ideias de processamento simultâneo e sincronização de processo de Brinch
Hansen [5], Dijkstra [10], Hoare [15] e Wirth [28].
O valor desses princípios de design está na disciplina
e repetibilidade aumentadas que eles fornecem para o processo de design. Os designers podem entender,
avaliar e criticar o trabalho uns dos outros em um objetivo comum estrutura. Em uma frase de Weinberg [25], as pessoas podem praticar melhor o "design de software sem ego" concentrando as críticas no design e não no autor.
Esses princípios de design também fornecem critérios diretos para procedimentos de inspeção de design mais formais, para que designers, inspetores e gerências possam se preparar melhor, conduzir e interpretar os resultados de inspeções periódicas e ordenadas de design.
Desenvolvimento de engenharia de software
Embora o trabalho conceitual primário da engenharia de software esteja incorporado
no design, a organização e o suporte das atividades de design no
desenvolvimento de software sustentado é uma atividade significativa em si mesma, conforme discutido
em [3] e [20]. A seleção e definição de linguagens e ferramentas de suporte de design e programação, o uso de sistemas de suporte de biblioteca
para manter o estado de um design em desenvolvimento, a estratégia de teste e integração,
todos impactam o processo de design de maneiras importantes. Portanto, as disciplinas,
ferramentas e procedimentos usados ​​para sustentar o desenvolvimento de software precisam
ser examinados, estruturados e escolhidos com tanto cuidado quanto os próprios princípios de design.
A principal necessidade de disciplina de desenvolvimento está no controle intelectual e gerenciamento de abstrações e detalhes de design em larga escala. Brooks [6] afirma que "integridade conceitual é a consideração mais importante no design de sistemas". Linguagens de design e programação são necessárias para lidar com abstrações de procedimentos e abstrações de dados, com estrutura de sistema e com a cooperação harmoniosa de processos multidistribuídos. Sistemas de suporte de biblioteca de design são necessários para a conveniente criação, armazenamento, recuperação e modificação de unidades de design e para a avaliação geral do status e progresso do design em relação aos objetivos. O isolamento e a delegação de trabalho entre atividades conceituais e administrativas, e entre várias subatividades em ambas as categorias são de importância crítica para um esforço de desenvolvimento sustentado e gerenciável. As Equipes de Programadores Chefes [3] incorporam essa estruturação de trabalho para projetos de pequeno e médio porte. Em projetos maiores, é necessária uma organização de Equipes de Programadores Chefes e outras unidades funcionais. Gerenciamento de Engenharia de Software O gerenciamento da engenharia de software é principalmente o gerenciamento de um processo de design e representa uma atividade intelectual muito difícil. Mesmo
que o processo seja altamente criativo, ele deve ser estimado e programado
para que várias partes da atividade de design possam ser coordenadas e integradas
grated em um resultado harmonioso, e para que os usuários possam planejar os resultados também
. O controle intelectual que vem de disciplinas e procedimentos de design e
desenvolvimento bem concebidos é inestimável para atingir esse resultado.
Sem esse controle intelectual, até mesmo os melhores gerentes enfrentam
probabilidades desesperadoras ao tentar ver o trabalho até o fim.
Para atender aos compromissos de custo/cronograma diante de técnicas de
estimativa imperfeitas, um gerente de engenharia de software deve praticar
um processo de gerenciar e projetar para custo/cronograma. Esse processo exige uma
retificação contínua e implacável dos objetivos de design com o custo/
cronograma necessário para atingir esses objetivos. Ocasionalmente, essa retificação
pode ser simplificada por uma nova abordagem ou técnica brilhante, que
aumenta a produtividade e encurta o tempo no processo de desenvolvimento. Mas
geralmente, apenas porque as melhores abordagens e técnicas possíveis conhecidas
já estão planejadas, uma deficiência, ou mesmo uma bonança em software viável,
requer consulta com o usuário para fazer as melhores escolhas
entre função, desempenho, custo e cronograma. É especialmente importante
aproveitar as bonanças para combater outras deficiências; muitas vezes
as bonanças não são reconhecidas e desperdiçadas. O controle intelectual de
um bom design de software não só permite uma melhor escolha em um desenvolvimento atual,
mas também permite melhorias subsequentes de função e desempenho
em um sistema de linha de base bem projetado.
Na engenharia de software, há duas partes em uma estimativa: fazer
uma boa estimativa e tornar a estimativa boa. Cabe ao gerente de engenharia de software
verificar se ambas as partes estão certas, juntamente com
a função e o desempenho corretos.
Princípios da educação em engenharia de software
Graus em engenharia de software
Um diploma em engenharia de software deve, antes de tudo, ser um diploma de engenharia,
lidando com design e construção de engenharia. Não deve ser simplesmente
um diploma de programação de computadores ou um diploma de ciência da computação. Como já
observado, há muita programação a ser feita na sociedade, e outros
currículos em artes e ciências ou administração de empresas devem ser chamados
para fornecer educação adequadamente focada para programação mais geral
em aplicações de negócios e ciências. O programa de mestrado da UCLA
em Ciência da Computação [16] é um bom modelo de outros currículos, que
tem conteúdo de alta tecnologia, mas não pretende ser engenharia de software.
Os princípios usuais da educação universitária devem ser aplicados a um currículo em engenharia de software, ou seja, que seja uma preparação para uma
carreira baseada em tópicos de meia-vida razoável, ao mesmo tempo em que produz habilidades de trabalho de nível básico
e a capacidade de aprender mais tarde. Esses objetivos não são incompatíveis
porque os próprios tópicos necessários para lidar com problemas de software desafiadores tecnicamente são geralmente tópicos básicos de longa vida, e eles
de fato preparam as pessoas para educação mais avançada e aprendizado
continuado. É bem sabido que matemática e ciência são mais facilmente
aprendidas quando jovens e, portanto, como regra, tópicos leves devem ser adiados para
experiência de pós-graduação e aprendizado contínuo. Há um perigo real em
usar tópicos leves e cursos de pesquisa carregados de chavões para fornecer
vendabilidade de entrada em empregos de curto prazo. Mas sem fundamentos técnicos adequados,
as pessoas ficarão sem saída no meio da carreira, exatamente quando se espera
que resolvam problemas mais difíceis como indivíduos, como membros ou como gerentes de
equipes.
Nas três categorias de práticas de engenharia de software listadas
acima, os estudos em práticas de design são os principais candidatos para a educação universitária
inicial; as práticas de desenvolvimento devem ser introduzidas gradualmente mais tarde, e as práticas de
gerenciamento adiadas para aprendizado contínuo de pós-graduação, após considerável
experiência em prática individual e de equipe em engenharia de software.
Fundamentos e solução de problemas
Este é um dilema difícil nos currículos universitários para equilibrar as necessidades
de bases técnicas sólidas e aprender a resolver problemas. Claro,
este dilema não é exclusivo da engenharia de software. Limitar tópicos a
técnicas permite um processo educacional mais eficiente em termos de quantidade,
volume e qualidade de técnicas que são ensináveis. Mas é frequentemente
difícil para os alunos aplicarem tais técnicas em contextos de resolução de problemas.
A resolução de problemas é um grande motivador e construtor de confiança. Mas muita
ênfase na resolução de problemas reduz a quantidade de preparação técnica
possível e produz alunos capazes de fazer uma boa primeira exibição em
sua carreira, mas que provavelmente abandonarão cedo devido à falta de
habilidades técnicas mais profundas.
É característico na engenharia de software que os problemas a serem
resolvidos por profissionais avançados exijam esforços sustentados ao longo de meses ou
anos de muitas pessoas, geralmente na casa das dezenas ou centenas. Este tipo de esforço em massa
de resolução de problemas requer um tipo radicalmente diferente de precisão e
escopo em técnicas do que os necessários para solucionadores de problemas individuais. Se
a precisão e o escopo não forem adquiridos na educação universitária, é difícil
adquiri-los mais tarde, não importa o quão bem motivada ou hábil uma pessoa
possa ser em abordagens individuais e intuitivas para resolução de problemas.
Todos nós conhecemos experiências em cursos de matemática elementar de obter pouco ou nenhum crédito por adivinhar respostas corretas sem mostrar
o processo para encontrá-las. Havia uma boa razão, porque adivinhar
respostas para pequenos problemas não pode ser ampliado para problemas maiores, enquanto
processos necessários para resolver problemas menores podem ser ampliados. Esse problema de
escala é a principal diferença entre programação de computadores e
engenharia de software.
Tópicos do currículo
O currículo ACM '78 [2] é uma prescrição bem aceita para um diploma de graduação
em ciência da computação/programação. Mas há aqueles que
acreditam que o currículo '78 não apresenta o suficiente e o tipo certo
de matemática. Em qualquer caso, este autor acredita que os diplomas em engenharia de software
devem ser consideravelmente mais fortes em matemática discreta do que
sugerido pelo currículo '78. Em particular, um currículo em engenharia de software
deve exigir um bom conhecimento prático do cálculo de predicados de primeira ordem; as álgebras de conjuntos, funções e relações; e uma
compreensão profunda o suficiente do raciocínio matemático para usá-lo de forma flexível
em problemas grandes e complexos. Estamos começando a ver evidências
do 'poder prático do raciocínio matemático no domínio da complexidade
de software, por exemplo, na verificação de programas [12], e no desenvolvimento
de sistemas de software inteiros, como o UCLA Unix Security Kernel
[24]. Com tal base, o currículo pode fornecer uma compreensão
de algoritmos [1], programas de computador [17, 26, 27], estruturas de dados
[13], abstrações de dados [18] e bancos de dados [23] como objetos matemáticos.

Educação universitária para adultos
O rápido crescimento da engenharia de software significa que haverá uma
quantidade considerável de educação para adultos no trabalho universitário (em contraste com
cursos curtos que podem ser dados em universidades sem diploma).
Normalmente, esses serão diplomas avançados para pessoas com uma boa
base em matemática ou ciência da engenharia. É de se esperar que
a educação para adultos continue paralelamente em artes e ciências, e em escolas de
administração de empresas pelo mesmo motivo, porque toda a indústria
está crescendo rapidamente. Mas, como observado antes, distinguimos entre programação
e engenharia de software e pretendemos discutir aqui a educação
universitária para adultos apenas em engenharia de software.
Alunos adultos em currículos universitários têm vantagens e desvantagens
sobre alunos mais jovens que vêm diretamente de educação anterior.
Suas vantagens estão em sua motivação e no fato de que eles têm uma base de experiência maior na qual incorporar as ideias, técnicas,
etc., que recebem no processo educacional. Suas desvantagens estão em estar
enferrujado no processo de aprendizagem e possivelmente em ter sua educação um tanto
desatualizada com o passar do tempo. No geral, as pessoas que são
motivadas o suficiente para retornar para a educação de adultos no nível universitário são
geralmente alunos superiores e tiram mais proveito de sua educação do que seus
colegas mais jovens, mas deve-se esperar que vivam de acordo com os padrões acadêmicos
da instituição.

Cursos de laboratório em engenharia de software
Sabemos por outras disciplinas de ciência e engenharia que os cursos de laboratório
geralmente são mais difíceis de desenvolver do que os cursos de palestra. Em software,
simplesmente deixar as pessoas aprenderem sozinhas no desenvolvimento de programas
e sistemas como projetos pode levar a duas semanas de experiência repetidas
sete vezes em vez de um curso de laboratório de quatorze semanas de experiência cumulativa. O problema com esses projetos de alunos de ciclo aberto é que
muito do tempo é gasto na recuperação de decisões imprudentes ou execuções ruins
feitas anteriormente, com pouco aprendizado real acontecendo.
Um programa de graduação em engenharia de software deve conter uma
sequência mínima de cursos de laboratório, que é baseada na compreensão
e modificação de programas existentes e na resolução de problemas de integração de hardware/software
antes de prosseguir para o design e desenvolvimento do programa e
mais tarde para a especificação e design do sistema. Esta sequência de laboratório deve
proceder de (1) um ambiente altamente estruturado no qual programas cuidadosamente concebidos
(com problemas cuidadosamente concebidos) são apresentados aos alunos
para teste e modificação para (2) situações menos estruturadas onde
os alunos projetam e desenvolvem produtos de software pequenos, depois grandes, a partir de especificações bem definidas,
finalmente para (3) situações ainda menos estruturadas onde
eles lidam com requisitos informais a partir dos quais especificações e designs
devem ser desenvolvidos. Nesta sequência, há uma oportunidade de
identificar problemas, que todos os alunos encontram simultaneamente, para os quais
os instrutores podem ajudar a desenvolver abordagens e soluções. Um problema de integração de hardware/software no início da sequência de laboratório parece especialmente
importante para alunos de engenharia de software, porque geralmente há
interfaces importantes entre hardware e software nos sistemas de alto desempenho
lidados pela engenharia de software.

Software Productivity in the Enterprise

Diferenciais de produtividade em software
ART\ClE
20
Há uma diferença de 10 para 1 na produtividade entre programadores praticantes
hoje - isto é, entre programadores certificados por suas posições industriais
e remuneração. Esse diferencial é indiscutível, e é um comentário sério
sobre nossa capacidade de medir e impor padrões de produtividade
na indústria.
Há duas razões principais para esse diferencial surpreendente. Primeiro,
programação é uma atividade de resolução de problemas, e há um grande diferencial
entre as pessoas em sua capacidade de resolver problemas dos tipos encontrados em
programação. Segundo, a indústria tolera esse diferencial porque
a produtividade da programação é extremamente difícil de medir. Linhas de
código-fonte do programa escritas e depuradas por dia são fáceis de medir,
mas elas estão apenas remotamente relacionadas à produtividade real. Às vezes, a
maior produtividade real é o resultado de descobrir como reutilizar programas
já escritos-po 1 I, para um propósito de aparência bem diferente. Outra
forma de alta produção ocorre ao descobrir como resolver problemas com
programas existentes no passado. revisando-os como subprogramas. É baixa produtividade
escrever uma grande quantidade de código-fonte de programa para as partes fáceis
do que precisa ser feito quando já foi feito. E ainda assim essa
produtividade ex
produtividade do trabalho de uma sal
da}.
1_- não há maneiras objetivas de medir programas
mais do que se pode medir a
contagem das quantidades de palavras faladas por

dia. E os resultados precisam ser medidos em valor para a empresa, não
linhas de código.
Embora esse diferencial de produtividade entre programadores seja compreensível,
também há uma diferença de 10 para 1 na produtividade entre organizações
de software. Essa diferença precisa de um pouco mais de explicação. À primeira
olha, parece que as diferenças entre programadores tenderiam a
se equilibrar nas organizações. Por exemplo, as alturas médias dos programadores
de organização para organização diferem muito menos do que a
altura de programador para programador. Por que a produtividade não se equilibra
também?
Há duas razões principais pelas quais o diferencial na produtividade individual
não se equilibra em organizações de software. Primeiro, a
produtividade individual não é simplesmente aditiva em uma organização de software: módulo I
e módulo I podem ser iguais a 0 sistema se as interfaces e funções do módulo
não corresponderem. Tornar a produtividade individual aditiva em organizações de software
requer boa tecnologia e boa gestão. Segundo, programadores individuais
não se juntam a organizações de software aleatoriamente. Em cada caso
há uma oferta e uma aceitação. Acontece que essas organizações
com boa tecnologia e boa gestão podem atrair os melhores programadores,
e vice-versa. Então, as melhores organizações têm as duas
melhores maneiras. Elas atraem a maior produtividade individual e tornam essa produtividade
mais aditiva.
Mas agora chegamos a um paradoxo curioso. As organizações de software
com melhor desempenho — as 10 performers — normalmente não são tidas em maior
estima por suas próprias empresas do que as I performers. Pois como suas
próprias empresas saberão que são 1's ou 1 O's, quando são a única
organização de software que conhecem? Na verdade, há um efeito reverso. As 1
performers geralmente fazem o software parecer difícil; as 10 performers geralmente
fazem com que pareça fácil. Como as pessoas em uma empresa podem distinguir entre
fazer coisas difíceis e fazer as coisas parecerem difíceis em software? Cada comparação
que elas podem fazer é comparar maçãs com laranjas — problemas diferentes,
empresas diferentes, situações diferentes. Simplesmente não há uma maneira fácil e objetiva de
saber.
Essa dificuldade de julgar a produtividade da própria organização de software
pode parecer frustrante. Afinal, como as organizações
de desempenho 10 obterão suas justas recompensas? Elas obterão suas justas recompensas de uma
maneira simples. Suas empresas sobreviverão. O processamento de dados e a qualidade
do software são cada vez mais uma questão de sobrevivência para as empresas. Quanto
maior a dependência do processamento de dados para sobrevivência, maior a seletividade
do desempenho produtivo em software. Por exemplo, não há
uma grande companhia aérea no mundo sem um sistema automatizado de reservas
de companhias aéreas. Elas não podem sobreviver sem um. Então, a longo prazo, não
há problema em identificar organizações de software produtivas.

Sete Indicadores de Produtividade em Software
Embora o moinho de produtividade de longo prazo triture com segurança e precisão,
a essência da gestão é antecipar e melhorar a produtividade de sua própria empresa no curto prazo, incluindo a de sua organização de software.
Na percepção de que nenhuma medição simples será suficiente,
oferecemos um conjunto de indicadores de produtividade em software. Nenhum desses indicadores é numérico ou objetivo. Cada um deles requer avaliação e julgamento da gerência. Além disso, esses indicadores não somam, nem têm um papel fixo de importância. Isso também requer julgamento da gerência.
Pode parecer pouco conforto nisso, mas prometer algo mais é um desserviço ao leitor. Não há dúvida de que medições de gestão de formas numéricas e objetivas podem ser elaboradas para refletir esses indicadores. Mas tais medições devem ser elaboradas pela gerência empresarial que então conhece suas circunstâncias especiais e conhece por construção as limitações e falibilidades de suas próprias medições.
1. Bom controle de cronograma e orçamento
Cronogramas e orçamentos estourados refletem uma falta de controle intelectual e de gestão. O controle ruim de cronograma e orçamento nega à gerência a real capacidade de exercer escolha sobre qual papel o software desempenhará na empresa. Se os programadores decidirem quando os projetos serão concluídos depois que estiverem bem encaminhados, em vez de a gerência da empresa decidir antes de aprová-los, os programadores estão tomando decisões de nível empresarial, goste ou não.
Orçamentos estourados geralmente são pequenos preços a pagar em comparação com o
custo de oportunidade da empresa em não ter o serviço de software
planejado. Se não houver um grande custo de oportunidade, o software não deveria ter sido justificado de qualquer maneira.
2. Boa metodologia
As pessoas de software devem saber o que está acontecendo na universidade e na
profissão. A metodologia usada deve ser baseada na escolha do mais recente e melhor, e não baseada na ignorância. Também deve ser generosamente misturada com o antigo e confiável. O objetivo de uma boa metodologia não é produtividade ou qualidade. mas controle de gestão. Uma vez que o controle de gestão é alcançado, pode-se escolher produtividade, qualidade ou outros objetivos de produtividade, qualidade ou outros
para atender às necessidades da empresa.
3. Boas pessoas
De onde vêm as pessoas de software? Você deve escolher
boas pessoas nos currículos universitários de matemática e ciência da computação.
A experiência mostrou que é preciso mais maturidade matemática para gerenciar software do que para fazer software. Você precisa de um bom material para desenvolver seu futuro. A indústria está lotada de programadores mal-educados que fazem os programas rodarem apenas por tentativa e erro. Eles são o equivalente a digitadores de caça e bicada, que estão fazendo o que é natural, enquanto digitadores de toque aprenderam a fazer o que é artificial.
4. Fazendo parecer fácil
Processos sistemáticos e ordenados fazem o software parecer fácil, principalmente
no momento da integração de sistemas. A crise de integração não é um sinal de um
problema difícil; é um sinal de tecnologia e gerenciamento ruins. É difícil
ver as pessoas pensando, mas é fácil vê-las codificando. O programador cujos pés estão na mesa pode ser seu ativo mais produtivo. Pensar leva tempo - mais tempo do que imaginamos.
5. População estável
Você não precisa apenas ter boas pessoas e educá-las para seu próprio empreendimento. Você precisa mantê-las. Se sua população for instável, é provável que você esteja 1) dispensando pessoas pobres que nunca deveria ter contratado ou 2) perdendo pessoas boas que não pode perder. Obter tecnologia mais avançada do que a que você tem ao contratar profissionais experientes perde a continuidade com seu passado e a esperança para seu próprio pessoal, então faça isso com cuidado. Você não pode gastar o suficiente em educação, mas certifique-se de que seja educação em um nível universitário de metodologia, com critérios de aprovação/reprovação, não entretenimento de curso de curta duração.
6. Flexibilidade de Pessoas
Os requisitos para alta produtividade de software são surpreendentemente como
os de qualquer outra parte de sua empresa - marketing, manufatura,
administração e assim por diante. Você precisa de mentes organizadas e corações fortes. Construir uma boa apresentação de vendas é surpreendentemente semelhante a escrever um bom programa: você escreve um programa para um cliente em potencial executar em vez de um computador. Então pergunte a si mesmo como seu pessoal de software pode ajudar no resto de sua empresa. Se sua principal reivindicação à fama é saber como os computadores funcionam, em vez de como sua empresa funciona, contrate algumas pessoas novas. Eles precisam saber como os computadores funcionam, tudo bem, mas precisam fazer isso com menos da metade do seu esforço.
7. Paixão por Computador
Pessoas que amam programar computadores e vê-los rodando, que os devoram
não deveriam ter permissão para programar por pagamento. Se forem muito boas, há um pequeno número de tais posições — em universidades e grandes
centros de pesquisa industrial. Caso contrário, elas deveriam ter um computador em casa.
Software é um negócio muito sério para ser feito por diversão. Deve-se programar um computador apenas como último recurso — quando ele não foi programado antes. Esses problemas estão ficando cada vez mais difíceis de encontrar hoje em dia e não há muitas coisas fáceis para fazer.

Segredos da produtividade excepcional
Podemos resumir os segredos da produtividade excepcional em três etapas. Primeiro, minimizar a reinvenção; segundo, minimizar o retrabalho; e terceiro, trabalhar de forma inteligente quando necessário, em vez de trabalhar duro.
O desempenho excepcional começa com a minimização da reinvenção e o desenvolvimento de um novo software apenas como último recurso; mas quando um novo software é necessário, o desempenho excepcional encontra as maneiras mais simples e diretas de produzir esse software. A finalização da reinvenção se aplica não apenas aos produtos finais, mas também às ferramentas usadas no desenvolvimento de software.
A maneira mais econômica de colocar um novo sistema de software em funcionamento é descobrir que ele já existe. Pode exigir algum esforço, e
há algum risco de se esforçar apenas para descobrir que tal
sistema não existe; mas no desempenho excepcional, minimiza-se a reinvenção.
A próxima maneira mais eficaz de colocar um novo sistema de software em funcionamento é descobrir componentes maiores que podem ser integrados com o mínimo de esforço no s~ em necessário. Pode parecer · crível a princípio, mas o desempenho excepcional reduz o trabalho necessário "desenvolvimento de software por grandes fatores. Na verdade, entrar em cada fase de requisitos, design, implementação e operação. desempenho pode reduzir o trabalho necessário nas fases subsequentes de tluee ou mais. Ou seja, um bom trabalho de análise de requisitos ~ e -· e design por um fator de três, um bom


design pode reduzir o trabalho de implementação por um fator de três, e uma
boa implementação pode reduzir o trabalho de operações e manutenção por
um fator de três.
Em suma, as oportunidades de produtividade decaem exponencialmente
ao longo da vida do sistema. Esses fatores podem parecer incríveis, mas
a experiência mostra o contrário. Se você escolher qualquer trabalho de software de US$ 500.000
aleatoriamente, é provável que seja um trabalho de software de US$ 1.000.000 bem feito ou um trabalho de software de US$ 200.000 mal feito. O fato é que o custo do software geralmente
reflete mais diretamente a capacidade da equipe do que o tamanho
do trabalho real a ser feito.
Como já foi mencionado, o desempenho excepcional é possível
somente trabalhando de forma mais inteligente, não trabalhando mais duro. Ele requer técnicas
mais poderosas, tanto conceituais quanto organizacionais. A chave para o desempenho
excepcional é o controle intelectual, não apenas por indivíduos, mas por
uma organização inteira. Por esse motivo, as técnicas organizacionais de estruturação
do trabalho são tão importantes quanto as técnicas conceituais de estruturação de programas.
Em software, a única maneira de fazer mais trabalho é trabalhando de forma inteligente.
Quando as pessoas trabalham duro e por longas horas, elas começam a dar desculpas para
si mesmas, cometem erros e acabam fazendo muito retrabalho. E quando
elas estão fazendo retrabalho por causa de erros que elas desculpam porque
estavam trabalhando duro, isso se torna um ciclo vicioso. Depuração de programa é retrabalho,
não importa o que os programadores queiram pensar. Espero que novos programas
funcionem na primeira vez que forem testados e daí em diante. A depuração não só mostra
uma falta de concentração e integridade de design, mas também é um grande obstáculo à
produtividade. Se alguém escreve cem linhas de código em um dia e
depois leva duas semanas para depurá-lo, ele realmente escreveu apenas
dez linhas por dia.
As limitações finais para uma produtividade excepcional não são capacidade
ou conhecimento; as limitações são encontradas nas instituições sociais e empresariais
ao nosso redor. Essas limitações começam na escola, onde não é inteligente
ser muito inteligente porque isso dificulta para os outros alunos. Eles continuam
na indústria por meio de todos os tipos de arranjos formais e informais,
com pressão dos colegas para não aparecerem para os associados. Na engenharia de software,
onde os empregos geralmente são únicos e ninguém sabe seu tamanho real de qualquer maneira,
há uma motivação definitiva para inflar o tamanho dos empregos para fazê-los
parecer mais importantes. Os gerentes geralmente são pagos por quantas pessoas
eles gerenciam, em vez de quanto eles fazem com as pessoas que têm.
Mas essa é outra longa história em si.
