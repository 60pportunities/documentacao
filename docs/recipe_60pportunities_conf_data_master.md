"Quem nunca ouviu uma √°rea de neg√≥cio reclamar que precisa analisar alguma informa√ß√£o importante, mas que a devs/areas de desenvolvimento est√£o demorando muito pra entregar. Hoje, em uma conversa, disseram TCU."

- [x] **Falta dos respons√°veis pelos dados**: Quem s√£o os respons√°veis pelos dados?
- [x] **Problemas de Qualidade dos dados**: O time de infraestrutura √© respons√°vel pela qualidade, mas n√£o conhece os dados t√£o bem, pois n√£o est√£o intimamente ligados com o time de neg√≥cio.
- [x] **Escalabilidade Organizacional**: O time centralizado de ETL se torna o gargalo na democratiza√ß√£o dos dados na empresa.

Integridade de dados refere-se √† garantia de que os dados permanecer√£o precisos, inalterados e consistentes durante todo o seu ciclo de vida.

| **Caracter√≠stica**      | **Data Warehouse**                                          | **Data Lake**                                                  | **Data Mesh**                                               |
| :------ | :--------- | :-------- | :----|
| **Tipo de Dados**        | Dados estruturados                                          | Dados estruturados e n√£o estruturados                          | Dados distribu√≠dos, por dom√≠nio                              |
| **Processamento**        | ETL (Extra√ß√£o, Transforma√ß√£o e Carga antes do armazenamento)| ELT (Extra√ß√£o, Carga e Transforma√ß√£o ap√≥s o armazenamento)     | Processamento descentralizado por cada dom√≠nio               |
| **Objetivo Principal**   | An√°lises de Business Intelligence (BI) e relat√≥rios         | Armazenamento de grandes volumes de dados brutos para an√°lise posterior | Escalabilidade e autonomia na gest√£o de dados por dom√≠nio  |
| **Exemplo de Uso**       | Relat√≥rios financeiros, dashboards e KPIs                  | An√°lises de dados n√£o estruturados, machine learning, logs    | Grandes organiza√ß√µes com m√∫ltiplos departamentos e sistemas distribu√≠dos |
| **Escalabilidade**       | Limitada, pois depende de uma estrutura centralizada        | Alta, permite armazenamento de dados em grande escala         | Muito alta, cada dom√≠nio pode escalar independentemente      |
| **Governan√ßa**           | Centralizada, controlada por uma equipe de TI               | Menos rigorosa, exige boas pr√°ticas de governan√ßa              | Descentralizada, cada dom√≠nio gerencia seus pr√≥prios dados   |
| **Vantagens**            | Consultas r√°pidas, alta performance para BI                 | Flexibilidade no armazenamento de dados e baixo custo         | Autonomia, escalabilidade e alinhamento com as necessidades de neg√≥cios |
| **Desvantagens**         | Rigidez na estrutura de dados, dificuldades com dados n√£o estruturados | Governan√ßa e consultas podem ser mais dif√≠ceis de gerenciar    | Complexidade de gest√£o e padroniza√ß√£o entre os dom√≠nios     |
| **Tecnologias Comuns**   | Google BigQuery, Amazon Redshift, Snowflake, Microsoft SQL Server | Hadoop, Apache Spark, AWS S3, Azure Data Lake, Google Cloud Storage | Arquitetura distribu√≠da, com ferramentas como Kubernetes, Kafka, etc. |

## Arquitetura Integra√ß√£o de Dados
As arquiteturas de integra√ß√£o de dados tornam-se canais para coletar e fornecer insights sobre processos e dados de neg√≥cios.

## Arquitetura Integra√ß√£o de Dados
A economia digital colocou mais demanda por servi√ßos de dados dentro de uma organiza√ß√£o, sobrecarregando a TI para fornecer esses servi√ßos, acarretando uma prolifera√ß√£o de integra√ß√µes n√£o governadas na verdade piora na entrega e manuten√ß√£o da mesma.

Arquiteturas de integra√ß√£o de dados consistem em m√∫ltiplas tecnologias que tamb√©m podem ser alinhadas a outras √°reas, como gerenciamento de dados ou governan√ßa de dados. No entanto, vale a pena abordar essas tecnologias para e

As arquiteturas de integra√ß√£o de dados tornam-se canais para coletar e fornecer insights sobre processos e dados de neg√≥cios.

A integra√ß√£o de dados geralmente √© uma tarefa dentro de um projeto maior, sendo um m√©todo que fornece dados que podem suportar algum conjunto de requisitos de neg√≥cios, objetivando uma melhorara na efici√™ncia geral das organiza√ß√µes comerciais e t√©cnicas, validando efetivamente seus pipelines e resultados de dados e an√°lises.

Uma arquitetura de integra√ß√£o auxuliar√° a organizar as integra√ß√µes em um ambiente coerente e estruturado.

Para podermos iniciar o trabalho, foi necess√°rio efetuar um mapeamento dos dados mestres e refer√™mcia, propondo uma higieniza√ß√£o durante o processo de implanta√ß√£o de um novo sistema de Gest√£o Empresarial. Nosso objetivo foi a promo√ß√£o da higieniza√ß√£o, designa√ß√£o do gestor, background check e seus metadados.

Foram identificados neste trabalho, ciclos viciosos de desenvolvimento em uma arquitetura acidental,que n√£o garantiam a qualidade dos dados, aumentavam as d√≠vida t√©cnica e de processo. 

Eventualmente, surgem perguntas sobre como os resultados foram derivados, a qualidade dos dados, a fonte dos dados e por que as mesmas m√©tricas t√™m resultados diferentes em diferentes opera√ß√µes de neg√≥cios.


Uma arquitetura de integra√ß√£o de dados consiste nas tecnologias, dados e padr√µes, processos de neg√≥cios, necessidades de armazenamento e requisitos operacionais que permitem a entrega da integra√ß√£o de dados.

| Requisitos             | Tecnologia   | Design               | Implementa√ß√£o       | Monitoramento |
| -----                  | ----         | ----                 | -----               | ----          |
| Dados Estruturados     | Mensageria   | Replica√ß√£o           | Data Pipeline       | Custo         |
| Dados N√£o Estruturados | ETL/ELT/ETLT | Prepara√ß√£o           | Integra√ß√£o Metadata | Adminitra√ß√£o  |
| Processos de Neg√≥cio   | Orquestra√ß√£o | Transforma√ß√£o        | Armazenagem         | Suporte       |
| Metadata               | DatOps       | Orquestra√ß√£p         |                     |               |
| Temporalidade          | Cataloga√ß√£o  | ETL/ELT/ETLT         |                     |               |
| Performance            |              |  Pipeline Integra√ß√£o |                     |               |

## Base de governan√ßa de dados e gerenciamento de informa√ß√µes: 
Crie uma base de governan√ßa de dados e gerenciamento de informa√ß√µes para dar suporte ao gerenciamento de dados mestres e gerenciamento de metadados para dar suporte a casos de uso de governan√ßa de dados e an√°lises; desenvolva novas habilidades e pr√°ticas recomendadas; e estabele√ßa seguran√ßa, privacidade e conformidade no gerenciamento de dados.

## Arquitetura e moderniza√ß√£o de gerenciamento de dados: 
Implante uma infraestrutura de gerenciamento de dados escal√°vel e confi√°vel e arquitete a arquitetura de dados moderna mais adequada, incluindo gerenciamento de dados local, nativo da nuvem e h√≠brido para oferecer suporte a volume, velocidade e variedade de dados extremos.

## Princ√≠pios e implanta√ß√µes de gerenciamento de dados
Selecione, projete, implante e operacionalize sistemas de gerenciamento de dados usando tend√™ncias emergentes em armazenamentos de dados para fins especiais, como armazenamentos n√£o relacionais, gr√°ficos e de objetos, e migre bancos de dados para executar cargas de trabalho h√≠bridas, multicloud e de borda.

## Integra√ß√£o de dados de √∫ltima gera√ß√£o
Desenvolva as melhores pr√°ticas e arquitetura para integra√ß√£o de dados, aproveitando os princ√≠pios de engenharia de dados e as tecnologias de virtualiza√ß√£o de dados para oferecer suporte a casos de uso de streaming em lote e em tempo real.

## Design de integra√ß√µes usando m√©todos apropriados
O design de uma arquitetura de integra√ß√£o pega os processos de neg√≥cios definidos e os traduz em pipelines de integra√ß√£o. As fontes de dados e processos se tornam o pipeline de integra√ß√£o; o uso de dados e os tipos de dados se tornam os m√©todos de integra√ß√£o e transforma√ß√µes; e a usabilidade e o acesso aos dados se torna

Insights sobre formatos de dados, uso dos dados, m√©todos de armazenamento,  podem determinar o m√©todo de integra√ß√£o.

Processos de neg√≥cios e regras de transforma√ß√£o

As perguntas a serem respondidas pelos requisitos do processo incluem:

| Perguntas                                                | Perguntas                                              |
| -----                                                    | ----                                                   |
| Qual √© a fonte dos dados ?                               | Existe algum Org√£o regulador? H√° contratos?            |
| Quem criar√° os dados?                                    | Quem poder√° ler, consultar ou manter?                  |
| Dados hist√≥ricos dever√£o ser mantidos, por quanto tempo? | Dados hist√≥ricos precisar√£o ser modificados?           |
| Quais os tipos de valida√ß√µes, ser√£o necess√°rias?         | Como os dados ser√£o usados?                            |
| Que tipo de metadados devem ser capturados?              | Como os usu√°rios consumir√£o/acessar√£o os dados finais? |

Os metadados cont√™m as informa√ß√µes necess√°rias para fornecer informa√ß√µes sobre defini√ß√µes de dados ou dicion√°rios, linhagem de dados, pipelines de dados para usu√°rios corporativos e desenvolvedores. 
Esses tipos incluem metadados operacionais (relacionados a opera√ß√µes da arquitetura de integra√ß√£o, como tempos de execu√ß√£o de pipeline, n√∫mero de falhas, transforma√ß√µes, agrega√ß√µes e jun√ß√µes executadas em dados) e metadados de neg√≥cios (como dicion√°rios de dados e linhagem).

## M√©todos de integra√ß√£o
Existem v√°rios m√©todos de integra√ß√£o de dados, dependendo do formato, caso de uso e volume. H√° plataformas de integra√ß√£o que fornecem recursos que v√£o al√©m de apenas extrair, transformar e carregar (ETL/ELT/ETLT), como cat√°logos de dados, recursos de IA, governan√ßa de dados e suporte a DataOps, integra√ß√£o de fluxo ou virtualiza√ß√£o.

| T√©cnica de Integra√ß√£o | Descri√ß√£o                                                                                   | 
| -----                 | ----                                                                                        |
| Replica√ß√£o            | Pode ser considerada a forma mais b√°sica de integra√ß√£o, pois envolve a c√≥pia direta de dados de um sistema para outro. |
| Virtualiza√ß√£o         | Executa consultas em v√°rias fontes de dados para criar visualiza√ß√µes virtuais integradas de dados sob demanda.         | 
| ETL/ELT               | Os dados de origem s√£o extra√≠dos e podem ser gravados como um arquivo em lote ou processados em tr√¢nsito, aproveitando uma ferramenta ou plataforma de integra√ß√£o de dados.|
| ETLT                  | Mesmos conceitos fundamentais de ETL, porem, o processo de integra√ß√£o envolve v√°rias etapas de extra√ß√£o, transforma√ß√£o e carga, e tamb√©m pode incluir etapas adicionais de carregamento e transforma√ß√£o. |
| Stream Data Processing| √â um m√©todo para ingerir, integrar e processar dados em tempo real assim que s√£o produzidos. A lat√™ncia entre a cria√ß√£o e o processamento de dados √© extremamente baixa em compara√ß√£o ao processamento em lote. |

## Plataformas de integra√ß√£o
As plataformas de integra√ß√£o visam ser uma plataforma √∫nica para recursos de dados. 
Com as permiss√µes e acesso adequados, os usu√°rios podem acessar dicion√°rios de dados, entender a precis√£o e a qualidade dos dados, integrar dados mestres, visualizar a linhagem de dados e ver transforma√ß√µes, valida√ß√µes e quaisquer consolida√ß√µes de dados at√© a fonte. 

## Scheduler e Workflow Manager
O agendamento de pipeline de integra√ß√£o e o gerenciamento de fluxo de trabalho, como execu√ß√£o de frequ√™ncia de trabalhos, alertas e automa√ß√£o s√£o padr√£o, definidas nestas plataformas.

## Cat√°logos de dados
Os cat√°logos de dados armazenam metadados, tanto operacionais quanto comerciais, que complementam as transforma√ß√µes de dados ou an√°lises para visualizar a jornada de dados.

CI/CD, DataOps, Orquestra√ß√£o
Orquestra√ß√£o √© o processo de cria√ß√£o de uma unidade l√≥gica de pipelines de dados relacionados, fluxos de trabalho e componentes associados que produzem os conjuntos de dados desejados, incluindo seus artefatos (por exemplo, metadados, dicion√°rio de dados, qualidade de dados e estat√≠sticas de valida√ß√£o).

HA, DR, Escalabilidade
O foco principal em alta disponibilidade (HA) e recupera√ß√£o de desastres (DR) √© manter o sistema operacional o tempo todo. No entanto, a principal diferen√ßa √© que a HA aborda o problema enquanto o sistema √© executado, enquanto a DR entra depois que ele falha. 

Independentemente de qu√£o altamente dispon√≠vel um sistema seja, qualquer aplicativo de produ√ß√£o precisa ter planos de recupera√ß√£o de desastres, pois alta disponibilidade e recupera√ß√£o de desastres n√£o s√£o mutuamente exclusivas.

## Integra√ß√£o
A implementa√ß√£o depender√° das fun√ß√µes e recursos da ferramenta, que deveriam ter sido avaliados.

- [x] Qual a melhor forma de implementar o CDC e onde?
- [x] Como lidamos com dados atrasados/duplicados?
- [x] Em caso de falha do pipeline, o processo deve ser executado novamente ou precisa continuar de onde falhou? Quais verifica√ß√µes de integridade de dados s√£o necess√°rias?
- [x] Como acompanhamos as m√©tricas e monitoramos os pipelines de qualidade de dados (DQ)/SLAs?
- [x] Como maximizamos o desempenho ‚Äî taxa de transfer√™ncia ou lat√™ncia?
- [x] Como orquestramos pipelines de dados de ponta a ponta?
- [x] Como podemos depurar a l√≥gica de transforma√ß√£o em um ambiente altamente distribu√≠do?
- [x] Como o sistema lida com a propaga√ß√£o de altera√ß√µes upstream?
- [x] Como gerenciamos a configura√ß√£o e o estado do pipeline?
- [x] Como a reutiliza√ß√£o ser√° gerenciada/integrada √†s equipes de desenvolvimento?
- [x] Qual √© o processo de implanta√ß√£o?
- [x] O que √© o ambiente de desenvolvimento?
- [x] Como o aterro ser√° realizado?
- [x] Como implementamos pipelines de dados orientados por metadados?

| Tipo               | Descricao |
| ----               | ----      |
| Microlotes         | Divide o conjunto de dados resultante em lotes menores, agendando as extra√ß√µes v√°rias vezes ao longo do dia e da noite.  |
| Integra√ß√£o em lote | M√©todo tradicional, onde o processo come√ßa assim que todos os dados a serem integrados s√£o identificados, seja de um arquivo ou consultando o sistema de origem.  |
| Streaming de eventos  | Fluxos de eventos de alta frequ√™ncia que precisam ser processados dentro de SLAs muito r√≠gidos ‚Äì por exemplo, na detec√ß√£o de fraudes, monitoramento de rede, consist√™ncia transacional ou monitoramento da cadeia de suprimentos ‚Äì podem aproveitar o streaming de eventos. √Ä medida que os eventos s√£o processados no pipeline do fluxo de eventos, eles podem ser mesclados/atualizados/adicionados aos dados hist√≥ricos armazenados para an√°lise em tempo real. |
| Virtualiza√ß√£o | M√©todo eficaz para combinar fontes de dados diferentes em uma √∫nica camada de acesso sem precisar mover dados fisicamente. |
| Replica√ß√£o    | M√©todo que pega os dados da origem e os copia diretamente para o destino especificado. |
|

## Armazenamentos de dados e modelos de dados
Do ponto de vista da integra√ß√£o de dados, os armazenamentos de dados podem servir a v√°rias finalidades. Eles podem ser uma √°rea central que armazena todos os dados de origem em v√°rios formatos, armazenamentos intermedi√°rios para dados processados, armazenamentos tempor√°rios para integra√ß√µes e agrega√ß√µes tempor√°rias ou o produto de dados final em que os dados est√£o prontos para serem consumidos pelos usu√°rios finais.

- [x] Os dados residir√£o em uma tabela existente ou em uma nova tabela?
- [x] Como os dados ser√£o usados?
- [x] Existem preocupa√ß√µes com a seguran√ßa dos dados/informa√ß√µes de identifica√ß√£o pessoal (LGPF, GPDR, HIPAA)?
- [x] A quais dimens√µes os dados ser√£o associados se empregar um esquema em estrela?
  
## Fluxo de trabalho de agendamento e integra√ß√£o
Os pipelines de integra√ß√£o precisar√£o de alguma forma de agendamento para serem executados em um agendamento ou janela designada. Alguns pipelines de integra√ß√£o tamb√©m ter√£o depend√™ncias de outros pipelines antes de serem executados. 

O desenvolvimento da ingest√£o de dados √© a base para a extra√ß√£o de dados de sistemas de dados de origem e orquestra√ß√£o de diferentes m√©todos de integra√ß√£o de gerenciamento de dados.

## Monitorar/Suporte
M√©tricas bem definidas podem ser aproveitadas para avaliar a qualidade dos dados. M√©tricas operacionais sobre tempo de atividade, tempo defuncionamento, tempo para resolver problemas e monitoramento proativo de poss√≠veis problemas tamb√©m podem ser coletadas.

Os aspectos de administra√ß√£o podem exigir a integra√ß√£o de novas administra√ß√µes e suporte ao conhecimento de novas ferramentas de integra√ß√£o e metodologias de desenvolvimento, como implanta√ß√£o r√°pida. Existem duas √°reas distintas de administra√ß√£o de suporte: a administra√ß√£o de infraestrutura, opera√ß√µes e aplicativos e a administra√ß√£o dos pipelines de integra√ß√£o e aplicativos relacionados.

```mermaid
flowchart LR
DS[(Data Source)] & newLines["`Data
    Sources`"] --> |Pull/Push| id1(Ferramentas</br>Ingest√£o)
    id1 --> id2(Processamento</br>de dados)
    id2 --> id3(Armazenamento</br>de dados)
    id3 --> id4(Consumo</br>de dados)
```

## Plataforma de Dados
Implantar a plataforma de dados significa abrir as v√°lvulas para permitir a entrada dos dados (lote/streaming).
Essa deve ser a √∫ltima etapa da implanta√ß√£o e deve ser feita no final do provisionamento da plataforma de processamento/ingest√£o.

- [x] Verifique se o armazenamento de dados √© provisionado com pol√≠ticas de capacidade/acesso a dados.
- [x] Verifique se um agente de streaming est√° provisionado e pronto.
- [x] Verifique as qualidade dos dados s√£o implantadas;
- [x] Orquestra√ß√£o de dados seja provisionada;
- [x] Ferramentas de gerenciamento e controle de vers√£o do ciclo de vida dos dados estejam implantadas e prontas.
- [x] Ferramentas de detec√ß√£o de descompasso de dados estejam em vigor e ativas.
- [x] Defina m√©tricas a serem monitoradas em cada camada.
- [x] Defina o intervalo normal de m√©tricas.
- [x] Armazene m√©tricas em um reposit√≥rio de configura√ß√£o.
- [x] Selecione ferramentas para monitoramento e observabilidade de dados ‚Äî n√£o h√° uma ferramenta √∫nica.
- [x] Obtenha respostas para estas perguntas no sistema de monitoramento:
    - [x] O processamento/ingest√£o de dados est√° ocorrendo na taxa/lat√™ncia esperada?
    - [x] Existem problemas de qualidade de dados na ingest√£o, postagem, pr√©-processamento e p√≥s-processamento?
    - [x] As vari√°veis de ambiente/sistema/aplicativo s√£o otimizadas para o fluxo e o processamento de dados?
- [x] Realize o monitoramento de esquema.
- [x] Realize o monitoramento da qualidade dos dados.
- [x] Taxas de transfer√™ncia;
- [x] Taxas de erro;
- [x] Tempo de execu√ß√£o por est√°gio;
- [x] Erros de estrutura;
- [x] Detec√ß√£o de informa√ß√µes de identifica√ß√£o pessoal (PII);
- [x] Alertas de desvio de esquema;
- [x] Alertas de desvio sem√¢ntico;
- [x] M√©tricas de execu√ß√£o de trabalho e metadados correspondentes;
- [x] O tempo para iterar representa a capacidade de entender, monitorar e depurar pipelines existentes e criar novos;
- [x] Hora de implantar;
- [x] Hora de resolver problemas;
- [x] Frequ√™ncia de implanta√ß√£o;
- [x] Tempo m√©dio de restaura√ß√£o (MTTR);
- [x] Prazo de entrega para altera√ß√µes;
- [x] Hora de restaurar os servi√ßos;
- [x] Taxa de falha de altera√ß√£o;

## Automa√ß√£o

## Avaliando as op√ß√µes de arquitetura para bancos de dados multicloud
As arquiteturas centradas em dados multicloud s√£o complexas.

### O que √© multicloud?
No contexto de arquiteturas multicloud, √© √∫til entender a distin√ß√£o entre "h√≠brido" e "intercloud":
- [x] H√≠brido refere-se a componentes locais que s√£o combinados com componentes baseados em nuvem.
- [x] Intercloud refere-se a componentes de solu√ß√£o baseados em nuvem que est√£o sendo implantados em v√°rios ambientes de nuvem.

![](img/multicloud.png)

## Data Lake

- [x] **Transient/Staging**: Camada onde os dados s√£o recebidos e armazenados em seu formato original.
- [x] **Bronze/Raw**: Camada onde os dados s√£o transformados para um formato padronizado e carregados no data lake.
- [x] **Silver/Trusted**: Camada onde os dados s√£o limpos, corrigidos e enriquecidos com metadados.
- [x] **Gold/Refined**: Camada onde os dados s√£o preparados para an√°lise e visualiza√ß√£o.
- [x] **Sandbox**: Camada onde os dados s√£o usados para desenvolvimento, testes e experimenta√ß√£o.

![](img/post_camadaslake_img01.jpg)

### Existem tr√™s grupos principais em um ecossistema de dados moderno:

- [x] **Produtores de dados**: Os especialistas de dom√≠nio que possuem os sistemas ou fontes de dados recebidos (pedidos, faturas, invent√°rio e assim por diante).
- [x] **Construtores de Plataforma de Dados**: Um segmento da equipe de TI com diversas habilidades de dados, dependendo da maturidade da empresa.
- [x] **Consumidores de Dados**: Analistas e operadores que usam dados para otimizar os neg√≥cios, tomar decis√µes e definir estrat√©gias.

## Data Mesh (Zhamak Dehghani)
<p align="justify">O gerenciamento √© conduzido no n√≠vel da unidade, onde os indiv√≠duos mais familiarizados com os dados em suas respectivas √°reas determinam os m√©todos de processamento ideais. Sua proximidade com os dados e familiaridade com os requisitos permitem que eles garantam sua qualidade.</p>

Responsabilidade das unidades individuais que produzem os dados.

<p align="justify">Capacitar equipes de dom√≠nio para assumir a responsabilidade por seus pr√≥prios produtos de dados e garantir que os princ√≠pios de governan√ßa, como qualidade e seguran√ßa de dados, sejam respeitados.</p>

<p align="justify">A organiza√ß√£o precisa dar suporte a uma mudan√ßa cultural em que as equipes de dom√≠nio sejam capacitadas para assumir a propriedade de seus pipelines de dados e entregar dados como um produto.</p>

<p align="justify">Uma infraestrutura robusta de ferramentas de dados de autoatendimento √© essencial, permitindo que as unidades de neg√≥cios consumam, analisem e obtenham insights de dados de forma independente.</p>

<p align="justify">O Data Mesh oferece um novo paradigma para cumprir o valor prometido dos dados. Ela rejeita padr√µes de longa data arquiteturas de dados centralizadas, como o `data lake` e o `data warehouse` e seus associados equipes centralizadas. Em vez disso, ele descentraliza tanto a propriedade dos dados quanto os dados em si, transferindo-os para os dom√≠nios funcionais que criam e usam dados para administrar seus neg√≥cios.</p>

Seus quatro pilares:

- [x] **Propriedade de dom√≠nio**: Uma equipe de dom√≠nio est√° pr√≥xima dos principais processos de neg√≥cios, conhece os dados que o dom√≠nio produz e as an√°lises que seus stakeholders precisam para resolver problemas e capitalizar oportunidades.
- [x] **Dados como um produto**: Os produtos de dados consistem em mais do que apenas dados. Eles incluem c√≥digo para coletar e transformar dados e habilitar acesso gerenciado por meio de APIs. Eles incluem metadados que descrevem o produto, como esquema, sem√¢ntica e m√©tricas de qualidade.
- [x] **Plataforma de dados self-service**: As equipes de dom√≠nio precisam de uma plataforma de autoatendimento para entregar e gerenciar dados produtos. Eles precisam provisionar infraestrutura de armazenamento e computa√ß√£o, construir, implantar e gerenciar vers√µes de produtos de dados, limpar e transformar dados, fornecer acesso seguro a dados e cumprir pol√≠ticas e regulamenta√ß√µes.
- [x] **Governan√ßa computacional Federada**: √ìrg√£o federado composto por representantes de equipes de dom√≠nio e aqueles com responsabilidades globais de dados, como conformidade regulat√≥ria e gerenciamento de qualidade. Preocupa√ß√µes comuns, como o que constitui qualidade,classifica√ß√µes de dados e como lidar com diferentes n√≠veis de sensibilidade, modelagem de dados que abrangem dom√≠nios e padr√µes para metadados de produtos de dados.

A malha de dados (Data Mesh) aborda essas dimens√µes, fundadas em quatro princ√≠pios:

- [x] **Arquitetura de dados descentralizada orientada ao dom√≠nio**:
    - [x] Os diferentes dom√≠nios de negocios (produtores de dados) sao responsaveis ‚Äã‚Äãpor curar, validar, publicar, manter e gerenciar o ciclo de vida dos dados que possuem.
    - [x] Data lakes que s√£o gerenciados centralmente pela TI;
- [x] **Dados disponibilizados como produto**:
    - [x] Em um data lake t√≠pico, o data lake e os pipelines de dados s√£o o produto. Em uma malha de dados, os dados e o dom√≠nio e a expertise do produtor que re√∫ne e publica os dados s√£o o produto.
    - [x] Cada dom√≠nio deve ter um propriet√°rio do produto de dados, respons√°vel por garantir que os dados sejam entregues como um produto.
    - [x] Qualidade de dados, menor tempo de espera de consumo de dados e, em geral, satisfa√ß√£o do usu√°rio de dados.
    - [x] Quem s√£o os usu√°rios dos dados;
- [x] **Infraestrutura para disponibilizar os dados como self-service**: (Plataforma de dados self-service)
    - [x] armazenamento de dados escal√°vel;
    - [x] esquema de produtos de dados;
    - [x] constru√ß√£o e orquestra√ß√£o de pipeline de dados;
    - [x] linhagem de dados;
- [x] **Controle de acesso granular e escal√°vel**
    - [x] Os produtores especificam pol√≠ticas de acesso, governan√ßa e reten√ß√£o e quaisquer pol√≠ticas de acesso personalizadas com base na granularidade dos dados.
    - [x] Interoperabilidade por meio de padroniza√ß√£o global,
    - [x] Topologia din√¢mica;

## Quais ferramentas:

- [x] Dataflow:
    - [x] Google Cloud Dataflow
    - [x] AWS Data Pipeline/AWS Glue/Amazon Kinesis Data Streams
    - [x] Azure Data Factory/Azure Stream Analytics
    - [x] Oracle Cloud Data Flow
    - [x] Snowflake Data Cloud
    - [x] Apache Kafka
    - [x] Apache Nifi
    - [x] Apache Airflow e porque n√£o Rundeck.
- [x] Data Catalog:
    - [x] [Google Cloud Data Catalog](https://cloud.google.com/data-catalog/docs/concepts/overview?hl=pt-br)
    - [x] [Microsoft Azure Purview](https://learn.microsoft.com/pt-br/purview/purview)
    - [x] [DataHub](https://datahubproject.io/)
    - [x] [Metacat](https://github.com/Netflix/metacat)
    - [x] [Egeria](https://egeria-project.org/)
## Por onde come√ßar?

- [x] Mapeie os dom√≠nios da sua organiza√ß√£o;
- [x] Avalie os impulsionadores do neg√≥cio e comece pequeno (Agencias do Banco do Brasil e Terceiros);
- [x] Defina padr√µes de produtos de dados;
- [x] Atribuir propriet√°rios de produtos de dados;
- [x] Crie a plataforma de dados de autoatendimento;

## Definida onde queremos
- [x] Defina uma estrat√©gia de dados;
      - [x] Qual √© a natureza dos dados?
             - [x] Diferenciar informa√ß√µes sens√≠veis (como dados de clientes ou funcion√°rios) de informa√ß√µes n√£o sens√≠veis (como informa√ß√µes de produtos).
      - [x] Quando os dados foram criados ou alterados?
      - [x] Quem realizou opera√ß√µes nos dados?
      - [x] Por que esses dados est√£o sendo armazenados? (Dados pessoais devem ser armazenados apenas para um prop√≥sito comercial leg√≠timo.)
      - [x] Quanto tempo esses dados est√£o sendo armazenados?
      - [x] Como esses dados est√£o sendo usados?
             - [x] Descrever todos os aplicativos que t√™m depend√™ncia desses dados.
- [x] Desenvolver um modelo de governan√ßa;
- [x] Avalie a maturidade do Agile e do DevOps;
- [x] Plataformas de design e padr√µes t√©cnicos.

# Gerenciamento de Dados
<p align="justify">√â uma estrat√©gia usada por organiza√ß√µes para tornar os dados seguros, eficientes e dispon√≠veis para quaisquer prop√≥sitos comerciais relevantes.</p>

<p align="justify">Gerenciamento de dados se refere tanto a processos quanto a tecnologia. Processos s√£o geralmente definidos pela estrutura de governan√ßa de dados da organiza√ß√£o, e cada um desses processos √© implementado com as ferramentas de software relevantes.</p>

## Estrat√©gia de Gerenciamento de Dados
### Defini√ß√£o

 - [x] Resumo da estrat√©gia corporativa e de neg√≥cios;
 - [x] N√≠veis de maturidade atuais e desejados da an√°lise de dados;
 - [x] Vis√£o, miss√£o e valores da an√°lise de dados;
 - [x] Objetivos estrat√©gicos e KPIs para atingir nossa vis√£o;
 - [x] Equipe e or√ßamento;
 - [x] Princ√≠pios orientadores.

### Maturidade

- [x] Gerenciamento e infraestrutura de dados;
      - [x] Qual/is as fontes e aquisi√ß√£o de dados?
      - [x] Como avalio a qualidade e limpeza de dados?
      - [x] Como s√£o as solu√ß√µes de armazenamento e processamento de dados?
      - [x] Como fa√ßo a Integra√ß√£o, Transforma√ß√£o e Disponibiliza√ß√£o?
      - [x] Como fa√ßo a escalabilidade e desempenho da infraestrutura de dados?
      - [x] Quais s√£o as Tecnologias em gest√£o e infraestrutura de dados?
      - [x] Como posso avaliar se a implementa√ß√µes foi/esta bem-sucedida?
- [x] Governan√ßa e conformidade de dados
      - [x] Como a governan√ßa de dados permite que uma organiza√ß√£o se torne orientada por dados?
      - [x] Como DIVIDIR, os dados e dividir a responsabilidade da governa√ß√£o de dados?
      - [x] Como tratar a quest√£o da privacidade e seguran√ßa de dados?
      - [x] Como gerir a conformidade de dados?
      - [x] Como estabelecer a defini√ß√£o de √©tica de dados e seu uso respons√°vel?
      - [x] Como implementar a governan√ßa e conformidade de dados?
- [x] Ferramentas e t√©cnicas de an√°lise;
      - [x] Como padronizar e estabelecer o uso de ferramentas e t√©cnicas de visualiza√ß√£o de dados?
      - [x] Como padronizar e estabelecer o uso de modelos e t√©cnicas de an√°lise estat√≠stica?
      - [x] Como padronizar e estabelecer o uso de Ferramentas e t√©cnicas de Machine learning?
      - [x] Como padronizar e estabelecer o uso de Ferramentas e t√©cnicas de big data?
      - [x] Como padronizar e estabelecer o uso de Ferramentas e t√©cnicas de prepara√ß√£o de dados?
      - [x] Como padronizar e estabelecer o uso de Matriz de sele√ß√£o de ferramentas anal√≠ticas?
- [x] Organiza√ß√£o orientada a dados
      - [x] Como posso afirmar, que a organiza√ß√£o EST√Å orientada √Ä dados?
      - [x] Como posso construindo uma cultura baseada em dados na organiza√ß√£o?
      - [x] Como podemos criar uma infraestrutura de dados f√°cil de usar, consumir e distribuir?
      - [x] Como podemos fomentar a experimenta√ß√£o e a inova√ß√£o, com os Dados?


|  Dimens√£o                               | Emergente - N√≠vel 1  | Pr√©-Ado√ß√£o N√≠vel 2    | Areas - N√≠vel 3    | Corporativa- (N√≠vel 4)  | Maduro - (N√≠vel 5)  |
|  -------                                | -------  |   -------  |   -------  |   -------   |   -------  |
| Governan√ßa e conformidade de dados      |          |            |            |             |            |
| Gerenciamento e infraestrutura de dados |          |            |            |             |            |
| Ferramentas e t√©cnicas de an√°lise       |          |            |            |             |            |
| Organiza√ß√£o orientada a dados           |          |            |            |             |            |

#### Estrat√©gia de Dados

| Estrat√©gia   | Entenda |
| -----        | -----   |
| Ingest√£o | Os dados devem ser adquiridos de fontes confi√°veis, como bancos de dados de produ√ß√£o ou terceiros confi√°veis. |
| Data Lineage | Linhagem de dados √© o nome de um tipo espec√≠fico de metadados que cont√©m o hist√≥rico completo de seu assunto. Metadados de linhagem descrevem a origem dos dados aos quais se referem e fornecem detalhes de quaisquer opera√ß√µes desde o in√≠cio. A linhagem de dados funciona como um tipo de changelog para esses dados, registrando cada opera√ß√£o que ocorreu. |
| Acesso  | Supervisionar a cria√ß√£o de fun√ß√µes de usu√°rio e garantir que cada usu√°rio receba acesso de leitura e grava√ß√£o apropriados. |
| Integra√ß√£o | Processo de pegar dados de v√°rias fontes diferentes e agrup√°-los em um √∫nico local. Processos: ETL, ELT, ETLT. |
|            | Valida√ß√£o : verificar a precis√£o dos dados comparando-os a um esquema. |
|            | Consolida√ß√£o : centralizar o armazenamento de dados para melhorar a efici√™ncia ou armazenar big data de forma mais econ√¥mica. |
|            | Habilita√ß√£o de processo: novo processo que s√≥ √© poss√≠vel com uma fonte de dados integrada. |
|            | Gerenciamento de dados mestres (MDM) : t√©cnicas de integra√ß√£o para produzir dados mestres. |
|            | An√°lise e intelig√™ncia empresarial (BI) : fonte de dados unificada para fins de an√°lise, bem como outras aplica√ß√µes de BI. |
| Metadados  | Reunir e indexar metadados relevantes, e que esses metadados estejam dispon√≠veis quando necess√°rio.
| Conformidade | Gerenciamento de dados deve refletir todos os requisitos regulat√≥rios e garantir que a organiza√ß√£o permane√ßa no lado certo da lei. (LGPD (Regulamento Geral de Prote√ß√£o de Dados), PCI DSS (Padr√£o de Seguran√ßa de Dados do Setor de Cart√µes de Pagamento), HIPAA (Portabilidade e Responsabilidade de Seguro Sa√∫de)) e SOX (Sarbanes-Oxley) |
| An√°lise  | an√°lises para impulsionar suas tomadas de decis√£o. uporte aos esfor√ßos do tempo de an√°lise e garantir que os dados dispon√≠veis sejam oportunos, relevantes e completos. |
| Seguran√ßa | Gerente de dados √© respons√°vel por trazer problemas de seguran√ßa √† tona e tamb√©m por organizar auditorias e testes regulares.  |
| Arquivamento | Recomendar√° solu√ß√µes preferenciais para que a organiza√ß√£o tenha uma abordagem unificada para armazenamento de dados de longo prazo. |
| Efici√™ncia | Revisar regularmente sua estrat√©gia de gerenciamento de dados para perguntar se a abordagem atual √© econ√¥mica e sustent√°vel. |
| Escala     | gerenciamento de dados deve planejar escalar facilmente quando necess√°rio.(ex."IoT,Logs) |

### BuzzWord - Organizacional e Estrat√©gia de IA
<div class="mdx-columns2" markdown>
- [x] Resumo da estrat√©gia corporativa e de neg√≥cios
- [x] Fundamentos da IA
- [x] N√≠veis de maturidade atuais e DESEJADOS da IA
- [x] Vis√£o, miss√£o e valores da IA
- [x] Objetivos estrat√©gicos e KPIs para atingir nossa vis√£o
- [x] Princ√≠pios orientadores
- [x] Centro de dados de IA
- [x] Machine Learning/Deep Learning
- [x] NLP(Natural Language Processing) & Prompt Engineering
- [x] Equipe e Or√ßamento
</div>

#### Delivery e Responsibility
<div class="mdx-columns2" markdown>
- [x] Estrat√©gia de gerenciamento de mudan√ßas
- [x] Planos de gerenciamento de mudan√ßas
- [x] Avalia√ß√£o p√≥s-programa/projetos mudan√ßas e como reuno(PDCA) li√ß√µes aprendidas
- [x] An√°lise dos stakeholders
- [x] Estrat√©gia de engajamento dos stakeholders
- [x] Plano detalhado de engajamento dos stakeholders
</div>


```mermaid
flowchart LR
    A(Meus Dados</br>s√£o...) -->|Dados| B{Regulamentados}
    B --> |Sim| C(PCI DSS) & D(LGPD) & E(HIPAA) & F(SOX)
    B --> |N√£o| G{Ret√≠vel?}
    G --> H{Necessita</br>Criptografia?}
    H --> |Sim| H0(Criptografa)
    H --> H1(Tag de</br>Reten√ß√£o)
    H0 --> H1 --> RETER[(Reten√ß√£o)]
    C --> H0 --> ARQUIVA[(Arquiva)]
    D --> H0
    E --> H0
    F --> H0
```

## Data Mesh vs. Data Fabric
- [x] Data Fabric √© uma solu√ß√£o centralizada e orientada por tecnologia, que visa criar uma plataforma unificada para gerenciar e acessar dados onde quer que eles residam.
- [x] Data Mesh, por outro lado, descentraliza os dados e sua propriedade.
- [x] Em um data mesh equipes individuais ou unidades de negocios sao responsaveis ‚Äã‚Äãpor seus pr√≥prios dados e sao encarregadas de criar produtos de dados, para seu proprio consumo e presumivelmente o consumo de outros na organizacao.

## Dados Links
### Linhagem de Dados
<div class="mdx-columns2" markdown>
- [x] [SAS](https://www.sas.com/)
- [x] [Inform√°tica](https://www.informatica.com/)
- [x] [Octopai](https://www.octopai.com/) Adquirida recentemente pela [Cloudera](https://www.cloudera.com/about/news-and-blogs/press-releases/2024-11-14-cloudera-to-acquire-octopais-platform.html)
- [x] [Datahub](http://datahub.io/)
</div>

### Dados Abertos
<div class="mdx-columns2" markdown>
- [x] [Microdados ENEM](http://portal.inep.gov.br/microdados)
- [x] [Portal Brasileiro de Dados Abertos](http://dados.gov.br/)
- [x] [NASA](http://data.nasa.gov/)
- [x] [The World Bank](http://data.worldbank.org/)
- [x] [United States Government](http://www.data.gov/)
</div>

![](img/data-engenharia.png)

# Conceitos
## Fundamentais

- [x] Modularidade: Deve ser constru√≠da com componentes independentes que se integram facilmente, promovendo flexibilidade e escalabilidade.
- [x] Data as a Product: Cada conjunto de dados √© tratado como um produto, com ‚Äúdonos‚Äù respons√°veis, SLAs definidos e interfaces claras para consumo.
- [x] Interoperabilidade: Capaz de suportar diferentes tecnologias e padr√£o para facilitar integra√ß√£o.
- [x] Replicabilidade: Processos como ingest√£o de dados, transforma√ß√£o e monitoramento devem ser automatizados para reduzir erros e aumentar a efici√™ncia.
- [x] Seguran√ßa e Governan√ßa: Prote√ß√£o de dados, rastreabilidade e conformidade regulat√≥ria s√£o fundamentais e n√£o podem ficar de fora.

## Componentes Importantes

- [x] Sources: Pontos de origem dos dados, como bancos de dados transacionais, APIs, logs.
- [x] Ingestion: Ferramentas para capturar e transferir dados de fontes para ambiente de armazenamento.
- [x] Storage: Foco em armazenamento de dados em formatos brutos e tamb√©m estruturado e otimizado para an√°lises.
- [x] Processing: Processamento em lote (batch) e em tempo real (streaming).
- [x] Transformation (ETL/ELT): Prepara√ß√£o e transforma√ß√£o e limpeza dos dados usando pipelines.
- [x] Governance & Metadata Management: Controle de qualidade, cat√°logo de dados e gerenciamento de metadados.
- [x] Orchestration: Coordena√ß√£o de workflows de dados.
- [x] Consumption: Interfaces e ferramentas para acessar dados em dashboards.
- [x] Monitoring & Observability: Rastreamento de desempenho, lat√™ncia e falhas.
- [x] Security & Compliance: Criptografia, autentica√ß√£o (IAM) e controle de acessos.

# Tools
‚û§ Ab Initio
‚Ü≥ Gerenciamento abrangente de dados com recursos avan√ßados de qualidade de dados.
‚Ü≥ Principais recursos: An√°lise automatizada de dados, defini√ß√£o de regras, emiss√£o de t√≠quetes, controle centralizado.

‚û§ Qualidade de dados SAS
‚Ü≥ Melhora a precis√£o, consist√™ncia e integridade dos dados com ferramentas abrangentes.
‚Ü≥ Principais recursos: Perfil de dados, fus√£o duplicada, padroniza√ß√£o, Base de Conhecimento de Qualidade SAS.

‚û§ Plataforma DQLabs
‚Ü≥ Ferramenta hol√≠stica de qualidade e observabilidade de dados usando IA e aprendizado de m√°quina.
‚Ü≥ Principais recursos: Perfil de dados automatizado, detec√ß√£o de anomalias, monitoramento proativo.

‚û§ Abrir Refinar
‚Ü≥ Uma ferramenta gratuita e de c√≥digo aberto para limpar e transformar dados confusos.
‚Ü≥ Principais recursos: Consist√™ncia de dados, corre√ß√£o de erros, transforma√ß√µes de dados vers√°teis.

‚û§ Precisamente Data Integrity Suite
‚Ü≥ Um conjunto modular fornece qualidade, governan√ßa e dom√≠nio de dados.
‚Ü≥ Principais recursos: Cria√ß√£o de perfil, limpeza, padroniza√ß√£o, visualiza√ß√£o de dados em tempo real.

‚û§ Qualidade de dados corporativos Oracle
‚Ü≥ Solu√ß√£o abrangente para governan√ßa de dados e gerenciamento de qualidade.
‚Ü≥ Principais recursos: Perfil de dados, recursos extens√≠veis, processamento em lote e em tempo real.

‚û§ Malha de dados Talend
‚Ü≥ Plataforma unificada para integra√ß√£o de dados e gest√£o da qualidade.
‚Ü≥ Principais recursos: Perfil de dados, limpeza, integra√ß√£o, monitoramento em tempo real.

‚û§ Servi√ßos de dados SAP
‚Ü≥ Ferramenta avan√ßada para integra√ß√£o e qualidade de dados em diversas fontes.
‚Ü≥ Principais recursos: Transforma√ß√£o de dados, limpeza, cria√ß√£o de perfil, integra√ß√£o com sistemas SAP.

‚û§ Ataccama ONE
‚Ü≥ Uma plataforma baseada em IA que integra governan√ßa de dados, qualidade e gerenciamento de dados mestres.
‚Ü≥ Principais recursos: Perfil de dados, monitoramento em tempo real, cat√°logo de dados integrado.

‚û§ Qualidade de dados da Informatica Cloud
‚Ü≥ Solu√ß√£o de qualidade de dados orientada por IA para ambientes de nuvem e h√≠bridos.
‚Ü≥ Principais recursos: Perfil de dados, limpeza, detec√ß√£o automatizada de anomalias, mecanismo CLAIRE.

C√≥digo de detec√ß√£o de mensagem (MDC)

Quando precisamos enviar dados cr√≠ticos para uma pessoa pela internet, os dados trocam de m√£os, saltando entre roteadores e servidores, e cada etapa traz o risco potencial de altera√ß√µes n√£o intencionais.

Note que estamos falando sobre a integridade e n√£o sobre a confidencialidade dos dados.

Um modify detection code (MDC) √© um resumo de mensagem ou uma soma de verifica√ß√£o que pode provar a integridade de uma mensagem: que a mensagem n√£o foi alterada.

![](img/mdc-001.png)

o Message Authentication Code (MAC) n√£o s√≥ garantem a integridade da mensagem, detectando quaisquer altera√ß√µes n√£o autorizadas, mas tamb√©m fornecem um mecanismo para autenticar a origem dos dados. Em outras palavras, os MACs oferecem garantia de que a mensagem √© de fato origin√°ria de Alice e n√£o de outra pessoa.

![](img/mdc-002.png)

HMAC ou um MAC baseado em Hash √© um m√©todo espec√≠fico para construir um algoritmo MAC a partir de uma fun√ß√£o hash resistente a colis√µes. HMAC usa duas passagens de computa√ß√£o de hash e fornece uma melhor imunidade contra ataques de extens√£o de comprimento. A figura abaixo explica a constru√ß√£o de HMACs.

![](img/mdc-003.png)

- [x] Behrouz A. Forouzan - Introdu√ß√£o √† Criptografia e Seguran√ßa de Redes
- [x] Novas dire√ß√µes na criptografia, Whitfield Diffie e Martin E. Hellman diffie.hellman.pdf (jhu.edu)
- [x] Codifica√ß√£o de fun√ß√µes hash para autentica√ß√£o de mensagens, Mihir Bellare, Ran Canetti, Hugo Krawczyk






Resumo da captura de dados de altera√ß√£o (CDC)

CDC √© uma t√©cnica usada em bancos de dados para capturar e replicar altera√ß√µes (como opera√ß√µes INSERT, UPDATE e DELETE) em tempo real ou quase em tempo real. Em vez de consultar tabelas inteiras em busca de atualiza√ß√µes, o CDC permite que os sistemas detectem e processem automaticamente apenas os dados alterados, melhorando a efici√™ncia e o desempenho.

üìç Principais benef√≠cios:

- An√°lise em tempo real: fornece insights imediatos capturando altera√ß√µes de dados ao vivo.

- Efici√™ncia de recursos: reduz a carga no banco de dados de origem rastreando apenas as altera√ß√µes
.
- Sincroniza√ß√£o de dados: garante que todos os sistemas estejam atualizados com os dados mais recentes.

- Recupera√ß√£o do sistema: facilita a reconstru√ß√£o dos estados do sistema usando uma sequ√™ncia de altera√ß√µes.

üìç Tipos de CDC:

1. Baseado em gatilho: usa gatilhos de banco de dados para capturar altera√ß√µes.

2. Baseado em log: l√™ as altera√ß√µes diretamente dos logs de transa√ß√µes.

3. Baseado em carimbo de data/hora: Usa colunas de carimbo de data/hora para identificar registros modificados.

üìç Desafios:

- Integridade dos dados: Garantir que todas as altera√ß√µes sejam capturadas com precis√£o.

- Escalabilidade: Adaptando-se ao crescente volume de dados.

- Lat√™ncia: Minimizando o atraso na propaga√ß√£o de dados.

üìç Ferramentas:

- Kafka: Ideal para gerenciar o fluxo de eventos de mudan√ßa.

- Debezium: uma ferramenta CDC de c√≥digo aberto que se integra ao Kafka para transmitir altera√ß√µes de v√°rios bancos de dados.

O CDC √© cada vez mais vital para estrat√©gias de dados modernas, garantindo dados em tempo real, consist√™ncia e auxiliando nos processos de recupera√ß√£o.



Voc√™ pode explicar a diferen√ßa entre Event Sourcing e Change Data Capture (CDC)?

Event Sourcing e CDC s√£o conceitos relacionados que os sistemas distribu√≠dos usam para propagar altera√ß√µes de dados para consumidores interessados e servi√ßos downstream.

Ambos lidam com eventos, mas servem a prop√≥sitos diferentes.

Fornecimento de eventos

Com o Event Sourcing, o log de eventos √© a fonte da verdade. Em vez de armazenar apenas o estado mais recente, voc√™ persiste cada altera√ß√£o de estado como um evento.

Isso permite:

‚Ä¢Auditoria
‚Ä¢Depura√ß√£o
‚Ä¢ Reconstru√ß√£o do Estado

Captura de dados de altera√ß√£o (CDC)

O CDC escuta as altera√ß√µes no n√≠vel do banco de dados e as propaga para outros servi√ßos. Ele garante a consist√™ncia dos dados entre os sistemas sem exigir que eles consultem o banco de dados de origem diretamente.

Isso funciona no n√≠vel do banco de dados e rastreia:
‚Ä¢Insere
‚Ä¢Atualiza√ß√µes
‚Ä¢Exclui

Embora distintos, esses conceitos podem ser complementares:

‚Ä¢ Voc√™ pode usar o Event Sourcing para gerenciar eventos de dom√≠nio interno e preservar o hist√≥rico.
‚Ä¢ E use o CDC para capturar altera√ß√µes relevantes e distribu√≠-las para sistemas externos.

Exemplo:

1. Um aplicativo fintech registra eventos TransactionInitiated e TransactionCompleted usando Event Sourcing.
2. Um pipeline CDC escuta atualiza√ß√µes no banco de dados de transa√ß√µes e sincroniza dados com relat√≥rios, detec√ß√£o de fraudes e notifica√ß√µes.

N√£o consigo pensar em uma analogia melhor do que essa. Voc√™ poderia?

O Event Sourcing √© como um livro-raz√£o - cada transa√ß√£o √© registrada para refer√™ncia futura.

O CDC √© como um mensageiro - ele detecta altera√ß√µes e notifica outros sistemas, mas n√£o armazena o hist√≥rico.
